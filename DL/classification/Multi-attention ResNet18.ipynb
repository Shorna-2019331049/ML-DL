{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbea84b1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-28T19:03:52.524582Z",
     "iopub.status.busy": "2025-02-28T19:03:52.524296Z",
     "iopub.status.idle": "2025-02-28T19:04:13.645008Z",
     "shell.execute_reply": "2025-02-28T19:04:13.643984Z"
    },
    "papermill": {
     "duration": 21.12822,
     "end_time": "2025-02-28T19:04:13.646377",
     "exception": false,
     "start_time": "2025-02-28T19:03:52.518157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/resnet18_cbam_eca/pytorch/default/1/best_model.pth\n",
      "/kaggle/input/psfhsp-classification/denoised/denoised/Standard_plane/20191115T105730_719.png\n",
      "/kaggle/input/psfhsp-classification/denoised/denoised/Non-standard_plane/20191220T102712_59.png\n",
      "/kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Standard_plane/01413PSFHSAoP4k_1413.png\n",
      "/kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Non-standard_plane/20191220T102712_59.png\n",
      "/kaggle/input/resnet18_cbam_eca_69epoch/pytorch/default/1/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        break\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bedbd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:13.657659Z",
     "iopub.status.busy": "2025-02-28T19:04:13.657282Z",
     "iopub.status.idle": "2025-02-28T19:04:13.661021Z",
     "shell.execute_reply": "2025-02-28T19:04:13.660358Z"
    },
    "papermill": {
     "duration": 0.010373,
     "end_time": "2025-02-28T19:04:13.662201",
     "exception": false,
     "start_time": "2025-02-28T19:04:13.651828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# test_root_dir = '/kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Standard_plane'\n",
    "\n",
    "# # Get all image file paths in the directory\n",
    "# image_files = [os.path.join(test_root_dir, f) for f in os.listdir(test_root_dir) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# # Iterate over each image and get its size\n",
    "# cnt_test_std = 0\n",
    "# cnt_test_nonstd = 0\n",
    "# cnt_train_std = 0\n",
    "# cnt_train_nonstd = 0\n",
    "# for image_path in image_files:\n",
    "#     try:\n",
    "#         with Image.open(image_path) as img:\n",
    "#             width, height = img.size\n",
    "#             cnt_test_std+=1\n",
    "#             # print(f\"Image: {os.path.basename(image_path)}, Size: {width}x{height}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not process {image_path}: {e}\")\n",
    "\n",
    "# print(cnt_test_std)\n",
    "\n",
    "\n",
    "\n",
    "# test_root_dir = '/kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Non-standard_plane'\n",
    "\n",
    "# # Get all image file paths in the directory\n",
    "# image_files = [os.path.join(test_root_dir, f) for f in os.listdir(test_root_dir) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# for image_path in image_files:\n",
    "#     try:\n",
    "#         with Image.open(image_path) as img:\n",
    "#             width, height = img.size\n",
    "#             cnt_test_nonstd+=1\n",
    "#             # print(f\"Image: {os.path.basename(image_path)}, Size: {width}x{height}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not process {image_path}: {e}\")\n",
    "\n",
    "# print(cnt_test_nonstd)\n",
    "\n",
    "\n",
    "# test_root_dir = '/kaggle/input/psfhsp-classification/denoised/denoised/Standard_plane'\n",
    "\n",
    "# # Get all image file paths in the directory\n",
    "# image_files = [os.path.join(test_root_dir, f) for f in os.listdir(test_root_dir) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# for image_path in image_files:\n",
    "#     try:\n",
    "#         with Image.open(image_path) as img:\n",
    "#             width, height = img.size\n",
    "#             cnt_train_std+=1\n",
    "#             # print(f\"Image: {os.path.basename(image_path)}, Size: {width}x{height}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not process {image_path}: {e}\")\n",
    "\n",
    "# print(cnt_train_std)\n",
    "\n",
    "\n",
    "# test_root_dir = '/kaggle/input/psfhsp-classification/denoised/denoised/Non-standard_plane'\n",
    "\n",
    "# # Get all image file paths in the directory\n",
    "# image_files = [os.path.join(test_root_dir, f) for f in os.listdir(test_root_dir) if f.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# for image_path in image_files:\n",
    "#     try:\n",
    "#         with Image.open(image_path) as img:\n",
    "#             width, height = img.size\n",
    "#             cnt_train_nonstd+=1\n",
    "#             # print(f\"Image: {os.path.basename(image_path)}, Size: {width}x{height}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Could not process {image_path}: {e}\")\n",
    "\n",
    "# print(cnt_train_nonstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b6ce33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:13.672433Z",
     "iopub.status.busy": "2025-02-28T19:04:13.672224Z",
     "iopub.status.idle": "2025-02-28T19:04:18.328381Z",
     "shell.execute_reply": "2025-02-28T19:04:18.327442Z"
    },
    "papermill": {
     "duration": 4.663964,
     "end_time": "2025-02-28T19:04:18.330884",
     "exception": false,
     "start_time": "2025-02-28T19:04:13.666920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_CBAM_ECA(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM_ECA(\n",
      "        (ChannelGate): ChannelGate(\n",
      "          (mlp): Sequential(\n",
      "            (0): Flatten()\n",
      "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
      "            (2): ReLU()\n",
      "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (SpatialGate): SpatialGate(\n",
      "          (compress): ChannelPool()\n",
      "          (spatial): BasicConv(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (eca_layer): eca_layer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM_ECA(\n",
      "        (ChannelGate): ChannelGate(\n",
      "          (mlp): Sequential(\n",
      "            (0): Flatten()\n",
      "            (1): Linear(in_features=64, out_features=4, bias=True)\n",
      "            (2): ReLU()\n",
      "            (3): Linear(in_features=4, out_features=64, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (SpatialGate): SpatialGate(\n",
      "          (compress): ChannelPool()\n",
      "          (spatial): BasicConv(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (eca_layer): eca_layer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM_ECA(\n",
      "        (ChannelGate): ChannelGate(\n",
      "          (mlp): Sequential(\n",
      "            (0): Flatten()\n",
      "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
      "            (2): ReLU()\n",
      "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (SpatialGate): SpatialGate(\n",
      "          (compress): ChannelPool()\n",
      "          (spatial): BasicConv(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (eca_layer): eca_layer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM_ECA(\n",
      "        (ChannelGate): ChannelGate(\n",
      "          (mlp): Sequential(\n",
      "            (0): Flatten()\n",
      "            (1): Linear(in_features=128, out_features=8, bias=True)\n",
      "            (2): ReLU()\n",
      "            (3): Linear(in_features=8, out_features=128, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (SpatialGate): SpatialGate(\n",
      "          (compress): ChannelPool()\n",
      "          (spatial): BasicConv(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (eca_layer): eca_layer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (cbam): CBAM_ECA(\n",
      "        (ChannelGate): ChannelGate(\n",
      "          (mlp): Sequential(\n",
      "            (0): Flatten()\n",
      "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "            (2): ReLU()\n",
      "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (SpatialGate): SpatialGate(\n",
      "          (compress): ChannelPool()\n",
      "          (spatial): BasicConv(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (eca_layer): eca_layer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (cbam): CBAM_ECA(\n",
      "        (ChannelGate): ChannelGate(\n",
      "          (mlp): Sequential(\n",
      "            (0): Flatten()\n",
      "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
      "            (2): ReLU()\n",
      "            (3): Linear(in_features=16, out_features=256, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (SpatialGate): SpatialGate(\n",
      "          (compress): ChannelPool()\n",
      "          (spatial): BasicConv(\n",
      "            (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "            (bn): BatchNorm2d(1, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (eca_layer): eca_layer(\n",
      "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (identity_downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "          Flatten-10                   [-1, 64]               0\n",
      "           Linear-11                    [-1, 4]             260\n",
      "             ReLU-12                    [-1, 4]               0\n",
      "           Linear-13                   [-1, 64]             320\n",
      "          Flatten-14                   [-1, 64]               0\n",
      "           Linear-15                    [-1, 4]             260\n",
      "             ReLU-16                    [-1, 4]               0\n",
      "           Linear-17                   [-1, 64]             320\n",
      "      ChannelGate-18           [-1, 64, 56, 56]               0\n",
      "      ChannelPool-19            [-1, 2, 56, 56]               0\n",
      "           Conv2d-20            [-1, 1, 56, 56]              98\n",
      "      BatchNorm2d-21            [-1, 1, 56, 56]               2\n",
      "        BasicConv-22            [-1, 1, 56, 56]               0\n",
      "      SpatialGate-23           [-1, 64, 56, 56]               0\n",
      "AdaptiveAvgPool2d-24             [-1, 64, 1, 1]               0\n",
      "           Conv1d-25                [-1, 1, 64]               3\n",
      "          Sigmoid-26             [-1, 64, 1, 1]               0\n",
      "        eca_layer-27           [-1, 64, 56, 56]               0\n",
      "         CBAM_ECA-28           [-1, 64, 56, 56]               0\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "            Block-30           [-1, 64, 56, 56]               0\n",
      "           Conv2d-31           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-32           [-1, 64, 56, 56]             128\n",
      "             ReLU-33           [-1, 64, 56, 56]               0\n",
      "           Conv2d-34           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-35           [-1, 64, 56, 56]             128\n",
      "          Flatten-36                   [-1, 64]               0\n",
      "           Linear-37                    [-1, 4]             260\n",
      "             ReLU-38                    [-1, 4]               0\n",
      "           Linear-39                   [-1, 64]             320\n",
      "          Flatten-40                   [-1, 64]               0\n",
      "           Linear-41                    [-1, 4]             260\n",
      "             ReLU-42                    [-1, 4]               0\n",
      "           Linear-43                   [-1, 64]             320\n",
      "      ChannelGate-44           [-1, 64, 56, 56]               0\n",
      "      ChannelPool-45            [-1, 2, 56, 56]               0\n",
      "           Conv2d-46            [-1, 1, 56, 56]              98\n",
      "      BatchNorm2d-47            [-1, 1, 56, 56]               2\n",
      "        BasicConv-48            [-1, 1, 56, 56]               0\n",
      "      SpatialGate-49           [-1, 64, 56, 56]               0\n",
      "AdaptiveAvgPool2d-50             [-1, 64, 1, 1]               0\n",
      "           Conv1d-51                [-1, 1, 64]               3\n",
      "          Sigmoid-52             [-1, 64, 1, 1]               0\n",
      "        eca_layer-53           [-1, 64, 56, 56]               0\n",
      "         CBAM_ECA-54           [-1, 64, 56, 56]               0\n",
      "             ReLU-55           [-1, 64, 56, 56]               0\n",
      "            Block-56           [-1, 64, 56, 56]               0\n",
      "           Conv2d-57          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-58          [-1, 128, 28, 28]             256\n",
      "             ReLU-59          [-1, 128, 28, 28]               0\n",
      "           Conv2d-60          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-61          [-1, 128, 28, 28]             256\n",
      "           Conv2d-62          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "          Flatten-64                  [-1, 128]               0\n",
      "           Linear-65                    [-1, 8]           1,032\n",
      "             ReLU-66                    [-1, 8]               0\n",
      "           Linear-67                  [-1, 128]           1,152\n",
      "          Flatten-68                  [-1, 128]               0\n",
      "           Linear-69                    [-1, 8]           1,032\n",
      "             ReLU-70                    [-1, 8]               0\n",
      "           Linear-71                  [-1, 128]           1,152\n",
      "      ChannelGate-72          [-1, 128, 28, 28]               0\n",
      "      ChannelPool-73            [-1, 2, 28, 28]               0\n",
      "           Conv2d-74            [-1, 1, 28, 28]              98\n",
      "      BatchNorm2d-75            [-1, 1, 28, 28]               2\n",
      "        BasicConv-76            [-1, 1, 28, 28]               0\n",
      "      SpatialGate-77          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-78            [-1, 128, 1, 1]               0\n",
      "           Conv1d-79               [-1, 1, 128]               3\n",
      "          Sigmoid-80            [-1, 128, 1, 1]               0\n",
      "        eca_layer-81          [-1, 128, 28, 28]               0\n",
      "         CBAM_ECA-82          [-1, 128, 28, 28]               0\n",
      "             ReLU-83          [-1, 128, 28, 28]               0\n",
      "            Block-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-86          [-1, 128, 28, 28]             256\n",
      "             ReLU-87          [-1, 128, 28, 28]               0\n",
      "           Conv2d-88          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-89          [-1, 128, 28, 28]             256\n",
      "          Flatten-90                  [-1, 128]               0\n",
      "           Linear-91                    [-1, 8]           1,032\n",
      "             ReLU-92                    [-1, 8]               0\n",
      "           Linear-93                  [-1, 128]           1,152\n",
      "          Flatten-94                  [-1, 128]               0\n",
      "           Linear-95                    [-1, 8]           1,032\n",
      "             ReLU-96                    [-1, 8]               0\n",
      "           Linear-97                  [-1, 128]           1,152\n",
      "      ChannelGate-98          [-1, 128, 28, 28]               0\n",
      "      ChannelPool-99            [-1, 2, 28, 28]               0\n",
      "          Conv2d-100            [-1, 1, 28, 28]              98\n",
      "     BatchNorm2d-101            [-1, 1, 28, 28]               2\n",
      "       BasicConv-102            [-1, 1, 28, 28]               0\n",
      "     SpatialGate-103          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-104            [-1, 128, 1, 1]               0\n",
      "          Conv1d-105               [-1, 1, 128]               3\n",
      "         Sigmoid-106            [-1, 128, 1, 1]               0\n",
      "       eca_layer-107          [-1, 128, 28, 28]               0\n",
      "        CBAM_ECA-108          [-1, 128, 28, 28]               0\n",
      "            ReLU-109          [-1, 128, 28, 28]               0\n",
      "           Block-110          [-1, 128, 28, 28]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         294,912\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "          Conv2d-116          [-1, 256, 14, 14]          32,768\n",
      "     BatchNorm2d-117          [-1, 256, 14, 14]             512\n",
      "         Flatten-118                  [-1, 256]               0\n",
      "          Linear-119                   [-1, 16]           4,112\n",
      "            ReLU-120                   [-1, 16]               0\n",
      "          Linear-121                  [-1, 256]           4,352\n",
      "         Flatten-122                  [-1, 256]               0\n",
      "          Linear-123                   [-1, 16]           4,112\n",
      "            ReLU-124                   [-1, 16]               0\n",
      "          Linear-125                  [-1, 256]           4,352\n",
      "     ChannelGate-126          [-1, 256, 14, 14]               0\n",
      "     ChannelPool-127            [-1, 2, 14, 14]               0\n",
      "          Conv2d-128            [-1, 1, 14, 14]              98\n",
      "     BatchNorm2d-129            [-1, 1, 14, 14]               2\n",
      "       BasicConv-130            [-1, 1, 14, 14]               0\n",
      "     SpatialGate-131          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-132            [-1, 256, 1, 1]               0\n",
      "          Conv1d-133               [-1, 1, 256]               3\n",
      "         Sigmoid-134            [-1, 256, 1, 1]               0\n",
      "       eca_layer-135          [-1, 256, 14, 14]               0\n",
      "        CBAM_ECA-136          [-1, 256, 14, 14]               0\n",
      "            ReLU-137          [-1, 256, 14, 14]               0\n",
      "           Block-138          [-1, 256, 14, 14]               0\n",
      "          Conv2d-139          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-140          [-1, 256, 14, 14]             512\n",
      "            ReLU-141          [-1, 256, 14, 14]               0\n",
      "          Conv2d-142          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-143          [-1, 256, 14, 14]             512\n",
      "         Flatten-144                  [-1, 256]               0\n",
      "          Linear-145                   [-1, 16]           4,112\n",
      "            ReLU-146                   [-1, 16]               0\n",
      "          Linear-147                  [-1, 256]           4,352\n",
      "         Flatten-148                  [-1, 256]               0\n",
      "          Linear-149                   [-1, 16]           4,112\n",
      "            ReLU-150                   [-1, 16]               0\n",
      "          Linear-151                  [-1, 256]           4,352\n",
      "     ChannelGate-152          [-1, 256, 14, 14]               0\n",
      "     ChannelPool-153            [-1, 2, 14, 14]               0\n",
      "          Conv2d-154            [-1, 1, 14, 14]              98\n",
      "     BatchNorm2d-155            [-1, 1, 14, 14]               2\n",
      "       BasicConv-156            [-1, 1, 14, 14]               0\n",
      "     SpatialGate-157          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-158            [-1, 256, 1, 1]               0\n",
      "          Conv1d-159               [-1, 1, 256]               3\n",
      "         Sigmoid-160            [-1, 256, 1, 1]               0\n",
      "       eca_layer-161          [-1, 256, 14, 14]               0\n",
      "        CBAM_ECA-162          [-1, 256, 14, 14]               0\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "           Block-164          [-1, 256, 14, 14]               0\n",
      "          Conv2d-165            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-166            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-167            [-1, 512, 7, 7]               0\n",
      "          Conv2d-168            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-169            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-170            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-171            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-172            [-1, 512, 7, 7]               0\n",
      "           Block-173            [-1, 512, 7, 7]               0\n",
      "          Conv2d-174            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-175            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-176            [-1, 512, 7, 7]               0\n",
      "          Conv2d-177            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-178            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-179            [-1, 512, 7, 7]               0\n",
      "           Block-180            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-181            [-1, 512, 1, 1]               0\n",
      "          Linear-182                    [-1, 2]           1,026\n",
      "================================================================\n",
      "Total params: 11,223,068\n",
      "Trainable params: 11,223,068\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 84.59\n",
      "Params size (MB): 42.81\n",
      "Estimated Total Size (MB): 127.97\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "# ------------------------- ECA Implementation -------------------------\n",
    "\n",
    "class eca_layer(nn.Module):\n",
    "    \"\"\"Constructs a ECA module.\n",
    "\n",
    "    Args:\n",
    "        channel: Number of channels of the input feature map\n",
    "        k_size: Adaptive selection of kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(eca_layer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False) \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # feature descriptor on the global spatial information\n",
    "        y = self.avg_pool(x)\n",
    "\n",
    "        # Two different branches of ECA module\n",
    "        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        # Multi-scale information fusion\n",
    "        y = self.sigmoid(y)\n",
    "\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# ------------------------- CBAM Implementation -------------------------\n",
    "class BasicConv(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "        super(BasicConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "        self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "        )\n",
    "        self.pool_types = pool_types\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type == 'avg':\n",
    "                avg_pool = F.adaptive_avg_pool2d(x, 1)\n",
    "                channel_att_raw = self.mlp(avg_pool.squeeze(-1).squeeze(-1))\n",
    "            elif pool_type == 'max':\n",
    "                max_pool = F.adaptive_max_pool2d(x, 1)\n",
    "                channel_att_raw = self.mlp(max_pool.squeeze(-1).squeeze(-1))\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum += channel_att_raw\n",
    "\n",
    "        scale = torch.sigmoid(channel_att_sum).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "class ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x, 1).unsqueeze(1)), dim=1)\n",
    "\n",
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = ChannelPool()\n",
    "        self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size - 1) // 2, relu=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = torch.sigmoid(x_out)  # Applying sigmoid instead of softmax for binary activation\n",
    "        return x * scale\n",
    "\n",
    "class CBAM_ECA(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(CBAM_ECA, self).__init__()\n",
    "        self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "        self.SpatialGate = SpatialGate()\n",
    "        self.eca_layer = eca_layer(gate_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_out = self.ChannelGate(x)\n",
    "        x_out = self.SpatialGate(x_out)\n",
    "        x_out = self.eca_layer(x_out)\n",
    "        return x_out\n",
    "\n",
    "# ------------------------- ResNet18 with CBAM_ECA (Excluding Last Layer) -------------------------\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, intermediate_channels, identity_downsample=None, stride=1, use_cbam_eca=True):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, intermediate_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.use_cbam_eca = use_cbam_eca\n",
    "        if use_cbam_eca:\n",
    "            self.cbam = CBAM_ECA(intermediate_channels)  # Add CBAM only if enabled\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        if self.use_cbam_eca:\n",
    "            x = self.cbam(x)  # Apply CBAM if enabled\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet_CBAM_ECA(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet_CBAM_ECA, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, layers[0], intermediate_channels=64, stride=1, use_cbam_eca=True)\n",
    "        self.layer2 = self._make_layer(block, layers[1], intermediate_channels=128, stride=2, use_cbam_eca=True)\n",
    "        self.layer3 = self._make_layer(block, layers[2], intermediate_channels=256, stride=2, use_cbam_eca=True)\n",
    "        self.layer4 = self._make_layer(block, layers[3], intermediate_channels=512, stride=2, use_cbam_eca=False)  # No CBAM in last layer\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)  # Last layer without CBAM\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return nn.functional.softmax(x, dim=1)\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride, use_cbam_eca):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != intermediate_channels:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, intermediate_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(intermediate_channels)\n",
    "            )\n",
    "\n",
    "        layers.append(block(self.in_channels, intermediate_channels, identity_downsample, stride, use_cbam_eca=use_cbam_eca))\n",
    "        self.in_channels = intermediate_channels\n",
    "\n",
    "        for _ in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels, use_cbam_eca=use_cbam_eca))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def ResNet18_CBAM_ECA():\n",
    "    img_channel = 3\n",
    "    num_classes = 2\n",
    "    return ResNet_CBAM_ECA(Block, [2, 2, 2, 2], img_channel, num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet18_cbam_eca = ResNet18_CBAM_ECA().to(device)  # Move model to device\n",
    "print(resnet18_cbam_eca)\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "from torchsummary import summary\n",
    "summary(resnet18_cbam_eca, (3, 224, 224), device=str(device))  # Ensure summary uses the correct device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d509d961",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:18.342793Z",
     "iopub.status.busy": "2025-02-28T19:04:18.342373Z",
     "iopub.status.idle": "2025-02-28T19:04:18.348050Z",
     "shell.execute_reply": "2025-02-28T19:04:18.347372Z"
    },
    "papermill": {
     "duration": 0.012645,
     "end_time": "2025-02-28T19:04:18.349130",
     "exception": false,
     "start_time": "2025-02-28T19:04:18.336485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience, min_delta=0.01, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_model = None  # Initialize best_model to None\n",
    "        self.best_loss = float('inf')  # Initialize best_loss to a large value\n",
    "        self.counter = 0\n",
    "        self.status = \"\"\n",
    "\n",
    "    def __call__(self, model, val_loss):\n",
    "        # Check if it's the first epoch or if validation loss improved\n",
    "        if val_loss < self.best_loss:  # Use '<' to check for improvement\n",
    "            self.best_loss = val_loss\n",
    "            self.best_model = copy.deepcopy(model.state_dict())\n",
    "            self.counter = 0\n",
    "            self.status = f\"Improvement found, counter reset to {self.counter}\"\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.status = f\"No improvement in the last {self.counter} epochs\"\n",
    "            if self.counter >= self.patience:\n",
    "                self.status = f\"Early stopping triggered after {self.counter} epochs.\"\n",
    "                if self.restore_best_weights:\n",
    "                    if self.best_model is not None:  # Check if best_model exists before loading\n",
    "                        model.load_state_dict(self.best_model)\n",
    "                    else:\n",
    "                        print(\"Warning: No best model found to restore.\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aa20467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:18.360267Z",
     "iopub.status.busy": "2025-02-28T19:04:18.360019Z",
     "iopub.status.idle": "2025-02-28T19:04:18.368489Z",
     "shell.execute_reply": "2025-02-28T19:04:18.367901Z"
    },
    "papermill": {
     "duration": 0.01546,
     "end_time": "2025-02-28T19:04:18.369726",
     "exception": false,
     "start_time": "2025-02-28T19:04:18.354266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint_f(model, optimizer, path, epoch, fold, train_acc, val_acc, early_stopping,train_accuracies,val_accuracies,train_f1_scores,\n",
    "                    val_f1_scores,train_roc_aucs,val_roc_aucs,all_train_loss,all_val_loss,best_acc,fold_train_accuracies,fold_val_accuracies,fold_train_loss,\n",
    "                    fold_val_loss,fold_train_f1,fold_val_f1,fold_train_roc,fold_val_roc,track_all_train_loss,track_all_val_loss):\n",
    "    checkpoint = {\n",
    "        'fold': fold,\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_acc': train_acc,\n",
    "        'val_acc': val_acc,\n",
    "        'best_loss': early_stopping.best_loss,\n",
    "        'counter': early_stopping.counter,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'train_f1_scores':train_f1_scores,\n",
    "        'val_f1_scores':val_f1_scores,\n",
    "        'train_roc_aucs':train_roc_aucs,\n",
    "        'val_roc_aucs':val_roc_aucs,\n",
    "        'all_train_loss':all_train_loss,\n",
    "        'all_val_loss':all_val_loss,\n",
    "        'best_acc':best_acc,\n",
    "        'fold_train_accuracies':fold_train_accuracies,\n",
    "        'fold_val_accuracies':fold_val_accuracies,\n",
    "        'fold_train_loss':fold_train_loss,\n",
    "        'fold_val_loss':fold_val_loss,\n",
    "        'fold_train_f1':fold_train_f1,\n",
    "        'fold_val_f1':fold_val_f1,\n",
    "        'fold_train_roc':fold_train_roc,\n",
    "        'fold_val_roc':fold_val_roc,\n",
    "        'track_all_train_loss':track_all_train_loss,\n",
    "        'track_all_val_loss':track_all_val_loss\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint_f(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    best_loss = checkpoint.get('best_loss', None)\n",
    "    counter = checkpoint.get('counter', 0)\n",
    "    train_accuracies = checkpoint.get('train_accuracies', [])\n",
    "    val_accuracies = checkpoint.get('val_accuracies', [])\n",
    "    all_train_loss = checkpoint.get('all_train_loss', [])\n",
    "    all_val_loss = checkpoint.get('all_val_loss',[])\n",
    "    train_f1_scores = checkpoint.get('train_f1_scores', [])\n",
    "    val_f1_scores = checkpoint.get('val_f1_scores', [])\n",
    "    train_roc_aucs = checkpoint.get('train_roc_aucs', [])\n",
    "    val_roc_aucs = checkpoint.get('val_roc_aucs', [])\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    fold_train_accuracies = checkpoint.get('fold_train_accuracies', [])\n",
    "    fold_val_accuracies = checkpoint.get('fold_val_accuracies', [])\n",
    "    fold_train_loss = checkpoint.get('fold_train_loss', [])\n",
    "    fold_val_loss = checkpoint.get('fold_val_loss', [])\n",
    "    fold_train_f1 = checkpoint.get('fold_train_f1', [])\n",
    "    fold_val_f1 = checkpoint.get('fold_val_f1', [])\n",
    "    fold_train_roc = checkpoint.get('fold_train_roc', [])\n",
    "    fold_val_roc = checkpoint.get('fold_val_roc', [])\n",
    "    track_all_train_loss = checkpoint.get('track_all_train_loss', [])\n",
    "    track_all_val_loss = checkpoint.get('track_all_val_loss', [])\n",
    "\n",
    "\n",
    "    return (model, optimizer, epoch, train_acc, val_acc, best_loss, counter,train_accuracies, val_accuracies,all_train_loss,all_val_loss,\n",
    "            train_f1_scores,val_f1_scores,train_roc_aucs,val_roc_aucs,best_acc,fold_train_accuracies,fold_val_accuracies,fold_train_loss,\n",
    "            fold_val_loss,fold_train_f1,fold_val_f1,fold_train_roc,fold_val_roc,track_all_train_loss,track_all_val_loss)\n",
    "\n",
    "\n",
    "def load_checkpoint_fold(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    fold = checkpoint['fold']\n",
    "    return fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f56726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:18.380975Z",
     "iopub.status.busy": "2025-02-28T19:04:18.380769Z",
     "iopub.status.idle": "2025-02-28T19:04:23.323716Z",
     "shell.execute_reply": "2025-02-28T19:04:23.322972Z"
    },
    "papermill": {
     "duration": 4.950194,
     "end_time": "2025-02-28T19:04:23.325233",
     "exception": false,
     "start_time": "2025-02-28T19:04:18.375039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f5beef4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:23.337097Z",
     "iopub.status.busy": "2025-02-28T19:04:23.336731Z",
     "iopub.status.idle": "2025-02-28T19:04:39.244185Z",
     "shell.execute_reply": "2025-02-28T19:04:39.243273Z"
    },
    "papermill": {
     "duration": 15.914758,
     "end_time": "2025-02-28T19:04:39.245695",
     "exception": false,
     "start_time": "2025-02-28T19:04:23.330937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking directory: /kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Non-standard_plane\n",
      "Checking directory: /kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Standard_plane\n",
      "Total images found: 12581\n",
      "Test directory exists: True\n",
      "Checking directory: /kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Non-standard_plane\n",
      "Checking directory: /kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k/Standard_plane\n",
      "Total images found: 12581\n",
      "Total images found: 12581\n",
      "Total labels found: 12581\n",
      "Unique labels: {0, 1}\n",
      "Test dataset size: 2097\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "class UltrasoundDataset_f(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Function to handle different dataset structures\n",
    "def load_dataset_f(root_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_label, class_name in enumerate(['Non-standard_plane', 'Standard_plane']):\n",
    "        class_dir = os.path.join(root_dir, class_name)  # Directly access class folder\n",
    "        print(f\"Checking directory: {class_dir}\")  # Debugging print\n",
    "\n",
    "        if os.path.exists(class_dir) and os.path.isdir(class_dir):\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                img_path = os.path.join(class_dir, img_name)\n",
    "                if os.path.isfile(img_path):  # Ensure it's an image file\n",
    "                    image_paths.append(img_path)\n",
    "                    labels.append(class_label)\n",
    "\n",
    "    print(f\"Total images found: {len(image_paths)}\")  # Debugging print\n",
    "    return image_paths, labels\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "### **Loading the test dataset**\n",
    "test_root_dir = '/kaggle/input/psfhsp-classification/2.Thesis_12k/2.Thesis_12k'\n",
    "test_image_paths, test_labels = load_dataset_f(test_root_dir)\n",
    "\n",
    "import os\n",
    "print(\"Test directory exists:\", os.path.exists(test_root_dir))\n",
    "test_image_paths, test_labels = load_dataset_f(test_root_dir)\n",
    "print(f\"Total images found: {len(test_image_paths)}\")\n",
    "print(f\"Total labels found: {len(test_labels)}\")\n",
    "print(f\"Unique labels: {set(test_labels)}\")\n",
    "\n",
    "\n",
    "# Splitting test data (keeping validation + test set separate)\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = train_test_split(\n",
    "    test_image_paths, test_labels, test_size=1/6, stratify=test_labels, random_state=42\n",
    ")\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Call the function early in the script\n",
    "set_seed(42)\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Creating test dataset\n",
    "test_dataset_f = UltrasoundDataset_f(test_image_paths, test_labels, transform=test_transform)\n",
    "print(f\"Test dataset size: {len(test_dataset_f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acf3c6a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:39.257992Z",
     "iopub.status.busy": "2025-02-28T19:04:39.257768Z",
     "iopub.status.idle": "2025-02-28T19:04:39.262248Z",
     "shell.execute_reply": "2025-02-28T19:04:39.261549Z"
    },
    "papermill": {
     "duration": 0.011674,
     "end_time": "2025-02-28T19:04:39.263378",
     "exception": false,
     "start_time": "2025-02-28T19:04:39.251704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Class 1: 1517 images\n",
      "Test Class 0: 580 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print class distribution in test dataset\n",
    "test_class_counts = Counter(test_labels)\n",
    "for class_label, count in test_class_counts.items():\n",
    "    print(f\"Test Class {class_label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b63c341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:39.275063Z",
     "iopub.status.busy": "2025-02-28T19:04:39.274858Z",
     "iopub.status.idle": "2025-02-28T19:04:39.303424Z",
     "shell.execute_reply": "2025-02-28T19:04:39.302794Z"
    },
    "papermill": {
     "duration": 0.035837,
     "end_time": "2025-02-28T19:04:39.304688",
     "exception": false,
     "start_time": "2025-02-28T19:04:39.268851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 15168\n",
      "Train Class 0: 7584 images\n",
      "Train Class 1: 7584 images\n"
     ]
    }
   ],
   "source": [
    "# Function to load image paths and labels from class folders\n",
    "def load_dataset_training(root_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "\n",
    "    for class_label, class_name in enumerate(['Non-standard_plane','Standard_plane']):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            image_paths.append(os.path.join(class_dir, img_name))\n",
    "            labels.append(class_label)\n",
    "\n",
    "    return image_paths, labels\n",
    "    \n",
    "### **Loading the train dataset**\n",
    "train_root_dir = '/kaggle/input/psfhsp-classification/denoised/denoised'\n",
    "train_image_paths, train_labels = load_dataset_training(train_root_dir)\n",
    "\n",
    "# Creating train dataset\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_dataset_f = UltrasoundDataset_f(train_image_paths, train_labels, transform=train_transform)\n",
    "print(f\"Train dataset size: {len(train_dataset_f)}\")\n",
    "\n",
    "# Print class distribution in train dataset\n",
    "train_class_counts = Counter(train_labels)\n",
    "for class_label, count in train_class_counts.items():\n",
    "    print(f\"Train Class {class_label}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fcd67a",
   "metadata": {
    "papermill": {
     "duration": 0.005227,
     "end_time": "2025-02-28T19:04:39.315352",
     "exception": false,
     "start_time": "2025-02-28T19:04:39.310125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2392caaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:04:39.327434Z",
     "iopub.status.busy": "2025-02-28T19:04:39.327225Z",
     "iopub.status.idle": "2025-02-28T22:17:30.972865Z",
     "shell.execute_reply": "2025-02-28T22:17:30.971854Z"
    },
    "papermill": {
     "duration": 11571.653313,
     "end_time": "2025-02-28T22:17:30.974217",
     "exception": false,
     "start_time": "2025-02-28T19:04:39.320904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "False\n",
      "Training and evaluation\n",
      "No model to load.\n",
      "Fold 1:\n",
      "Train_loader: 190\n",
      "Val_loader: 48\n",
      "Fold 2:\n",
      "Train_loader: 190\n",
      "Val_loader: 48\n",
      "Fold 3:\n",
      "Train_loader: 190\n",
      "Val_loader: 48\n",
      "Fold 4:\n",
      "Train_loader: 190\n",
      "Val_loader: 48\n",
      "Fold 5:\n",
      "Train_loader: 190\n",
      "Val_loader: 48\n",
      "5\n",
      "5\n",
      "---------------------EPOCH----------------------------  1\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [1/200],Train Loss: 0.5886, Train Accuracy: 0.7017471567496292, Train F1: 0.6930189159385868, train roc: 0.7651635605036654\n",
      "Epoch [1/200],Val Loss: 0.7295 , Val Accuracy: 0.575148319050758, Val F1: 0.6879690147664004, val roc: 0.6345217832267047\n",
      "The best weight is:  0\n",
      "New best model saved with validation accuracy: 0.5751 and validation loss: 0.7295\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  []\n",
      "Checkpoint saved at epoch 1\n",
      "---------------------EPOCH----------------------------  2\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [2/200],Train Loss: 0.5415, Train Accuracy: 0.7558101203230592, Train F1: 0.7495562505282732, train roc: 0.8296608018873037\n",
      "Epoch [2/200],Val Loss: 0.7710 , Val Accuracy: 0.5379037574159525, Val F1: 0.6802007299270074, val roc: 0.5884471702597979\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  []\n",
      "Checkpoint saved at epoch 2\n",
      "---------------------EPOCH----------------------------  3\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [3/200],Train Loss: 0.5272, Train Accuracy: 0.7727872094939838, Train F1: 0.7651418349092768, train roc: 0.8493377845529058\n",
      "Epoch [3/200],Val Loss: 0.7010 , Val Accuracy: 0.5959129861568886, Val F1: 0.3307860262008734, val roc: 0.8404048774404258\n",
      "The best weight is:  2\n",
      "New best model saved with validation accuracy: 0.5959 and validation loss: 0.7010\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  []\n",
      "Checkpoint saved at epoch 3\n",
      "---------------------EPOCH----------------------------  4\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [4/200],Train Loss: 0.4981, Train Accuracy: 0.8030490317264112, Train F1: 0.8011647254575708, train roc: 0.8809394849146082\n",
      "Epoch [4/200],Val Loss: 0.6581 , Val Accuracy: 0.6234751071546324, Val F1: 0.4751838235294118, val roc: 0.768468787340658\n",
      "The best weight is:  3\n",
      "New best model saved with validation accuracy: 0.6235 and validation loss: 0.6581\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  []\n",
      "Checkpoint saved at epoch 4\n",
      "---------------------EPOCH----------------------------  5\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [5/200],Train Loss: 0.4938, Train Accuracy: 0.8079110012360939, Train F1: 0.8054419497537768, train roc: 0.890921691409235\n",
      "Epoch [5/200],Val Loss: 0.5774 , Val Accuracy: 0.7230464886251237, Val F1: 0.6357328707718994, val roc: 0.8811427828497782\n",
      "The best weight is:  4\n",
      "New best model saved with validation accuracy: 0.7230 and validation loss: 0.5774\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  []\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.5885668574195159, 0.5415393790132121, 0.5272097865217611, 0.49810120980990563, 0.4938033500784322]\n",
      "fold_train_loss:  [0.5298441165685654]\n",
      "fold_val_loss:  [0.6874200439701478]\n",
      "fold_train_accuracies:  [0.7682609039058355]\n",
      "fold_val_accuracies:  [0.611097331680671]\n",
      "fold_train_f1:  [0.7628647353174969]\n",
      "fold_val_f1:  [0.5619744930391184]\n",
      "fold_train_roc:  [0.8432046646535436]\n",
      "fold_val_roc:  [0.7425970802234729]\n",
      "Checkpoint saved at epoch 5\n",
      "---------------------EPOCH----------------------------  6\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [6/200],Train Loss: 0.4754, Train Accuracy: 0.8263556947420472, Train F1: 0.8260259268433656, train roc: 0.9061301592684232\n",
      "Epoch [6/200],Val Loss: 0.4980 , Val Accuracy: 0.8032300593276203, Val F1: 0.8094478135971912, val roc: 0.8779138561041224\n",
      "The best weight is:  0\n",
      "New best model saved with validation accuracy: 0.8032 and validation loss: 0.4980\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355]\n",
      "Checkpoint saved at epoch 6\n",
      "---------------------EPOCH----------------------------  7\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [7/200],Train Loss: 0.4740, Train Accuracy: 0.8305587605076644, Train F1: 0.8310322156476002, train roc: 0.9047904411398142\n",
      "Epoch [7/200],Val Loss: 0.4775 , Val Accuracy: 0.8230059327620303, Val F1: 0.831397174254317, val roc: 0.9083811290107413\n",
      "The best weight is:  1\n",
      "New best model saved with validation accuracy: 0.8230 and validation loss: 0.4775\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355]\n",
      "Checkpoint saved at epoch 7\n",
      "---------------------EPOCH----------------------------  8\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [8/200],Train Loss: 0.4620, Train Accuracy: 0.8427558925333772, Train F1: 0.8424962852897473, train roc: 0.9173789366903923\n",
      "Epoch [8/200],Val Loss: 0.5431 , Val Accuracy: 0.7534607778510217, Val F1: 0.6808873720136518, val roc: 0.9210133972743102\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355]\n",
      "Checkpoint saved at epoch 8\n",
      "---------------------EPOCH----------------------------  9\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [9/200],Train Loss: 0.4503, Train Accuracy: 0.8530696332921301, Train F1: 0.8519471892385618, train roc: 0.9292175763304058\n",
      "Epoch [9/200],Val Loss: 0.4582 , Val Accuracy: 0.8447082096933729, Val F1: 0.8340965128566397, val roc: 0.9329940098409756\n",
      "The best weight is:  3\n",
      "New best model saved with validation accuracy: 0.8447 and validation loss: 0.4582\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355]\n",
      "Checkpoint saved at epoch 9\n",
      "---------------------EPOCH----------------------------  10\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [10/200],Train Loss: 0.4451, Train Accuracy: 0.8607334157395962, Train F1: 0.8601687903359257, train roc: 0.9347193539425003\n",
      "Epoch [10/200],Val Loss: 0.6212 , Val Accuracy: 0.6775469831849654, Val F1: 0.5307101727447217, val roc: 0.8702430066980551\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.47541516438910836, 0.47397808024757787, 0.4619541395651667, 0.45025466460930674, 0.44512619987914437]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409]\n",
      "Checkpoint saved at epoch 10\n",
      "---------------------EPOCH----------------------------  11\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [11/200],Train Loss: 0.4396, Train Accuracy: 0.8673973957474864, Train F1: 0.8677353062063298, train roc: 0.938768798686629\n",
      "Epoch [11/200],Val Loss: 0.6094 , Val Accuracy: 0.6905075807514832, Val F1: 0.7610078900483584, val roc: 0.8760173102987066\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963]\n",
      "Checkpoint saved at epoch 11\n",
      "---------------------EPOCH----------------------------  12\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [12/200],Train Loss: 0.4362, Train Accuracy: 0.8704466787539146, Train F1: 0.8711475409836066, train roc: 0.9414761632839642\n",
      "Epoch [12/200],Val Loss: 0.4864 , Val Accuracy: 0.8180619644034278, Val F1: 0.809655172413793, val roc: 0.9057995323490444\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963]\n",
      "Checkpoint saved at epoch 12\n",
      "---------------------EPOCH----------------------------  13\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [13/200],Train Loss: 0.4362, Train Accuracy: 0.870281852645459, Train F1: 0.8694642560955382, train roc: 0.9406330018056431\n",
      "Epoch [13/200],Val Loss: 0.5154 , Val Accuracy: 0.7883981542518128, Val F1: 0.8135888501742161, val roc: 0.8890393601151354\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963]\n",
      "Checkpoint saved at epoch 13\n",
      "---------------------EPOCH----------------------------  14\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [14/200],Train Loss: 0.4298, Train Accuracy: 0.8778739184177997, Train F1: 0.8775813646125887, train roc: 0.9448071980007039\n",
      "Epoch [14/200],Val Loss: 0.6069 , Val Accuracy: 0.6890867128255852, Val F1: 0.5494505494505495, val roc: 0.9396124920209481\n",
      "No improvement in the last 5 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963]\n",
      "Checkpoint saved at epoch 14\n",
      "---------------------EPOCH----------------------------  15\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [15/200],Train Loss: 0.4245, Train Accuracy: 0.8838071693448702, Train F1: 0.883006969797544, train roc: 0.9485929016772604\n",
      "Epoch [15/200],Val Loss: 0.4860 , Val Accuracy: 0.8219584569732937, Val F1: 0.7905352986811482, val roc: 0.9420522990974756\n",
      "No improvement in the last 6 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.439586856333833, 0.4361662623129393, 0.43617070678033326, 0.42984482755786496, 0.4244603818968723]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619]\n",
      "Checkpoint saved at epoch 15\n",
      "---------------------EPOCH----------------------------  16\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [16/200],Train Loss: 0.4248, Train Accuracy: 0.8819020932915774, Train F1: 0.8813447048107973, train roc: 0.947572148370448\n",
      "Epoch [16/200],Val Loss: 0.4342 , Val Accuracy: 0.8681608437705999, Val F1: 0.875156054931336, val roc: 0.949455066269382\n",
      "The best weight is:  0\n",
      "New best model saved with validation accuracy: 0.8682 and validation loss: 0.4342\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906]\n",
      "Checkpoint saved at epoch 16\n",
      "---------------------EPOCH----------------------------  17\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [17/200],Train Loss: 0.4183, Train Accuracy: 0.8915444206362287, Train F1: 0.8914907651715038, train roc: 0.9532174493769631\n",
      "Epoch [17/200],Val Loss: 0.6318 , Val Accuracy: 0.6733684904416611, Val F1: 0.51634943875061, val roc: 0.8866850273911709\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906]\n",
      "Checkpoint saved at epoch 17\n",
      "---------------------EPOCH----------------------------  18\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [18/200],Train Loss: 0.4154, Train Accuracy: 0.8922861381242789, Train F1: 0.8923305049839361, train roc: 0.9583491460353073\n",
      "Epoch [18/200],Val Loss: 0.5636 , Val Accuracy: 0.7402768622280818, Val F1: 0.7929584866001052, val roc: 0.9166132545716772\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906]\n",
      "Checkpoint saved at epoch 18\n",
      "---------------------EPOCH----------------------------  19\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [19/200],Train Loss: 0.4158, Train Accuracy: 0.8925422332097239, Train F1: 0.892213589022979, train roc: 0.9576507726997984\n",
      "Epoch [19/200],Val Loss: 0.5751 , Val Accuracy: 0.7246950214309265, Val F1: 0.6206269877328487, val roc: 0.9517121697281297\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906]\n",
      "Checkpoint saved at epoch 19\n",
      "---------------------EPOCH----------------------------  20\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [20/200],Train Loss: 0.4134, Train Accuracy: 0.8946847960444994, Train F1: 0.8939946914399468, train roc: 0.9605647016359506\n",
      "Epoch [20/200],Val Loss: 0.4148 , Val Accuracy: 0.8915265413781734, Val F1: 0.8852459016393442, val roc: 0.9638638091080334\n",
      "The best weight is:  4\n",
      "New best model saved with validation accuracy: 0.8915 and validation loss: 0.4148\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.42477922721912986, 0.4183409369305561, 0.4154067497504385, 0.4158256576249474, 0.41337358779028843]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787]\n",
      "Checkpoint saved at epoch 20\n",
      "---------------------EPOCH----------------------------  21\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [21/200],Train Loss: 0.4099, Train Accuracy: 0.8976429866490853, Train F1: 0.8977104266183495, train roc: 0.9603987819222897\n",
      "Epoch [21/200],Val Loss: 0.4553 , Val Accuracy: 0.8553065260382333, Val F1: 0.8707683249926407, val roc: 0.9555216663356927\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617]\n",
      "Checkpoint saved at epoch 21\n",
      "---------------------EPOCH----------------------------  22\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [22/200],Train Loss: 0.4012, Train Accuracy: 0.9092632272952036, Train F1: 0.9092108518182568, train roc: 0.9672539125417509\n",
      "Epoch [22/200],Val Loss: 0.5063 , Val Accuracy: 0.7940013183915623, Val F1: 0.8276812792941826, val roc: 0.9443003464580066\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617]\n",
      "Checkpoint saved at epoch 22\n",
      "---------------------EPOCH----------------------------  23\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [23/200],Train Loss: 0.4042, Train Accuracy: 0.9039063787703973, Train F1: 0.9036204331294427, train roc: 0.9654532681306206\n",
      "Epoch [23/200],Val Loss: 0.4190 , Val Accuracy: 0.8889255108767304, Val F1: 0.895309102205654, val roc: 0.965703351469546\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617]\n",
      "Checkpoint saved at epoch 23\n",
      "---------------------EPOCH----------------------------  24\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [24/200],Train Loss: 0.4010, Train Accuracy: 0.9080346106304079, Train F1: 0.9077685950413223, train roc: 0.967644442051671\n",
      "Epoch [24/200],Val Loss: 0.4209 , Val Accuracy: 0.8822947576656776, Val F1: 0.8906584992343032, val roc: 0.965221117571655\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617]\n",
      "Checkpoint saved at epoch 24\n",
      "---------------------EPOCH----------------------------  25\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [25/200],Train Loss: 0.4031, Train Accuracy: 0.9052327976926247, Train F1: 0.9045484727755645, train roc: 0.9644546032281363\n",
      "Epoch [25/200],Val Loss: 0.4768 , Val Accuracy: 0.8305308275634685, Val F1: 0.7999999999999999, val roc: 0.9513786584061377\n",
      "No improvement in the last 5 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.4098782967579992, 0.40124982140566173, 0.40423998660162874, 0.40099504746888814, 0.4030752713743009]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076]\n",
      "Checkpoint saved at epoch 25\n",
      "---------------------EPOCH----------------------------  26\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [26/200],Train Loss: 0.3962, Train Accuracy: 0.9136311191692764, Train F1: 0.9136595814796507, train roc: 0.9702258220922896\n",
      "Epoch [26/200],Val Loss: 0.4885 , Val Accuracy: 0.8154251812788398, Val F1: 0.842164599774521, val roc: 0.9474099080993305\n",
      "No improvement in the last 6 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438]\n",
      "Checkpoint saved at epoch 26\n",
      "---------------------EPOCH----------------------------  27\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [27/200],Train Loss: 0.3948, Train Accuracy: 0.9139607713861876, Train F1: 0.9142293789023989, train roc: 0.9699066565867455\n",
      "Epoch [27/200],Val Loss: 0.4308 , Val Accuracy: 0.8757415952537904, Val F1: 0.8623585250091274, val roc: 0.9622993896029572\n",
      "No improvement in the last 7 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438]\n",
      "Checkpoint saved at epoch 27\n",
      "---------------------EPOCH----------------------------  28\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [28/200],Train Loss: 0.3983, Train Accuracy: 0.911818031976265, Train F1: 0.9116724451048372, train roc: 0.9685969994584671\n",
      "Epoch [28/200],Val Loss: 0.4585 , Val Accuracy: 0.8503625576796309, Val F1: 0.8281604844814535, val roc: 0.9577328184334953\n",
      "No improvement in the last 8 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438]\n",
      "Checkpoint saved at epoch 28\n",
      "---------------------EPOCH----------------------------  29\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [29/200],Train Loss: 0.3973, Train Accuracy: 0.9124845488257107, Train F1: 0.912563807014655, train roc: 0.968245291346173\n",
      "Epoch [29/200],Val Loss: 0.5503 , Val Accuracy: 0.7537091988130564, Val F1: 0.6756404689535388, val roc: 0.9466705829969232\n",
      "No improvement in the last 9 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438]\n",
      "Checkpoint saved at epoch 29\n",
      "---------------------EPOCH----------------------------  30\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [30/200],Train Loss: 0.3950, Train Accuracy: 0.9130613926658426, Train F1: 0.9126583326434307, train roc: 0.9704562103098567\n",
      "Epoch [30/200],Val Loss: 0.3888 , Val Accuracy: 0.9205407187603033, Val F1: 0.9216769580760481, val roc: 0.975560185966261\n",
      "The best weight is:  4\n",
      "New best model saved with validation accuracy: 0.9205 and validation loss: 0.3888\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.39623760204566155, 0.3947507502217042, 0.3983048653916309, 0.3972596022643541, 0.39501161026327236]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933]\n",
      "Checkpoint saved at epoch 30\n",
      "---------------------EPOCH----------------------------  31\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [31/200],Train Loss: 0.3923, Train Accuracy: 0.9174221196637548, Train F1: 0.9170667108094687, train roc: 0.9717497504447954\n",
      "Epoch [31/200],Val Loss: 0.4779 , Val Accuracy: 0.8259723137771918, Val F1: 0.7929411764705884, val roc: 0.9620666939267514\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565]\n",
      "Checkpoint saved at epoch 31\n",
      "---------------------EPOCH----------------------------  32\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [32/200],Train Loss: 0.3920, Train Accuracy: 0.9182462502060327, Train F1: 0.9178671965557211, train roc: 0.9736926446505314\n",
      "Epoch [32/200],Val Loss: 0.4083 , Val Accuracy: 0.9014502307185234, Val F1: 0.9048073861827444, val roc: 0.9650280777425173\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565]\n",
      "Checkpoint saved at epoch 32\n",
      "---------------------EPOCH----------------------------  33\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [33/200],Train Loss: 0.3895, Train Accuracy: 0.9201417504532718, Train F1: 0.920332154895996, train roc: 0.9733241970350915\n",
      "Epoch [33/200],Val Loss: 0.4046 , Val Accuracy: 0.9034278180619644, Val F1: 0.8959147424511545, val roc: 0.974453664880856\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565]\n",
      "Checkpoint saved at epoch 33\n",
      "---------------------EPOCH----------------------------  34\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [34/200],Train Loss: 0.3924, Train Accuracy: 0.9156983930778739, Train F1: 0.9153916135968901, train roc: 0.9714333917269029\n",
      "Epoch [34/200],Val Loss: 0.3968 , Val Accuracy: 0.913946587537092, Val F1: 0.916852500796432, val roc: 0.9750564403775679\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565]\n",
      "Checkpoint saved at epoch 34\n",
      "---------------------EPOCH----------------------------  35\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [35/200],Train Loss: 0.3905, Train Accuracy: 0.9178409559126494, Train F1: 0.9182853864437341, train roc: 0.9730057589177499\n",
      "Epoch [35/200],Val Loss: 0.3835 , Val Accuracy: 0.9264754368611935, Val F1: 0.9278550630863798, val roc: 0.9766568164148446\n",
      "The best weight is:  4\n",
      "New best model saved with validation accuracy: 0.9265 and validation loss: 0.3835\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.39230921488059195, 0.39202670627518704, 0.3895349786469811, 0.3924363577052167, 0.390543280620324]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074]\n",
      "Checkpoint saved at epoch 35\n",
      "---------------------EPOCH----------------------------  36\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [36/200],Train Loss: 0.3883, Train Accuracy: 0.922037250700511, Train F1: 0.9218311022971409, train roc: 0.9742449221428242\n",
      "Epoch [36/200],Val Loss: 0.3910 , Val Accuracy: 0.9182597231377719, Val F1: 0.9214195183776934, val roc: 0.9740686632578525\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166]\n",
      "Checkpoint saved at epoch 36\n",
      "---------------------EPOCH----------------------------  37\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [37/200],Train Loss: 0.3860, Train Accuracy: 0.9238503378935223, Train F1: 0.9233449477351916, train roc: 0.9757684837321086\n",
      "Epoch [37/200],Val Loss: 0.3919 , Val Accuracy: 0.9156229400131839, Val F1: 0.9162303664921465, val roc: 0.9719978672822056\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166]\n",
      "Checkpoint saved at epoch 37\n",
      "---------------------EPOCH----------------------------  38\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [38/200],Train Loss: 0.3878, Train Accuracy: 0.9223669029174221, Train F1: 0.9227742252828333, train roc: 0.9745039792315301\n",
      "Epoch [38/200],Val Loss: 0.3922 , Val Accuracy: 0.9182597231377719, Val F1: 0.913888888888889, val roc: 0.9783664720076445\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166]\n",
      "Checkpoint saved at epoch 38\n",
      "---------------------EPOCH----------------------------  39\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [39/200],Train Loss: 0.3878, Train Accuracy: 0.9207251751133086, Train F1: 0.9205483977535514, train roc: 0.9750060818335009\n",
      "Epoch [39/200],Val Loss: 0.4121 , Val Accuracy: 0.8954830201121002, Val F1: 0.9024315173899661, val roc: 0.9723811751773654\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166]\n",
      "Checkpoint saved at epoch 39\n",
      "---------------------EPOCH----------------------------  40\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [40/200],Train Loss: 0.3895, Train Accuracy: 0.9210548001648126, Train F1: 0.9207609594706369, train roc: 0.9738527472665975\n",
      "Epoch [40/200],Val Loss: 0.3970 , Val Accuracy: 0.9126277612924497, Val F1: 0.9175738724727838, val roc: 0.9792885990437311\n",
      "No improvement in the last 5 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.3883265429421475, 0.3860456877633145, 0.38783726990222933, 0.38781778341845463, 0.3894576883629749]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598]\n",
      "Checkpoint saved at epoch 40\n",
      "---------------------EPOCH----------------------------  41\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [41/200],Train Loss: 0.3858, Train Accuracy: 0.923603098730839, Train F1: 0.9237099827174718, train roc: 0.9755136919638293\n",
      "Epoch [41/200],Val Loss: 0.3870 , Val Accuracy: 0.9218852999340804, Val F1: 0.9248811410459589, val roc: 0.9769059861668828\n",
      "No improvement in the last 6 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153]\n",
      "Checkpoint saved at epoch 41\n",
      "---------------------EPOCH----------------------------  42\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [42/200],Train Loss: 0.3842, Train Accuracy: 0.9244272292731168, Train F1: 0.9240076240987818, train roc: 0.9771827362975969\n",
      "Epoch [42/200],Val Loss: 0.3895 , Val Accuracy: 0.9192485168094924, Val F1: 0.9204287106203313, val roc: 0.9741225461035097\n",
      "No improvement in the last 7 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153]\n",
      "Checkpoint saved at epoch 42\n",
      "---------------------EPOCH----------------------------  43\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [43/200],Train Loss: 0.3872, Train Accuracy: 0.9230262073512444, Train F1: 0.9230262073512444, train roc: 0.9753466652760454\n",
      "Epoch [43/200],Val Loss: 0.3871 , Val Accuracy: 0.924851680949242, Val F1: 0.9241516966067865, val roc: 0.9765650902602845\n",
      "No improvement in the last 8 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153]\n",
      "Checkpoint saved at epoch 43\n",
      "---------------------EPOCH----------------------------  44\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [44/200],Train Loss: 0.3847, Train Accuracy: 0.9251751133086115, Train F1: 0.9251195777667822, train roc: 0.9762157799757247\n",
      "Epoch [44/200],Val Loss: 0.3826 , Val Accuracy: 0.9301022090339598, Val F1: 0.9321817018554064, val roc: 0.9795281880116812\n",
      "The best weight is:  3\n",
      "New best model saved with validation accuracy: 0.9301 and validation loss: 0.3826\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153]\n",
      "Checkpoint saved at epoch 44\n",
      "---------------------EPOCH----------------------------  45\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [45/200],Train Loss: 0.3838, Train Accuracy: 0.9246806757313556, Train F1: 0.9247612775765559, train roc: 0.9765490856388437\n",
      "Epoch [45/200],Val Loss: 0.3804 , Val Accuracy: 0.9284536762281569, Val F1: 0.9266644136532612, val roc: 0.9787937673821578\n",
      "The best weight is:  4\n",
      "New best model saved with validation accuracy: 0.9285 and validation loss: 0.3804\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.3858259274771339, 0.3842036059028224, 0.3871948312771948, 0.38466457144210214, 0.3837578629192553]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032]\n",
      "Checkpoint saved at epoch 45\n",
      "---------------------EPOCH----------------------------  46\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [46/200],Train Loss: 0.3845, Train Accuracy: 0.9258282511949892, Train F1: 0.9255952380952381, train roc: 0.9763049224867667\n",
      "Epoch [46/200],Val Loss: 0.3756 , Val Accuracy: 0.9340804218852999, Val F1: 0.9337748344370861, val roc: 0.9822618975713175\n",
      "The best weight is:  0\n",
      "New best model saved with validation accuracy: 0.9341 and validation loss: 0.3756\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334]\n",
      "Checkpoint saved at epoch 46\n",
      "---------------------EPOCH----------------------------  47\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [47/200],Train Loss: 0.3843, Train Accuracy: 0.924756881490028, Train F1: 0.9247630819942316, train roc: 0.9766414209504769\n",
      "Epoch [47/200],Val Loss: 0.3832 , Val Accuracy: 0.926829268292683, Val F1: 0.9275456919060053, val roc: 0.9770934897789891\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334]\n",
      "Checkpoint saved at epoch 47\n",
      "---------------------EPOCH----------------------------  48\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [48/200],Train Loss: 0.3864, Train Accuracy: 0.9217900115378276, Train F1: 0.9215637656004628, train roc: 0.9772597973255571\n",
      "Epoch [48/200],Val Loss: 0.3805 , Val Accuracy: 0.932762030323006, Val F1: 0.9341085271317828, val roc: 0.9793978505089973\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334]\n",
      "Checkpoint saved at epoch 48\n",
      "---------------------EPOCH----------------------------  49\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [49/200],Train Loss: 0.3836, Train Accuracy: 0.926576019777503, Train F1: 0.9262844378257632, train roc: 0.9775032326887224\n",
      "Epoch [49/200],Val Loss: 0.3749 , Val Accuracy: 0.9357072205736894, Val F1: 0.9352804513773646, val roc: 0.9806548214344727\n",
      "The best weight is:  3\n",
      "New best model saved with validation accuracy: 0.9357 and validation loss: 0.3749\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334]\n",
      "Checkpoint saved at epoch 49\n",
      "---------------------EPOCH----------------------------  50\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [50/200],Train Loss: 0.3822, Train Accuracy: 0.9276473011948908, Train F1: 0.9275338395510069, train roc: 0.9776916907540593\n",
      "Epoch [50/200],Val Loss: 0.3776 , Val Accuracy: 0.9320804484009232, Val F1: 0.9332036316472114, val roc: 0.9809111511923791\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.3844792333088423, 0.38429163866921473, 0.3864132012191572, 0.38355586779745, 0.382242067079795]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312]\n",
      "Checkpoint saved at epoch 50\n",
      "---------------------EPOCH----------------------------  51\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [51/200],Train Loss: 0.3831, Train Accuracy: 0.9261579034119004, Train F1: 0.9260359914148918, train roc: 0.9778600800483824\n",
      "Epoch [51/200],Val Loss: 0.3770 , Val Accuracy: 0.9314436387607119, Val F1: 0.9314436387607119, val roc: 0.9802375972770043\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478]\n",
      "Checkpoint saved at epoch 51\n",
      "---------------------EPOCH----------------------------  52\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [52/200],Train Loss: 0.3843, Train Accuracy: 0.9255810120323059, Train F1: 0.9253657327051822, train roc: 0.9779858119142026\n",
      "Epoch [52/200],Val Loss: 0.3798 , Val Accuracy: 0.9284772577455505, Val F1: 0.9277870216306155, val roc: 0.9806625764951729\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478]\n",
      "Checkpoint saved at epoch 52\n",
      "---------------------EPOCH----------------------------  53\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [53/200],Train Loss: 0.3821, Train Accuracy: 0.9278061644964563, Train F1: 0.9275673887878287, train roc: 0.978274794165009\n",
      "Epoch [53/200],Val Loss: 0.3776 , Val Accuracy: 0.9340804218852999, Val F1: 0.9348958333333334, val roc: 0.9805928329731729\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478]\n",
      "Checkpoint saved at epoch 53\n",
      "---------------------EPOCH----------------------------  54\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [54/200],Train Loss: 0.3806, Train Accuracy: 0.9302018953440462, Train F1: 0.9302018953440462, train roc: 0.9781577156600776\n",
      "Epoch [54/200],Val Loss: 0.3804 , Val Accuracy: 0.9287833827893175, Val F1: 0.9289005924950626, val roc: 0.9800275853432427\n",
      "No improvement in the last 5 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478]\n",
      "Checkpoint saved at epoch 54\n",
      "---------------------EPOCH----------------------------  55\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [55/200],Train Loss: 0.3815, Train Accuracy: 0.9282241450350227, Train F1: 0.9282714321007988, train roc: 0.9785558054808539\n",
      "Epoch [55/200],Val Loss: 0.3768 , Val Accuracy: 0.9340586877678866, Val F1: 0.9351070733290071, val roc: 0.979899963996431\n",
      "No improvement in the last 6 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.38308710330411005, 0.3842939268601568, 0.3820722393299404, 0.380598352614202, 0.3815378968652926]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047]\n",
      "Checkpoint saved at epoch 55\n",
      "---------------------EPOCH----------------------------  56\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [56/200],Train Loss: 0.3868, Train Accuracy: 0.9226965551343332, Train F1: 0.9227729293594599, train roc: 0.9760520188698864\n",
      "Epoch [56/200],Val Loss: 0.3743 , Val Accuracy: 0.9353988134475939, Val F1: 0.9365695792880259, val roc: 0.9826714506522214\n",
      "The best weight is:  0\n",
      "New best model saved with validation accuracy: 0.9354 and validation loss: 0.3743\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463]\n",
      "Checkpoint saved at epoch 56\n",
      "---------------------EPOCH----------------------------  57\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [57/200],Train Loss: 0.3813, Train Accuracy: 0.9292895994725564, Train F1: 0.9293710898913401, train roc: 0.9788412531685287\n",
      "Epoch [57/200],Val Loss: 0.3853 , Val Accuracy: 0.9222148978246539, Val F1: 0.9216987392169873, val roc: 0.9773894108910267\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463]\n",
      "Checkpoint saved at epoch 57\n",
      "---------------------EPOCH----------------------------  58\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [58/200],Train Loss: 0.3833, Train Accuracy: 0.9260754903576727, Train F1: 0.9258861439312567, train roc: 0.9776437576668796\n",
      "Epoch [58/200],Val Loss: 0.3829 , Val Accuracy: 0.9294660514172709, Val F1: 0.9296977660972405, val roc: 0.9785279032750775\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463]\n",
      "Checkpoint saved at epoch 58\n",
      "---------------------EPOCH----------------------------  59\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [59/200],Train Loss: 0.3844, Train Accuracy: 0.9255047383601154, Train F1: 0.9253509496284061, train roc: 0.9773640078668882\n",
      "Epoch [59/200],Val Loss: 0.3861 , Val Accuracy: 0.9244971974942301, Val F1: 0.9235392320534223, val roc: 0.980434799623615\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463]\n",
      "Checkpoint saved at epoch 59\n",
      "---------------------EPOCH----------------------------  60\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [60/200],Train Loss: 0.3845, Train Accuracy: 0.9249278945199835, Train F1: 0.9247294059324134, train roc: 0.977236503952404\n",
      "Epoch [60/200],Val Loss: 0.3790 , Val Accuracy: 0.9324101549620838, Val F1: 0.9325435998683779, val roc: 0.9811587844360223\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.38677854412480406, 0.38130208661681725, 0.3833100052256333, 0.38441644797199653, 0.38452212010559284]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926]\n",
      "Checkpoint saved at epoch 60\n",
      "---------------------EPOCH----------------------------  61\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [61/200],Train Loss: 0.3852, Train Accuracy: 0.9248392945442558, Train F1: 0.9247524752475247, train roc: 0.976085774670077\n",
      "Epoch [61/200],Val Loss: 0.3800 , Val Accuracy: 0.930784442979565, Val F1: 0.930921052631579, val roc: 0.9795631926281314\n",
      "No improvement in the last 5 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322]\n",
      "Checkpoint saved at epoch 61\n",
      "---------------------EPOCH----------------------------  62\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [62/200],Train Loss: 0.3824, Train Accuracy: 0.927888577550684, Train F1: 0.9279064019115103, train roc: 0.9781912944049401\n",
      "Epoch [62/200],Val Loss: 0.3845 , Val Accuracy: 0.9264996704021095, Val F1: 0.9263296993723158, val roc: 0.9782343721279683\n",
      "No improvement in the last 6 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322]\n",
      "Checkpoint saved at epoch 62\n",
      "---------------------EPOCH----------------------------  63\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [63/200],Train Loss: 0.3828, Train Accuracy: 0.926734794791495, Train F1: 0.9267890965988635, train roc: 0.9789354569811328\n",
      "Epoch [63/200],Val Loss: 0.3798 , Val Accuracy: 0.9284772577455505, Val F1: 0.9274974941530238, val roc: 0.978363647503638\n",
      "No improvement in the last 7 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322]\n",
      "Checkpoint saved at epoch 63\n",
      "---------------------EPOCH----------------------------  64\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [64/200],Train Loss: 0.3845, Train Accuracy: 0.9255871446229913, Train F1: 0.9257462379738508, train roc: 0.9764242572964889\n",
      "Epoch [64/200],Val Loss: 0.3708 , Val Accuracy: 0.9409825255522585, Val F1: 0.940787297386702, val roc: 0.9815142544565287\n",
      "The best weight is:  3\n",
      "New best model saved with validation accuracy: 0.9410 and validation loss: 0.3708\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322]\n",
      "Checkpoint saved at epoch 64\n",
      "---------------------EPOCH----------------------------  65\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [65/200],Train Loss: 0.3848, Train Accuracy: 0.9255047383601154, Train F1: 0.9254863171777118, train roc: 0.9774797501292696\n",
      "Epoch [65/200],Val Loss: 0.3774 , Val Accuracy: 0.9347181008902077, Val F1: 0.935378590078329, val roc: 0.9805543766947331\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.3852098171648226, 0.3824277731933092, 0.3827821995082654, 0.38445203367032504, 0.38481108358031824]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688, 0.3839365814234081]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859, 0.3785055197775364]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665, 0.9322923995139382]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751, 0.9261361057818922]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108, 0.93218282672439]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174, 0.9774233066963817]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926, 0.9796459686821999]\n",
      "Checkpoint saved at epoch 65\n",
      "---------------------EPOCH----------------------------  66\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [66/200],Train Loss: 0.3825, Train Accuracy: 0.9268172078457227, Train F1: 0.9267930750206101, train roc: 0.9783509179091812\n",
      "Epoch [66/200],Val Loss: 0.3848 , Val Accuracy: 0.9274884640738299, Val F1: 0.927007299270073, val roc: 0.9789943809751839\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082]\n",
      "Checkpoint saved at epoch 66\n",
      "---------------------EPOCH----------------------------  67\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [67/200],Train Loss: 0.3814, Train Accuracy: 0.9281358167133674, Train F1: 0.928052805280528, train roc: 0.9787065559795186\n",
      "Epoch [67/200],Val Loss: 0.3855 , Val Accuracy: 0.9241924851680949, Val F1: 0.9242424242424242, val roc: 0.9747919535529871\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082]\n",
      "Checkpoint saved at epoch 67\n",
      "---------------------EPOCH----------------------------  68\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [68/200],Train Loss: 0.3845, Train Accuracy: 0.9252513598153947, Train F1: 0.9254540971480234, train roc: 0.9767760094689029\n",
      "Epoch [68/200],Val Loss: 0.3821 , Val Accuracy: 0.9284772577455505, Val F1: 0.9289689034369886, val roc: 0.981068001454837\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082]\n",
      "Checkpoint saved at epoch 68\n",
      "---------------------EPOCH----------------------------  69\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [69/200],Train Loss: 0.3859, Train Accuracy: 0.9257519571487433, Train F1: 0.9257397181241241, train roc: 0.9752641591005471\n",
      "Epoch [69/200],Val Loss: 0.3778 , Val Accuracy: 0.9304319155951204, Val F1: 0.9307969826172516, val roc: 0.9811846565659552\n",
      "No improvement in the last 5 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082]\n",
      "Checkpoint saved at epoch 69\n",
      "---------------------EPOCH----------------------------  70\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [70/200],Train Loss: 0.3842, Train Accuracy: 0.9253399258343634, Train F1: 0.9253091508656224, train roc: 0.9770703875934292\n",
      "Epoch [70/200],Val Loss: 0.3753 , Val Accuracy: 0.9350478074513683, Val F1: 0.9354310062274664, val roc: 0.9798325660108916\n",
      "No improvement in the last 6 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.3824770638817235, 0.38141049648586073, 0.384503594197725, 0.38594734260910435, 0.3842132419347763]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688, 0.3839365814234081, 0.383710347821838]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859, 0.3785055197775364, 0.38109686101476353]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665, 0.9322923995139382, 0.9291275860067927]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751, 0.9261361057818922, 0.9262697692877817]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108, 0.93218282672439, 0.9292893231588408]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174, 0.9774233066963817, 0.9772336060103157]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926, 0.9796459686821999, 0.979174311711971]\n",
      "Checkpoint saved at epoch 70\n",
      "---------------------EPOCH----------------------------  71\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [71/200],Train Loss: 0.3819, Train Accuracy: 0.9269820339541783, Train F1: 0.9267526455026456, train roc: 0.9780855307589507\n",
      "Epoch [71/200],Val Loss: 0.3727 , Val Accuracy: 0.9380355965721819, Val F1: 0.9383202099737532, val roc: 0.9828617787683337\n",
      "No improvement in the last 7 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184]\n",
      "Checkpoint saved at epoch 71\n",
      "---------------------EPOCH----------------------------  72\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [72/200],Train Loss: 0.3813, Train Accuracy: 0.9288775342014175, Train F1: 0.9289536511072692, train roc: 0.9779350899190673\n",
      "Epoch [72/200],Val Loss: 0.3837 , Val Accuracy: 0.9274884640738299, Val F1: 0.9274884640738299, val roc: 0.9767436858212941\n",
      "No improvement in the last 8 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184]\n",
      "Checkpoint saved at epoch 72\n",
      "---------------------EPOCH----------------------------  73\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [73/200],Train Loss: 0.3860, Train Accuracy: 0.9236855117850667, Train F1: 0.9234963648380702, train roc: 0.9745937139663625\n",
      "Epoch [73/200],Val Loss: 0.3794 , Val Accuracy: 0.930784442979565, Val F1: 0.9308300395256918, val roc: 0.9807807711243568\n",
      "No improvement in the last 9 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184]\n",
      "Checkpoint saved at epoch 73\n",
      "---------------------EPOCH----------------------------  74\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [74/200],Train Loss: 0.3843, Train Accuracy: 0.9261639884631232, Train F1: 0.9260604060075921, train roc: 0.97654765957248\n",
      "Epoch [74/200],Val Loss: 0.3736 , Val Accuracy: 0.9353775140125289, Val F1: 0.9351422898742555, val roc: 0.9844317175789601\n",
      "No improvement in the last 10 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184]\n",
      "Checkpoint saved at epoch 74\n",
      "---------------------EPOCH----------------------------  75\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [75/200],Train Loss: 0.3842, Train Accuracy: 0.9257519571487433, Train F1: 0.9258863206383153, train roc: 0.977009487768914\n",
      "Epoch [75/200],Val Loss: 0.3767 , Val Accuracy: 0.9343883943290472, Val F1: 0.9343883943290472, val roc: 0.9814575097009617\n",
      "No improvement in the last 11 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.38192619508818576, 0.3813440087594484, 0.38597850846616844, 0.3843061608703513, 0.3841882426487772]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688, 0.3839365814234081, 0.383710347821838, 0.3835486231665862]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859, 0.3785055197775364, 0.38109686101476353, 0.3772349633276463]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665, 0.9322923995139382, 0.9291275860067927, 0.9332148823934305]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751, 0.9261361057818922, 0.9262697692877817, 0.9262298776187785]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108, 0.93218282672439, 0.9292893231588408, 0.9332338795553156]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174, 0.9774233066963817, 0.9772336060103157, 0.9768342963971548]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926, 0.9796459686821999, 0.979174311711971, 0.9812550925987813]\n",
      "Checkpoint saved at epoch 75\n",
      "---------------------EPOCH----------------------------  76\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [76/200],Train Loss: 0.3822, Train Accuracy: 0.9278061644964563, Train F1: 0.9276750330250991, train roc: 0.9783335577833691\n",
      "Epoch [76/200],Val Loss: 0.3699 , Val Accuracy: 0.9413315754779169, Val F1: 0.9420949902407287, val roc: 0.983442540245923\n",
      "The best weight is:  0\n",
      "New best model saved with validation accuracy: 0.9413 and validation loss: 0.3699\n",
      "Improvement found, counter reset to 0\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058]\n",
      "Checkpoint saved at epoch 76\n",
      "---------------------EPOCH----------------------------  77\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [77/200],Train Loss: 0.3819, Train Accuracy: 0.9268172078457227, Train F1: 0.9264169705004971, train roc: 0.9807611635457245\n",
      "Epoch [77/200],Val Loss: 0.3801 , Val Accuracy: 0.9324324324324325, Val F1: 0.9326765188834154, val roc: 0.9772025590875375\n",
      "No improvement in the last 1 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058]\n",
      "Checkpoint saved at epoch 77\n",
      "---------------------EPOCH----------------------------  78\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [78/200],Train Loss: 0.3846, Train Accuracy: 0.9262403164661283, Train F1: 0.9262828432583807, train roc: 0.9765468639584745\n",
      "Epoch [78/200],Val Loss: 0.3810 , Val Accuracy: 0.928806855636124, Val F1: 0.9291338582677166, val roc: 0.9787601644122056\n",
      "No improvement in the last 2 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058]\n",
      "Checkpoint saved at epoch 78\n",
      "---------------------EPOCH----------------------------  79\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [79/200],Train Loss: 0.3829, Train Accuracy: 0.9266584260403791, Train F1: 0.9265555372173627, train roc: 0.9774780524312178\n",
      "Epoch [79/200],Val Loss: 0.3808 , Val Accuracy: 0.9294427959116386, Val F1: 0.9290450928381963, val roc: 0.9793120796322418\n",
      "No improvement in the last 3 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058]\n",
      "Checkpoint saved at epoch 79\n",
      "---------------------EPOCH----------------------------  80\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [80/200],Train Loss: 0.3809, Train Accuracy: 0.9300370828182942, Train F1: 0.9300486116832825, train roc: 0.977824247017946\n",
      "Epoch [80/200],Val Loss: 0.3758 , Val Accuracy: 0.9357072205736894, Val F1: 0.9357072205736894, val roc: 0.9806026423488936\n",
      "No improvement in the last 4 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.38218095506492417, 0.38190729853354, 0.38458296264472763, 0.3829352361591239, 0.3809067200673254]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688, 0.3839365814234081, 0.383710347821838, 0.3835486231665862, 0.3825026344939282]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859, 0.3785055197775364, 0.38109686101476353, 0.3772349633276463, 0.3775123888005813]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665, 0.9322923995139382, 0.9291275860067927, 0.9332148823934305, 0.9335441760063603]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751, 0.9261361057818922, 0.9262697692877817, 0.9262298776187785, 0.9273957991369244]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108, 0.93218282672439, 0.9292893231588408, 0.9332338795553156, 0.9337315361607492]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174, 0.9774233066963817, 0.9772336060103157, 0.9768342963971548, 0.9781887769473464]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926, 0.9796459686821999, 0.979174311711971, 0.9812550925987813, 0.9798639971453603]\n",
      "Checkpoint saved at epoch 80\n",
      "---------------------EPOCH----------------------------  81\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [81/200],Train Loss: 0.3832, Train Accuracy: 0.9269820339541783, Train F1: 0.9272577996715927, train roc: 0.9772247238945342\n",
      "Epoch [81/200],Val Loss: 0.3815 , Val Accuracy: 0.9274884640738299, Val F1: 0.927007299270073, val roc: 0.9774893548789395\n",
      "No improvement in the last 5 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962]\n",
      "Checkpoint saved at epoch 81\n",
      "---------------------EPOCH----------------------------  82\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [82/200],Train Loss: 0.3814, Train Accuracy: 0.9287951211471898, Train F1: 0.9286893364146582, train roc: 0.9791258070930322\n",
      "Epoch [82/200],Val Loss: 0.3841 , Val Accuracy: 0.926829268292683, Val F1: 0.9261968085106382, val roc: 0.976239620490951\n",
      "No improvement in the last 6 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962]\n",
      "Checkpoint saved at epoch 82\n",
      "---------------------EPOCH----------------------------  83\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [83/200],Train Loss: 0.3823, Train Accuracy: 0.927888577550684, Train F1: 0.9279657528607886, train roc: 0.9779216826857521\n",
      "Epoch [83/200],Val Loss: 0.3762 , Val Accuracy: 0.9353988134475939, Val F1: 0.9350563286944997, val roc: 0.981269627586974\n",
      "No improvement in the last 7 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962]\n",
      "Checkpoint saved at epoch 83\n",
      "---------------------EPOCH----------------------------  84\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [84/200],Train Loss: 0.3820, Train Accuracy: 0.9274000824062629, Train F1: 0.9274598600247015, train roc: 0.9781872012798416\n",
      "Epoch [84/200],Val Loss: 0.3805 , Val Accuracy: 0.9291130893504781, Val F1: 0.9285476902625457, val roc: 0.978661580365358\n",
      "No improvement in the last 8 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962]\n",
      "Checkpoint saved at epoch 84\n",
      "---------------------EPOCH----------------------------  85\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [85/200],Train Loss: 0.3878, Train Accuracy: 0.9215492377420684, Train F1: 0.9216847647252386, train roc: 0.9756461004174544\n",
      "Epoch [85/200],Val Loss: 0.3772 , Val Accuracy: 0.9330695680844049, Val F1: 0.9337251061051257, val roc: 0.9805717697232595\n",
      "No improvement in the last 9 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.38324880129412603, 0.3814286446885059, 0.3822798614439211, 0.38197382453240847, 0.38775858659493295]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688, 0.3839365814234081, 0.383710347821838, 0.3835486231665862, 0.3825026344939282, 0.3833379437107789]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859, 0.3785055197775364, 0.38109686101476353, 0.3772349633276463, 0.3775123888005813, 0.3799145085116228]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665, 0.9322923995139382, 0.9291275860067927, 0.9332148823934305, 0.9335441760063603, 0.9303798406497978]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751, 0.9261361057818922, 0.9262697692877817, 0.9262298776187785, 0.9273957991369244, 0.9266115027393959]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108, 0.93218282672439, 0.9292893231588408, 0.9332338795553156, 0.9337315361607492, 0.9301066465685764]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174, 0.9774233066963817, 0.9772336060103157, 0.9768342963971548, 0.9781887769473464, 0.9776211030741229]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926, 0.9796459686821999, 0.979174311711971, 0.9812550925987813, 0.9798639971453603, 0.9788463906090964]\n",
      "Checkpoint saved at epoch 85\n",
      "---------------------EPOCH----------------------------  86\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [86/200],Train Loss: 0.3830, Train Accuracy: 0.9259106642492171, Train F1: 0.9257944696657038, train roc: 0.9779778653777393\n",
      "Epoch [86/200],Val Loss: 0.3745 , Val Accuracy: 0.9360580092287409, Val F1: 0.9360580092287409, val roc: 0.9821184996756166\n",
      "No improvement in the last 10 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766]\n",
      "Checkpoint saved at epoch 86\n",
      "---------------------EPOCH----------------------------  87\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [87/200],Train Loss: 0.3827, Train Accuracy: 0.9268996208999506, Train F1: 0.9269297306203147, train roc: 0.9772481016539418\n",
      "Epoch [87/200],Val Loss: 0.3796 , Val Accuracy: 0.930784442979565, Val F1: 0.9304635761589405, val roc: 0.9790795506344487\n",
      "No improvement in the last 11 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766]\n",
      "Checkpoint saved at epoch 87\n",
      "---------------------EPOCH----------------------------  88\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [88/200],Train Loss: 0.3855, Train Accuracy: 0.9236855117850667, Train F1: 0.9236855117850667, train roc: 0.9764987636411806\n",
      "Epoch [88/200],Val Loss: 0.3747 , Val Accuracy: 0.9360580092287409, Val F1: 0.9357615894039735, val roc: 0.9815010196459464\n",
      "No improvement in the last 12 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766]\n",
      "Checkpoint saved at epoch 88\n",
      "---------------------EPOCH----------------------------  89\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [89/200],Train Loss: 0.3844, Train Accuracy: 0.9245158632056036, Train F1: 0.9243600330305533, train roc: 0.9767473496081278\n",
      "Epoch [89/200],Val Loss: 0.3722 , Val Accuracy: 0.9376854599406528, Val F1: 0.9378084896347483, val roc: 0.9832415996020475\n",
      "No improvement in the last 13 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766]\n",
      "Checkpoint saved at epoch 89\n",
      "---------------------EPOCH----------------------------  90\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [90/200],Train Loss: 0.3831, Train Accuracy: 0.927070457354759, Train F1: 0.9272024348112199, train roc: 0.9773091790106065\n",
      "Epoch [90/200],Val Loss: 0.3758 , Val Accuracy: 0.9350478074513683, Val F1: 0.9353462422054479, val roc: 0.9794160029776865\n",
      "No improvement in the last 14 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.38296640311416824, 0.38266857423280415, 0.3855122470542004, 0.38440794505571063, 0.3830705837199562]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688, 0.3839365814234081, 0.383710347821838, 0.3835486231665862, 0.3825026344939282, 0.3833379437107789, 0.3837251506353679]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859, 0.3785055197775364, 0.38109686101476353, 0.3772349633276463, 0.3775123888005813, 0.3799145085116228, 0.3753780846794446]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766, 0.9256164234989195]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665, 0.9322923995139382, 0.9291275860067927, 0.9332148823934305, 0.9335441760063603, 0.9303798406497978, 0.9351267457658136]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751, 0.9261361057818922, 0.9262697692877817, 0.9262298776187785, 0.9273957991369244, 0.9266115027393959, 0.9255944359825717]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108, 0.93218282672439, 0.9292893231588408, 0.9332338795553156, 0.9337315361607492, 0.9301066465685764, 0.9350875813263702]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174, 0.9774233066963817, 0.9772336060103157, 0.9768342963971548, 0.9781887769473464, 0.9776211030741229, 0.9771562518583192]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926, 0.9796459686821999, 0.979174311711971, 0.9812550925987813, 0.9798639971453603, 0.9788463906090964, 0.9810713345071491]\n",
      "Checkpoint saved at epoch 90\n",
      "---------------------EPOCH----------------------------  91\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [91/200],Train Loss: 0.3852, Train Accuracy: 0.9231910334597, Train F1: 0.9232416405863945, train roc: 0.976627212271604\n",
      "Epoch [91/200],Val Loss: 0.3762 , Val Accuracy: 0.9353988134475939, Val F1: 0.9354413702239789, val roc: 0.9827620520499597\n",
      "No improvement in the last 15 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766, 0.9256164234989195]\n",
      "Checkpoint saved at epoch 91\n",
      "---------------------EPOCH----------------------------  92\n",
      "Fold 2\n",
      "-------\n",
      "Epoch [92/200],Train Loss: 0.3797, Train Accuracy: 0.9300313169606066, Train F1: 0.9300255501524767, train roc: 0.9785212454659574\n",
      "Epoch [92/200],Val Loss: 0.3861 , Val Accuracy: 0.9225444957152275, Val F1: 0.9224678323985483, val roc: 0.9777322622234755\n",
      "No improvement in the last 16 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766, 0.9256164234989195]\n",
      "Checkpoint saved at epoch 92\n",
      "---------------------EPOCH----------------------------  93\n",
      "Fold 3\n",
      "-------\n",
      "Epoch [93/200],Train Loss: 0.3847, Train Accuracy: 0.9258282511949892, Train F1: 0.926084099868594, train roc: 0.9774874350316309\n",
      "Epoch [93/200],Val Loss: 0.3781 , Val Accuracy: 0.9317732366512854, Val F1: 0.9320643255661306, val roc: 0.979605560188225\n",
      "No improvement in the last 17 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766, 0.9256164234989195]\n",
      "Checkpoint saved at epoch 93\n",
      "---------------------EPOCH----------------------------  94\n",
      "Fold 4\n",
      "-------\n",
      "Epoch [94/200],Train Loss: 0.3864, Train Accuracy: 0.9222084878450763, Train F1: 0.9222277146152579, train roc: 0.9767399068998687\n",
      "Epoch [94/200],Val Loss: 0.3785 , Val Accuracy: 0.9320804484009232, Val F1: 0.9319682959048878, val roc: 0.9816507897304602\n",
      "No improvement in the last 18 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766, 0.9256164234989195]\n",
      "Checkpoint saved at epoch 94\n",
      "---------------------EPOCH----------------------------  95\n",
      "Fold 5\n",
      "-------\n",
      "Epoch [95/200],Train Loss: 0.3845, Train Accuracy: 0.9245982694684796, Train F1: 0.9245734069738687, train roc: 0.9769747868207347\n",
      "Epoch [95/200],Val Loss: 0.3787 , Val Accuracy: 0.9307616221562809, Val F1: 0.930784442979565, val roc: 0.9784204695074121\n",
      "No improvement in the last 19 epochs\n",
      "-------------------------------- Fold train accuracy:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766, 0.9256164234989195]\n",
      "-----------------fold5--------------------------------\n",
      "all_train_loss:  [0.38518024886909286, 0.379708678628269, 0.38474519048866473, 0.3863742982086382, 0.3845193746842836]\n",
      "fold_train_loss:  [0.5298441165685654, 0.4613456497380608, 0.43324580697636855, 0.4175452318630721, 0.40388768472169573, 0.3963128860373246, 0.39137010762566016, 0.3878969944778242, 0.38512935980370167, 0.3841964016148919, 0.3823179037947404, 0.3840658408089688, 0.3839365814234081, 0.383710347821838, 0.3835486231665862, 0.3825026344939282, 0.3833379437107789, 0.3837251506353679, 0.3841055581757897]\n",
      "fold_val_loss:  [0.6874200439701478, 0.5196011422822873, 0.5408175534258286, 0.5239079086730878, 0.45566045343875883, 0.4633525238682827, 0.4141861028969288, 0.3968378723909457, 0.38531755879521373, 0.37835681910316155, 0.37834494647880396, 0.3814865174392859, 0.3785055197775364, 0.38109686101476353, 0.3772349633276463, 0.3775123888005813, 0.3799145085116228, 0.3753780846794446, 0.37951333733896414]\n",
      "fold_train_accuracies:  [0.7682609039058355, 0.842694679362963, 0.873961402981906, 0.8905919362612617, 0.9048160002075438, 0.9129911728046565, 0.9178698938627166, 0.9220068933579153, 0.9241824648790334, 0.9253196930390478, 0.9275942240639463, 0.9256988555689322, 0.9261109099739082, 0.9262592534715184, 0.9262922051105058, 0.9275118395333962, 0.9265230105600766, 0.9256164234989195, 0.9251714717857704]\n",
      "fold_val_accuracies:  [0.611097331680671, 0.780390392563802, 0.7616025738411206, 0.7796055518498886, 0.8502117881071346, 0.8431558503571243, 0.894254477391193, 0.9120506335386557, 0.9249082765909863, 0.9322918778951204, 0.9313686777897532, 0.9287974230291665, 0.9322923995139382, 0.9291275860067927, 0.9332148823934305, 0.9335441760063603, 0.9303798406497978, 0.9351267457658136, 0.9305117232742621]\n",
      "fold_train_f1:  [0.7628647353174969, 0.84233408147104, 0.8737870875391215, 0.8902748510858327, 0.9045717558765871, 0.9129567090289946, 0.917788612460362, 0.9218519265078708, 0.9241249339021671, 0.9251480726133405, 0.9274884880705496, 0.9256221037485751, 0.9261361057818922, 0.9262697692877817, 0.9262298776187785, 0.9273957991369244, 0.9266115027393959, 0.9255944359825717, 0.9252304824393184]\n",
      "fold_val_f1:  [0.5619744930391184, 0.7373078090933042, 0.7448475521536132, 0.7380673739308489, 0.856883441145356, 0.8260002072589379, 0.8876741737974598, 0.9143088327242956, 0.9256615327563489, 0.93278262729989, 0.9316268319097463, 0.9288097833048108, 0.93218282672439, 0.9292893231588408, 0.9332338795553156, 0.9337315361607492, 0.9301066465685764, 0.9350875813263702, 0.9305452534146221]\n",
      "fold_train_roc:  [0.8432046646535436, 0.9184472934743072, 0.9428556126908401, 0.9554708436236936, 0.9650410015748936, 0.9694861959587063, 0.9726411485550142, 0.9746752428413122, 0.9761615918304081, 0.9770802128411165, 0.978166841453705, 0.9774275083049174, 0.9774233066963817, 0.9772336060103157, 0.9768342963971548, 0.9781887769473464, 0.9776211030741229, 0.9771562518583192, 0.9772701172979591]\n",
      "fold_val_roc:  [0.7425970802234729, 0.9021090797856409, 0.9105041987762619, 0.9336658654136787, 0.9564250280482076, 0.9579345770197933, 0.9706523386685074, 0.9752205553537598, 0.9771831155849032, 0.9800638420972312, 0.9802841112170047, 0.9800364697755926, 0.9796459686821999, 0.979174311711971, 0.9812550925987813, 0.9798639971453603, 0.9788463906090964, 0.9810713345071491, 0.9800342267399065]\n",
      "Checkpoint saved at epoch 95\n",
      "---------------------EPOCH----------------------------  96\n",
      "Fold 1\n",
      "-------\n",
      "Epoch [96/200],Train Loss: 0.3813, Train Accuracy: 0.9289599472556453, Train F1: 0.9290651744568796, train roc: 0.9789516353143428\n",
      "Epoch [96/200],Val Loss: 0.3807 , Val Accuracy: 0.9284772577455505, Val F1: 0.9289689034369886, val roc: 0.9800314084845493\n",
      "Early stopping triggered after 20 epochs.\n",
      "Early stopping at epoch 96\n",
      "train_accuracies:  [0.9289599472556453]\n",
      "final_train_loss:  0.4011657389716098\n",
      "final_val_loss:  0.42775798051307595\n",
      "final_train_accuracy:  90.74216590742749\n",
      "final_val_accuracy:  88.01204732995281\n",
      "final_train_f1:  0.907067325253274\n",
      "final_val_f1:  0.8719545304379791\n",
      "final_train_roc:  0.96356686256992\n",
      "final_val_roc:  0.9553299496221535\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import random\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "net = ResNet18_CBAM_ECA().to(device)\n",
    "\n",
    "\n",
    "# Set Kaggle directories for working and output storage\n",
    "working_dir = '/kaggle/working'\n",
    "output_dir = '/kaggle/output'\n",
    "\n",
    "# Create directories for working storage\n",
    "save_dir = os.path.join(working_dir, 'resnet18_cbam_eca/model')\n",
    "checkpoint_dir = os.path.join(working_dir, 'checkpoints_resnet18')\n",
    "\n",
    "# Create directories for output storage\n",
    "output_save_dir = os.path.join(output_dir, 'resnet18_cbam_eca/model')\n",
    "output_checkpoint_dir = os.path.join(output_dir, 'checkpoints_resnet18')\n",
    "\n",
    "# Ensure all directories exist\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(output_save_dir, exist_ok=True)\n",
    "os.makedirs(output_checkpoint_dir, exist_ok=True)\n",
    "\n",
    "best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "output_best_model_path = os.path.join(output_save_dir, 'best_model.pth')\n",
    "\n",
    "\n",
    "# Check if any checkpoint file exists in the directory\n",
    "load_PATH = \"/kaggle/input/resnet_cbam_eca_70epoch/pytorch/default/1/checkpoint_epoch.pth\"\n",
    "print(os.path.exists(load_PATH))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training and evaluation\")\n",
    "\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True,random_state=42)\n",
    "\n",
    "\n",
    "model = net.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 200\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "patience = 20\n",
    "early_stopping = EarlyStopping(patience=patience)\n",
    "early_stop = False\n",
    "\n",
    "if os.path.exists(load_PATH):\n",
    "    print(\"Loading model...\")\n",
    "    (model, optimizer, start_epoch, train_acc, val_acc, best_loss, counter,train_accuracies, val_accuracies,all_train_loss,all_val_loss,train_f1_scores,\n",
    "     val_f1_scores,train_roc_aucs,val_roc_aucs,best_acc,fold_train_accuracies,fold_val_accuracies,fold_train_loss,\n",
    "     fold_val_loss,fold_train_f1,fold_val_f1,fold_train_roc,fold_val_roc,track_all_train_loss,track_all_val_loss) = load_checkpoint_f(model, optimizer, load_PATH)\n",
    "\n",
    "    early_stopping.best_loss = best_loss\n",
    "    early_stopping.counter = counter\n",
    "    best_model_wts = model.state_dict()\n",
    "\n",
    "    if (start_epoch+1)% 5 == 0 :\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_f1_scores = []\n",
    "        val_f1_scores = []\n",
    "        train_roc_aucs = []\n",
    "        val_roc_aucs = []\n",
    "        all_train_loss = []\n",
    "        all_val_loss = []\n",
    "\n",
    "    print(\"train_accuracies: \",train_accuracies)\n",
    "    print(\"val_accuracies: \",val_accuracies)\n",
    "    print(\"train_f1_scores: \",train_f1_scores)\n",
    "    print(\"val_f1_scores: \",val_f1_scores)\n",
    "    print('train_roc_aucs: ',train_roc_aucs)\n",
    "    print('val_roc_aucs: ',val_roc_aucs)\n",
    "    print('all_train_loss: ',all_train_loss)\n",
    "    print('all_val_loss: ',all_val_loss)\n",
    "    print(\"best_acc: \",best_acc)\n",
    "    print(\"fold_train_accuracies: \",fold_train_accuracies)\n",
    "    print(\"fold_val_accuracies: \",fold_val_accuracies)\n",
    "    print(\"fold_train_loss: \",fold_train_loss)\n",
    "    print(\"fold_val_loss: \",fold_val_loss)\n",
    "    print(\"fold_train_f1: \",fold_train_f1)\n",
    "    print(\"fold_val_f1: \",fold_val_f1)\n",
    "    print(\"fold_train_roc: \",fold_train_roc)\n",
    "    print(\"fold_val_roc: \",fold_val_roc)\n",
    "    print(\"---------------------------------------------------------------------\")\n",
    "    # print(\"mean(val_loss): \",np.mean(all_val_loss))\n",
    "    print(f\"Model loaded from epoch {start_epoch + 1} with best_loss: {best_loss} and counter: {counter}\")\n",
    "    print(f\"Train accuracy: {train_acc}, Validation accuracy: {val_acc}\")\n",
    "    load_model = False\n",
    "    start_epoch += 1\n",
    "else:\n",
    "    print(\"No model to load.\")\n",
    "    fold_train_loss = []\n",
    "    fold_val_loss = []\n",
    "    fold_train_accuracies = []\n",
    "    fold_val_accuracies = []\n",
    "    fold_train_f1 = []\n",
    "    fold_val_f1 = []\n",
    "    fold_train_roc = []\n",
    "    fold_val_roc = []\n",
    "    track_all_train_loss = []\n",
    "    track_all_val_loss = []\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    train_f1_scores = []\n",
    "    val_f1_scores = []\n",
    "    train_roc_aucs = []\n",
    "    val_roc_aucs = []\n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "    best_acc = 0.0\n",
    "    best_loss = 1e5\n",
    "    best_f1 = 0.0\n",
    "    best_model_wts = 0\n",
    "    start_epoch = 0\n",
    "    fold = 0\n",
    "\n",
    "\n",
    "train_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# Set the seed globally\n",
    "set_seed(42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_dataset_f.image_paths, train_dataset_f.labels)):\n",
    "  # Define the data loaders for the current fold\n",
    "  train_loader = DataLoader(\n",
    "      dataset=train_dataset_f,\n",
    "      batch_size=64,\n",
    "      worker_init_fn=lambda _: np.random.seed(42),\n",
    "      sampler=torch.utils.data.SubsetRandomSampler(train_idx),\n",
    "  )\n",
    "  val_loader = DataLoader(\n",
    "      dataset=train_dataset_f,\n",
    "      batch_size=64,\n",
    "      sampler=torch.utils.data.SubsetRandomSampler(val_idx),\n",
    "  )\n",
    "\n",
    "  train_loaders.append(train_loader)\n",
    "  val_loaders.append(val_loader)\n",
    "\n",
    "  print(f\"Fold {fold + 1}:\")\n",
    "  print(f\"Train_loader: {len(train_loaders[fold])}\")\n",
    "  print(f\"Val_loader: {len(val_loaders[fold])}\")\n",
    "\n",
    "  if (fold+1) % 5 == 0:\n",
    "      break\n",
    "\n",
    "# print size of train_loaders\n",
    "print(len(train_loaders))\n",
    "print(len(val_loaders))\n",
    "\n",
    "for epoch in range(start_epoch,num_epochs):\n",
    "\n",
    "    # if (counter == 20):\n",
    "    #     break\n",
    "    \n",
    "    \n",
    "    print(\"---------------------EPOCH---------------------------- \",epoch+1)\n",
    "    fold = epoch%5\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(\"-------\")\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    true = []\n",
    "    pre = []\n",
    "    proba = []\n",
    "    train_loss = []\n",
    "\n",
    "    for images,labels in train_loaders[fold]:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images.to(device))\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # running_loss += loss.item()\n",
    "        train_loss.append(loss.item())\n",
    "        pred = outputs.argmax(dim=1, keepdim=True)\n",
    "        true.extend(labels.cpu().numpy())\n",
    "        pre.extend(pred.cpu().numpy())\n",
    "        train_probs = torch.nn.functional.softmax(outputs, dim=1)[:, 1]\n",
    "        proba.extend(train_probs.detach().cpu().numpy())\n",
    "        # correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    all_train_loss.append(np.mean(train_loss))\n",
    "    track_all_train_loss.append(np.mean(train_loss))\n",
    "    train_accuracy = accuracy_score(true,pre)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    train_f1 = f1_score(true,pre)\n",
    "    train_f1_scores.append(train_f1)\n",
    "    train_roc = roc_auc_score(true,proba)\n",
    "    train_roc_aucs.append(train_roc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}],Train Loss: {np.mean(train_loss):.4f}, Train Accuracy: {train_accuracy}, Train F1: {train_f1}, train roc: {train_roc}\")\n",
    "\n",
    "\n",
    "\n",
    "    # val the model\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    val_loss = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        val_true = []\n",
    "        val_pre = []\n",
    "        val_proba = []\n",
    "        val_loss = []\n",
    "        for val_images, val_labels in val_loaders[fold]:\n",
    "\n",
    "            outputs = model(val_images.to(device))\n",
    "            loss = criterion(outputs, val_labels.to(device))\n",
    "            running_loss += loss.item()\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            pred = outputs.argmax(dim=1, keepdim=True)\n",
    "            val_true.extend(val_labels.cpu().numpy())\n",
    "            val_pre.extend(pred.cpu().numpy())\n",
    "            val_probs = torch.nn.functional.softmax(outputs, dim=1)[:, 1]\n",
    "            val_proba.extend(val_probs.detach().cpu().numpy())\n",
    "            # correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "        all_val_loss.append(np.mean(val_loss))\n",
    "        track_all_val_loss.append(np.mean(val_loss))\n",
    "        val_accuracy = accuracy_score(val_true,val_pre)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_f1 = f1_score(val_true,val_pre)\n",
    "        val_f1_scores.append(val_f1)\n",
    "        val_roc = roc_auc_score(val_true,val_proba)\n",
    "        val_roc_aucs.append(val_roc)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}],Val Loss: {np.mean(val_loss):.4f} , Val Accuracy: {val_accuracy}, Val F1: {val_f1}, val roc: {val_roc}\")\n",
    "\n",
    "\n",
    "\n",
    "        if np.mean(val_loss) < best_loss:\n",
    "                best_acc = val_accuracy\n",
    "                best_loss = np.mean(val_loss)\n",
    "                #Save the best model\n",
    "                best_model_wts = model.state_dict()\n",
    "                torch.save(best_model_wts, best_model_path)  # Save in working dir\n",
    "                torch.save(best_model_wts, output_best_model_path)  # Save in output dir\n",
    "                print(\"The best weight is: \",fold)\n",
    "                print(f\"New best model saved with validation accuracy: {best_acc:.4f} and validation loss: {best_loss:.4f}\")\n",
    "\n",
    "\n",
    "        optimizer.param_groups[0]['lr'] *= 0.9\n",
    "        early_stop = early_stopping(model, np.mean(val_loss))\n",
    "        print(early_stopping.status)\n",
    "\n",
    "        if early_stop:\n",
    "          print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "          break\n",
    "\n",
    "        print(\"-------------------------------- Fold train accuracy: \",fold_train_accuracies)\n",
    "\n",
    "        if (fold+1)% 5 != 0:\n",
    "            # Save checkpoint\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint_epoch.pth')\n",
    "            output_checkpoint_path = os.path.join(output_checkpoint_dir, 'checkpoint_epoch.pth')\n",
    "\n",
    "            save_checkpoint_f(model, optimizer, checkpoint_path, epoch, fold, train_acc=train_accuracy, val_acc=val_accuracy,\n",
    "                              early_stopping=early_stopping,train_accuracies=train_accuracies, val_accuracies=val_accuracies,train_f1_scores=train_f1_scores, val_f1_scores=val_f1_scores,\n",
    "                              train_roc_aucs=train_roc_aucs,val_roc_aucs=val_roc_aucs,all_train_loss=all_train_loss,all_val_loss=all_val_loss,best_acc=best_acc,\n",
    "                              fold_train_accuracies=fold_train_accuracies,fold_val_accuracies=fold_val_accuracies,fold_train_loss=fold_train_loss,fold_val_loss=fold_val_loss,\n",
    "                              fold_train_f1=fold_train_f1,fold_val_f1=fold_val_f1,fold_train_roc=fold_train_roc,fold_val_roc=fold_val_roc,track_all_train_loss=track_all_train_loss,\n",
    "                              track_all_val_loss=track_all_val_loss)\n",
    "            save_checkpoint_f(model, optimizer, output_checkpoint_path, epoch, fold, train_acc=train_accuracy, val_acc=val_accuracy,\n",
    "                              early_stopping=early_stopping,train_accuracies=train_accuracies, val_accuracies=val_accuracies,train_f1_scores=train_f1_scores, val_f1_scores=val_f1_scores,\n",
    "                              train_roc_aucs=train_roc_aucs,val_roc_aucs=val_roc_aucs,all_train_loss=all_train_loss,all_val_loss=all_val_loss,best_acc=best_acc,\n",
    "                              fold_train_accuracies=fold_train_accuracies,fold_val_accuracies=fold_val_accuracies,fold_train_loss=fold_train_loss,fold_val_loss=fold_val_loss,\n",
    "                              fold_train_f1=fold_train_f1,fold_val_f1=fold_val_f1,fold_train_roc=fold_train_roc,fold_val_roc=fold_val_roc,track_all_train_loss=track_all_train_loss,\n",
    "                              track_all_val_loss=track_all_val_loss)\n",
    "\n",
    "            print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "\n",
    "\n",
    "\n",
    "    if (fold+1) % 5 == 0:\n",
    "      print(\"-----------------fold5--------------------------------\")\n",
    "      fold_train_loss.append(np.mean(all_train_loss))\n",
    "      fold_val_loss.append(np.mean(all_val_loss))\n",
    "      fold_train_accuracies.append(np.mean(train_accuracies))\n",
    "      fold_val_accuracies.append(np.mean(val_accuracies))\n",
    "      fold_train_f1.append(np.mean(train_f1_scores))\n",
    "      fold_val_f1.append(np.mean(val_f1_scores))\n",
    "      fold_train_roc.append(np.mean(train_roc_aucs))\n",
    "      fold_val_roc.append(np.mean(val_roc_aucs))\n",
    "\n",
    "      print(\"all_train_loss: \",all_train_loss)\n",
    "      print(\"fold_train_loss: \",fold_train_loss)\n",
    "      print(\"fold_val_loss: \",fold_val_loss)\n",
    "      print(\"fold_train_accuracies: \",fold_train_accuracies)\n",
    "      print(\"fold_val_accuracies: \",fold_val_accuracies)\n",
    "      print(\"fold_train_f1: \",fold_train_f1)\n",
    "      print(\"fold_val_f1: \",fold_val_f1)\n",
    "      print(\"fold_train_roc: \",fold_train_roc)\n",
    "      print(\"fold_val_roc: \",fold_val_roc)\n",
    "\n",
    "      checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint_epoch.pth')\n",
    "      output_checkpoint_path = os.path.join(output_checkpoint_dir, 'checkpoint_epoch.pth')\n",
    "\n",
    "      save_checkpoint_f(model, optimizer, checkpoint_path, epoch, fold, train_acc=train_accuracy, val_acc=val_accuracy,\n",
    "                              early_stopping=early_stopping,train_accuracies=train_accuracies, val_accuracies=val_accuracies,train_f1_scores=train_f1_scores, val_f1_scores=val_f1_scores,\n",
    "                              train_roc_aucs=train_roc_aucs,val_roc_aucs=val_roc_aucs,all_train_loss=all_train_loss,all_val_loss=all_val_loss,best_acc=best_acc,\n",
    "                              fold_train_accuracies=fold_train_accuracies,fold_val_accuracies=fold_val_accuracies,fold_train_loss=fold_train_loss,fold_val_loss=fold_val_loss,\n",
    "                              fold_train_f1=fold_train_f1,fold_val_f1=fold_val_f1,fold_train_roc=fold_train_roc,fold_val_roc=fold_val_roc,track_all_train_loss=track_all_train_loss,\n",
    "                              track_all_val_loss=track_all_val_loss)\n",
    "      save_checkpoint_f(model, optimizer, output_checkpoint_path, epoch, fold, train_acc=train_accuracy, val_acc=val_accuracy,\n",
    "                              early_stopping=early_stopping,train_accuracies=train_accuracies, val_accuracies=val_accuracies,train_f1_scores=train_f1_scores, val_f1_scores=val_f1_scores,\n",
    "                              train_roc_aucs=train_roc_aucs,val_roc_aucs=val_roc_aucs,all_train_loss=all_train_loss,all_val_loss=all_val_loss,best_acc=best_acc,\n",
    "                              fold_train_accuracies=fold_train_accuracies,fold_val_accuracies=fold_val_accuracies,fold_train_loss=fold_train_loss,fold_val_loss=fold_val_loss,\n",
    "                              fold_train_f1=fold_train_f1,fold_val_f1=fold_val_f1,fold_train_roc=fold_train_roc,fold_val_roc=fold_val_roc,track_all_train_loss=track_all_train_loss,\n",
    "                              track_all_val_loss=track_all_val_loss)\n",
    "\n",
    "      print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "\n",
    "      all_train_loss = []\n",
    "      all_val_loss = []\n",
    "      train_accuracies = []\n",
    "      val_accuracies = []\n",
    "      train_f1_scores = []\n",
    "      val_f1_scores = []\n",
    "      train_roc_aucs = []\n",
    "      val_roc_aucs = []\n",
    "\n",
    "\n",
    "\n",
    "print(\"train_accuracies: \",train_accuracies)\n",
    "\n",
    "if train_accuracies:\n",
    "    fold_train_loss.append(np.mean(all_train_loss))\n",
    "    fold_val_loss.append(np.mean(all_val_loss))\n",
    "    fold_train_accuracies.append(np.mean(train_accuracies))\n",
    "    fold_val_accuracies.append(np.mean(val_accuracies))\n",
    "    fold_train_f1.append(np.mean(train_f1_scores))\n",
    "    fold_val_f1.append(np.mean(val_f1_scores))\n",
    "    fold_train_roc.append(np.mean(train_roc_aucs))\n",
    "    fold_val_roc.append(np.mean(val_roc_aucs))\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'checkpoint_epoch.pth')\n",
    "    output_checkpoint_path = os.path.join(output_checkpoint_dir, 'checkpoint_epoch.pth')\n",
    "\n",
    "    save_checkpoint_f(model, optimizer, checkpoint_path, epoch, fold, train_acc=train_accuracy, val_acc=val_accuracy,\n",
    "                              early_stopping=early_stopping,train_accuracies=train_accuracies, val_accuracies=val_accuracies,train_f1_scores=train_f1_scores, val_f1_scores=val_f1_scores,\n",
    "                              train_roc_aucs=train_roc_aucs,val_roc_aucs=val_roc_aucs,all_train_loss=all_train_loss,all_val_loss=all_val_loss,best_acc=best_acc,\n",
    "                              fold_train_accuracies=fold_train_accuracies,fold_val_accuracies=fold_val_accuracies,fold_train_loss=fold_train_loss,fold_val_loss=fold_val_loss,\n",
    "                              fold_train_f1=fold_train_f1,fold_val_f1=fold_val_f1,fold_train_roc=fold_train_roc,fold_val_roc=fold_val_roc,track_all_train_loss=track_all_train_loss,\n",
    "                              track_all_val_loss=track_all_val_loss)\n",
    "    save_checkpoint_f(model, optimizer, output_checkpoint_path, epoch, fold, train_acc=train_accuracy, val_acc=val_accuracy,\n",
    "                              early_stopping=early_stopping,train_accuracies=train_accuracies, val_accuracies=val_accuracies,train_f1_scores=train_f1_scores, val_f1_scores=val_f1_scores,\n",
    "                              train_roc_aucs=train_roc_aucs,val_roc_aucs=val_roc_aucs,all_train_loss=all_train_loss,all_val_loss=all_val_loss,best_acc=best_acc,\n",
    "                              fold_train_accuracies=fold_train_accuracies,fold_val_accuracies=fold_val_accuracies,fold_train_loss=fold_train_loss,fold_val_loss=fold_val_loss,\n",
    "                              fold_train_f1=fold_train_f1,fold_val_f1=fold_val_f1,fold_train_roc=fold_train_roc,fold_val_roc=fold_val_roc,track_all_train_loss=track_all_train_loss,\n",
    "                              track_all_val_loss=track_all_val_loss)\n",
    "\n",
    "\n",
    "final_train_loss = np.mean(fold_train_loss)\n",
    "final_val_loss = np.mean(fold_val_loss)\n",
    "final_train_accuracy = np.mean(fold_train_accuracies)\n",
    "final_val_accuracy = np.mean(fold_val_accuracies)\n",
    "final_train_f1 = np.mean(fold_train_f1)\n",
    "final_val_f1 = np.mean(fold_val_f1)\n",
    "final_train_roc = np.mean(fold_train_roc)\n",
    "final_val_roc = np.mean(fold_val_roc)\n",
    "\n",
    "print(\"final_train_loss: \",final_train_loss)\n",
    "print(\"final_val_loss: \",final_val_loss)\n",
    "print(\"final_train_accuracy: \",final_train_accuracy*100)\n",
    "print(\"final_val_accuracy: \",final_val_accuracy*100)\n",
    "print(\"final_train_f1: \",final_train_f1)\n",
    "print(\"final_val_f1: \",final_val_f1)\n",
    "print(\"final_train_roc: \",final_train_roc)\n",
    "print(\"final_val_roc: \",final_val_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97bf0f33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:17:31.015000Z",
     "iopub.status.busy": "2025-02-28T22:17:31.014755Z",
     "iopub.status.idle": "2025-02-28T22:17:31.020628Z",
     "shell.execute_reply": "2025-02-28T22:17:31.020028Z"
    },
    "papermill": {
     "duration": 0.027721,
     "end_time": "2025-02-28T22:17:31.021932",
     "exception": false,
     "start_time": "2025-02-28T22:17:30.994211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_checkpoint_metrics(path):\n",
    "    checkpoint = torch.load(path)\n",
    "    train_acc = checkpoint['train_acc']\n",
    "    val_acc = checkpoint['val_acc']\n",
    "    best_loss = checkpoint.get('best_loss', None)\n",
    "    counter = checkpoint.get('counter', 0)\n",
    "    train_accuracies = checkpoint.get('train_accuracies', [])\n",
    "    val_accuracies = checkpoint.get('val_accuracies', [])\n",
    "    all_train_loss = checkpoint.get('all_train_loss', [])\n",
    "    all_val_loss = checkpoint.get('all_val_loss',[])\n",
    "    train_f1_scores = checkpoint.get('train_f1_scores', [])\n",
    "    val_f1_scores = checkpoint.get('val_f1_scores', [])\n",
    "    train_roc_aucs = checkpoint.get('train_roc_aucs', [])\n",
    "    val_roc_aucs = checkpoint.get('val_roc_aucs', [])\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    fold_train_accuracies = checkpoint.get('fold_train_accuracies', [])\n",
    "    fold_val_accuracies = checkpoint.get('fold_val_accuracies', [])\n",
    "    fold_train_loss = checkpoint.get('fold_train_loss', [])\n",
    "    fold_val_loss = checkpoint.get('fold_val_loss', [])\n",
    "    fold_train_f1 = checkpoint.get('fold_train_f1', [])\n",
    "    fold_val_f1 = checkpoint.get('fold_val_f1', [])\n",
    "    fold_train_roc = checkpoint.get('fold_train_roc', [])\n",
    "    fold_val_roc = checkpoint.get('fold_val_roc', [])\n",
    "    track_all_train_loss = checkpoint.get('track_all_train_loss', [])\n",
    "    track_all_val_loss = checkpoint.get('track_all_val_loss', [])\n",
    "\n",
    "\n",
    "    return (train_acc, val_acc, best_loss, counter,train_accuracies, val_accuracies,all_train_loss,all_val_loss,\n",
    "            train_f1_scores,val_f1_scores,train_roc_aucs,val_roc_aucs,best_acc,fold_train_accuracies,fold_val_accuracies,fold_train_loss,\n",
    "            fold_val_loss,fold_train_f1,fold_val_f1,fold_train_roc,fold_val_roc,track_all_train_loss,track_all_val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1e52fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:17:31.061312Z",
     "iopub.status.busy": "2025-02-28T22:17:31.061100Z",
     "iopub.status.idle": "2025-02-28T22:17:31.064111Z",
     "shell.execute_reply": "2025-02-28T22:17:31.063482Z"
    },
    "papermill": {
     "duration": 0.023732,
     "end_time": "2025-02-28T22:17:31.065184",
     "exception": false,
     "start_time": "2025-02-28T22:17:31.041452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# checkpoint_dir = \"/kaggle/input/resnet18_cbam_eca_69epoch/pytorch/default/1/checkpoint_epoch.pth\"\n",
    "\n",
    "# (train_acc, val_acc, best_loss, counter,train_accuracies, val_accuracies,all_train_loss,all_val_loss,train_f1_scores,\n",
    "#      val_f1_scores,train_roc_aucs,val_roc_aucs,best_acc,fold_train_accuracies,fold_val_accuracies,fold_train_loss,\n",
    "#      fold_val_loss,fold_train_f1,fold_val_f1,fold_train_roc,fold_val_roc,track_all_train_loss,track_all_val_loss) = load_checkpoint_metrics(checkpoint_dir)\n",
    "\n",
    "# final_train_loss = np.mean(fold_train_loss)\n",
    "# final_val_loss = np.mean(fold_val_loss)\n",
    "# final_train_accuracy = np.mean(fold_train_accuracies)\n",
    "# final_val_accuracy = np.mean(fold_val_accuracies)\n",
    "# final_train_f1 = np.mean(fold_train_f1)\n",
    "# final_val_f1 = np.mean(fold_val_f1)\n",
    "# final_train_roc = np.mean(fold_train_roc)\n",
    "# final_val_roc = np.mean(fold_val_roc)\n",
    "\n",
    "# print(\"final_train_loss: \",final_train_loss)\n",
    "# print(\"final_val_loss: \",final_val_loss)\n",
    "# print(\"final_train_accuracy: \",final_train_accuracy*100)\n",
    "# print(\"final_val_accuracy: \",final_val_accuracy*100)\n",
    "# print(\"final_train_f1: \",final_train_f1)\n",
    "# print(\"final_val_f1: \",final_val_f1)\n",
    "# print(\"final_train_roc: \",final_train_roc)\n",
    "# print(\"final_val_roc: \",final_val_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addd2c58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:17:31.104755Z",
     "iopub.status.busy": "2025-02-28T22:17:31.104513Z",
     "iopub.status.idle": "2025-02-28T22:17:31.337299Z",
     "shell.execute_reply": "2025-02-28T22:17:31.336494Z"
    },
    "papermill": {
     "duration": 0.253751,
     "end_time": "2025-02-28T22:17:31.338500",
     "exception": false,
     "start_time": "2025-02-28T22:17:31.084749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(track_all_train_loss) + 1), track_all_train_loss, label='Train Loss')\n",
    "plt.plot(range(1, len(track_all_val_loss) + 1), track_all_val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Validation Loss per epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dd38057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:17:31.380183Z",
     "iopub.status.busy": "2025-02-28T22:17:31.379965Z",
     "iopub.status.idle": "2025-02-28T22:18:10.289957Z",
     "shell.execute_reply": "2025-02-28T22:18:10.289037Z"
    },
    "papermill": {
     "duration": 38.952309,
     "end_time": "2025-02-28T22:18:10.311530",
     "exception": false,
     "start_time": "2025-02-28T22:17:31.359221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9546971864568431, Test F1: 0.9685117666556181, Test ROC: 0.9853749460141387, Test Precision: 0.974, Test Recall: 0.9630850362557679\n",
      "True Negatives (Predicted 1 when Ground Truth is 1): 1461\n",
      "True negative filenames: 1461\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "# model_weight_path = '/kaggle/input/resnet18_cbam_eca_69epoch/pytorch/default/1/best_model.pth'\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "# net = ResNet18_CBAM_ECA().to(device)\n",
    "\n",
    "# net.load_state_dict(torch.load(model_weight_path))\n",
    "# print(net.load_state_dict(torch.load(model_weight_path)))\n",
    "\n",
    "\n",
    "net.eval()\n",
    "# Initialize an array to store filenames\n",
    "true_negative_filenames = []\n",
    "true = []\n",
    "pre = []\n",
    "proba = []\n",
    "\n",
    "# DataLoader for the test dataset\n",
    "batch_size = 64\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset_f, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "# Loop through the test dataset\n",
    "for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "    # Get corresponding file paths for the current batch\n",
    "    batch_image_paths = test_image_paths[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "\n",
    "    # Make predictions\n",
    "    outputs = net(images.to(device))\n",
    "    preds = outputs.argmax(dim=1, keepdim=True).cpu().numpy()\n",
    "    test_probs = torch.nn.functional.softmax(outputs, dim=1)[:, 1].detach().cpu().numpy()\n",
    "\n",
    "    # Extend true labels, predictions, and probabilities\n",
    "    true.extend(labels.cpu().numpy())\n",
    "    pre.extend(preds)\n",
    "    proba.extend(test_probs)\n",
    "\n",
    "    # Save true positive filenames in the array\n",
    "    for label, pred, img_path in zip(labels, preds, batch_image_paths):\n",
    "        if label.item() == 1 and pred.item() == 1:\n",
    "            original_name = os.path.basename(img_path)\n",
    "            true_negative_filenames.append(original_name)\n",
    "\n",
    "test_accuracy = accuracy_score(true, pre)\n",
    "test_f1 = f1_score(true, pre)\n",
    "test_roc = roc_auc_score(true, proba)\n",
    "test_precision = precision_score(true, pre)\n",
    "test_recall = recall_score(true, pre)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy}, Test F1: {test_f1}, Test ROC: {test_roc}, Test Precision: {test_precision}, Test Recall: {test_recall}\")\n",
    "\n",
    "true_negatives = sum((np.array(true) == 1) & (np.array(pre).flatten() == 1))\n",
    "print(f\"True Negatives (Predicted 1 when Ground Truth is 1): {true_negatives}\")\n",
    "\n",
    "# Output the list of true positive filenames\n",
    "print(f\"True negative filenames: {len(true_negative_filenames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f01b21b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:18:10.352930Z",
     "iopub.status.busy": "2025-02-28T22:18:10.352664Z",
     "iopub.status.idle": "2025-02-28T22:18:10.355745Z",
     "shell.execute_reply": "2025-02-28T22:18:10.354952Z"
    },
    "papermill": {
     "duration": 0.025102,
     "end_time": "2025-02-28T22:18:10.356931",
     "exception": false,
     "start_time": "2025-02-28T22:18:10.331829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# after 30 epochs\n",
    "# Test Accuracy: 0.9518359561278016, Test F1: 0.9669610729473339, Test ROC: 0.983022299002114, Test Precision: 0.9597402597402598, Test Recall: 0.974291364535267\n",
    "# True Negatives (Predicted 1 when Ground Truth is 1): 1478\n",
    "# True negative filenames: 1478\n",
    "\n",
    "# after 69 epochs\n",
    "# Test Accuracy: 0.944206008583691, Test F1: 0.9606986899563319, Test ROC: 0.9855954356374877, Test Precision: 0.9794520547945206, Test Recall: 0.942649967040211\n",
    "# True Negatives (Predicted 1 when Ground Truth is 1): 1430\n",
    "# True negative filenames: 1430"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "524df0e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:18:10.399185Z",
     "iopub.status.busy": "2025-02-28T22:18:10.398950Z",
     "iopub.status.idle": "2025-02-28T22:18:10.960881Z",
     "shell.execute_reply": "2025-02-28T22:18:10.959990Z"
    },
    "papermill": {
     "duration": 0.584001,
     "end_time": "2025-02-28T22:18:10.962233",
     "exception": false,
     "start_time": "2025-02-28T22:18:10.378232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAocAAAHHCAYAAADNpPITAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhmElEQVR4nO3dd1gUV9sG8HsWpC5LUQFRmhERFMUWgsYWC5YYLPmMSgxYo4Kxa0wEEWPvqNFYYgu+aqISW1TsRrGLlWBXogJGKaJShPn+4GXerMDKsosoe/+85rqcM2fOPDtSHk+ZEURRFEFEREREBEBW1gEQERER0buDySERERERSZgcEhEREZGEySERERERSZgcEhEREZGEySERERERSZgcEhEREZGEySERERERSZgcEhEREZGEySERURFu3LiBdu3awdzcHIIgIDIyUqvt3717F4IgYM2aNVpt933WsmVLtGzZsqzDINJpTA6J6J1269YtfP3116hevTqMjIygUCjQtGlTLFy4EC9fvizVa/v7++Py5cuYOnUq1q9fj0aNGpXq9d6mgIAACIIAhUJR6H28ceMGBEGAIAiYM2eO2u0/fPgQoaGhiImJ0UK0RPQ26Zd1AERERdm1axf+7//+D4aGhvjqq69Qp04dZGVl4c8//8TYsWNx9epVLF++vFSu/fLlS0RHR+P7779HUFBQqVzD0dERL1++RIUKFUql/TfR19fHixcvsGPHDvTo0UPpWEREBIyMjJCRkVGith8+fIjJkyfDyckJnp6exT5v3759JboeEWkPk0MieifduXMHPXv2hKOjIw4ePIgqVapIxwIDA3Hz5k3s2rWr1K7/+PFjAICFhUWpXUMQBBgZGZVa+29iaGiIpk2b4j//+U+B5HDDhg3o1KkTtmzZ8lZiefHiBUxMTGBgYPBWrkdEReOwMhG9k2bNmoX09HSsWrVKKTHMV6NGDQwfPlzaf/XqFaZMmYIPPvgAhoaGcHJywnfffYfMzEyl85ycnPDpp5/izz//xIcffggjIyNUr14d69atk+qEhobC0dERADB27FgIggAnJycAecOx+X//t9DQUAiCoFQWFRWFjz/+GBYWFpDL5XB1dcV3330nHS9qzuHBgwfRrFkzmJqawsLCAr6+voiNjS30ejdv3kRAQAAsLCxgbm6Ovn374sWLF0Xf2Nf07t0bf/zxB1JSUqSyM2fO4MaNG+jdu3eB+k+fPsWYMWPg4eEBuVwOhUKBDh064OLFi1Kdw4cPo3HjxgCAvn37SsPT+Z+zZcuWqFOnDs6dO4fmzZvDxMREui+vzzn09/eHkZFRgc/v4+MDS0tLPHz4sNiflYiKh8khEb2TduzYgerVq6NJkybFqj9gwACEhISgQYMGmD9/Plq0aIHp06ejZ8+eBerevHkTn3/+Odq2bYu5c+fC0tISAQEBuHr1KgCgW7dumD9/PgCgV69eWL9+PRYsWKBW/FevXsWnn36KzMxMhIWFYe7cufjss89w/Phxleft378fPj4+SEpKQmhoKEaNGoUTJ06gadOmuHv3boH6PXr0wLNnzzB9+nT06NEDa9asweTJk4sdZ7du3SAIArZu3SqVbdiwAbVq1UKDBg0K1L99+zYiIyPx6aefYt68eRg7diwuX76MFi1aSImam5sbwsLCAACDBg3C+vXrsX79ejRv3lxq58mTJ+jQoQM8PT2xYMECtGrVqtD4Fi5ciMqVK8Pf3x85OTkAgJ9++gn79u3DokWLYGdnV+zPSkTFJBIRvWNSU1NFAKKvr2+x6sfExIgAxAEDBiiVjxkzRgQgHjx4UCpzdHQUAYhHjx6VypKSkkRDQ0Nx9OjRUtmdO3dEAOLs2bOV2vT39xcdHR0LxDBp0iTx3z9S58+fLwIQHz9+XGTc+ddYvXq1VObp6SlaW1uLT548kcouXrwoymQy8auvvipwvX79+im12bVrV7FixYpFXvPfn8PU1FQURVH8/PPPxdatW4uiKIo5OTmira2tOHny5ELvQUZGhpiTk1PgcxgaGophYWFS2ZkzZwp8tnwtWrQQAYjLli0r9FiLFi2Uyvbu3SsCEH/44Qfx9u3bolwuF7t06fLGz0hEJcOeQyJ656SlpQEAzMzMilV/9+7dAIBRo0YplY8ePRoACsxNdHd3R7NmzaT9ypUrw9XVFbdv3y5xzK/Ln6v4+++/Izc3t1jnPHr0CDExMQgICICVlZVUXrduXbRt21b6nP82ePBgpf1mzZrhyZMn0j0sjt69e+Pw4cNISEjAwYMHkZCQUOiQMpA3T1Emy/vVkZOTgydPnkhD5ufPny/2NQ0NDdG3b99i1W3Xrh2+/vprhIWFoVu3bjAyMsJPP/1U7GsRkXqYHBLRO0ehUAAAnj17Vqz69+7dg0wmQ40aNZTKbW1tYWFhgXv37imVOzg4FGjD0tISycnJJYy4oC+++AJNmzbFgAEDYGNjg549e2Lz5s0qE8X8OF1dXQscc3Nzwz///IPnz58rlb/+WSwtLQFArc/SsWNHmJmZYdOmTYiIiEDjxo0L3Mt8ubm5mD9/PlxcXGBoaIhKlSqhcuXKuHTpElJTU4t9zapVq6q1+GTOnDmwsrJCTEwMwsPDYW1tXexziUg9TA6J6J2jUChgZ2eHK1euqHXe6wtCiqKnp1douSiKJb5G/ny4fMbGxjh69Cj279+PPn364NKlS/jiiy/Qtm3bAnU1oclnyWdoaIhu3bph7dq12LZtW5G9hgAwbdo0jBo1Cs2bN8cvv/yCvXv3IioqCrVr1y52DymQd3/UceHCBSQlJQEALl++rNa5RKQeJodE9E769NNPcevWLURHR7+xrqOjI3Jzc3Hjxg2l8sTERKSkpEgrj7XB0tJSaWVvvtd7JwFAJpOhdevWmDdvHq5du4apU6fi4MGDOHToUKFt58cZFxdX4Nhff/2FSpUqwdTUVLMPUITevXvjwoULePbsWaGLePL99ttvaNWqFVatWoWePXuiXbt2aNOmTYF7UtxEvTieP3+Ovn37wt3dHYMGDcKsWbNw5swZrbVPRMqYHBLRO2ncuHEwNTXFgAEDkJiYWOD4rVu3sHDhQgB5w6IACqwonjdvHgCgU6dOWovrgw8+QGpqKi5duiSVPXr0CNu2bVOq9/Tp0wLn5j8M+vXH6+SrUqUKPD09sXbtWqVk68qVK9i3b5/0OUtDq1atMGXKFCxevBi2trZF1tPT0yvQK/nrr7/iwYMHSmX5SWxhibS6xo8fj/v372Pt2rWYN28enJyc4O/vX+R9JCLN8CHYRPRO+uCDD7BhwwZ88cUXcHNzU3pDyokTJ/Drr78iICAAAFCvXj34+/tj+fLlSElJQYsWLXD69GmsXbsWXbp0KfIxKSXRs2dPjB8/Hl27dsU333yDFy9eYOnSpahZs6bSgoywsDAcPXoUnTp1gqOjI5KSkvDjjz+iWrVq+Pjjj4tsf/bs2ejQoQO8vb3Rv39/vHz5EosWLYK5uTlCQ0O19jleJ5PJMHHixDfW+/TTTxEWFoa+ffuiSZMmuHz5MiIiIlC9enWleh988AEsLCywbNkymJmZwdTUFF5eXnB2dlYrroMHD+LHH3/EpEmTpEfrrF69Gi1btkRwcDBmzZqlVntEVAxlvFqaiEil69eviwMHDhSdnJxEAwMD0czMTGzatKm4aNEiMSMjQ6qXnZ0tTp48WXR2dhYrVKgg2tvbixMmTFCqI4p5j7Lp1KlTgeu8/giVoh5lI4qiuG/fPrFOnTqigYGB6OrqKv7yyy8FHmVz4MAB0dfXV7SzsxMNDAxEOzs7sVevXuL169cLXOP1x73s379fbNq0qWhsbCwqFAqxc+fO4rVr15Tq5F/v9UflrF69WgQg3rlzp8h7KorKj7IpSlGPshk9erRYpUoV0djYWGzatKkYHR1d6CNofv/9d9Hd3V3U19dX+pwtWrQQa9euXeg1/91OWlqa6OjoKDZo0EDMzs5Wqjdy5EhRJpOJ0dHRKj8DEalPEEU1Zi0TERERUbnGOYdEREREJGFySEREREQSJodEREREJGFySEREREQSJodEREREJGFySEREREQSPgSbyoXc3Fw8fPgQZmZmWn1tFxERvR2iKOLZs2ews7ODTFZ6fVcZGRnIysrSuB0DAwMYGRlpIaJ3D5NDKhcePnwIe3v7sg6DiIg0FB8fj2rVqpVK2xkZGTA2qwi8eqFxW7a2trhz5065TBCZHFK5YGZmBgAI330axqbyMo6GqHR8VqdqWYdAVGqepaWhhrO99PO8NGRlZQGvXsCwdl9Az6DkDeVkIeHqamRlZTE5JHpX5Q8lG5vKYSIvvR8sRGVJoVCUdQhEpe6tTA3SM4CgQXJY3l8tx+SQiIiIdIsAQJMktJxPbWdySERERLpFkOVtmpxfjpXvT0dEREREamHPIREREekWQdBwWLl8jyszOSQiIiLdwmFllcr3pyMiIiIitbDnkIiIiHQLh5VVYnJIREREOkbDYeVyPvBavj8dEREREamFySERERHplvxhZU02NRw9ehSdO3eGnZ0dBEFAZGRkkXUHDx4MQRCwYMECpfKnT5/Cz88PCoUCFhYW6N+/P9LT05XqXLp0Cc2aNYORkRHs7e0xa9YsteLMx+SQiIiIdEv+amVNNjU8f/4c9erVw5IlS1TW27ZtG06ePAk7O7sCx/z8/HD16lVERUVh586dOHr0KAYNGiQdT0tLQ7t27eDo6Ihz585h9uzZCA0NxfLly9WKFeCcQyIiItI1b3lBSocOHdChQweVdR48eIBhw4Zh79696NSpk9Kx2NhY7NmzB2fOnEGjRo0AAIsWLULHjh0xZ84c2NnZISIiAllZWfj5559hYGCA2rVrIyYmBvPmzVNKIouDPYdEREREJZCWlqa0ZWZmlqid3Nxc9OnTB2PHjkXt2rULHI+OjoaFhYWUGAJAmzZtIJPJcOrUKalO8+bNYWBgINXx8fFBXFwckpOT1YqHySERERHpFi0NK9vb28Pc3Fzapk+fXqJwZs6cCX19fXzzzTeFHk9ISIC1tbVSmb6+PqysrJCQkCDVsbGxUaqTv59fp7g4rExERES6RUvDyvHx8VAoFFKxoaGh2k2dO3cOCxcuxPnz5yG8I89PZM8hERERUQkoFAqlrSTJ4bFjx5CUlAQHBwfo6+tDX18f9+7dw+jRo+Hk5AQAsLW1RVJSktJ5r169wtOnT2FrayvVSUxMVKqTv59fp7iYHBIREZFuecurlVXp06cPLl26hJiYGGmzs7PD2LFjsXfvXgCAt7c3UlJScO7cOem8gwcPIjc3F15eXlKdo0ePIjs7W6oTFRUFV1dXWFpaqhUTh5WJiIhItwiCZgmemsO/6enpuHnzprR/584dxMTEwMrKCg4ODqhYsaJS/QoVKsDW1haurq4AADc3N7Rv3x4DBw7EsmXLkJ2djaCgIPTs2VN67E3v3r0xefJk9O/fH+PHj8eVK1ewcOFCzJ8/X+2Px+SQiIiIqBSdPXsWrVq1kvZHjRoFAPD398eaNWuK1UZERASCgoLQunVryGQydO/eHeHh4dJxc3Nz7Nu3D4GBgWjYsCEqVaqEkJAQtR9jAzA5JCIiIl0jE/I2Tc5XQ8uWLSGKYrHr3717t0CZlZUVNmzYoPK8unXr4tixY2rFVhgmh0RERKRbNJ03qMU5h++i8v3piIiIiEgt7DkkIiIi3fKWX5/3vmFySERERLqFw8oqMTkkIiIi3cKeQ5XKd+pLRERERGphzyERERHpFg4rq8TkkIiIiHQLh5VVKt+pLxERERGphT2HREREpFs4rKwSk0MiIiLSLRxWVql8p75EREREpBb2HBIREZGO0XBYuZz3rTE5JCIiIt3CYWWVynfqS0RERERqYc8hERER6RZB0HC1cvnuOWRySERERLqFj7JRickhERER6RbOOVSpfKe+RERERKQW9hwSERGRbuGwskpMDomIiEi3cFhZpfKd+hIRERGRWthzSERERLqFw8oqMTkkIiIi3cJhZZXKd+pLRERERGphzyERERHpFEEQILDnsEhMDomIiEinMDlUjcPKRERERCRhzyERERHpFuG/mybnl2NMDomIiEincFhZNSaHREREpFOYHKrGOYdEREREJGHPIREREekU9hyqxuSQiIiIdAqTQ9U4rExEREREEvYcEhERkW7ho2xUYnJIREREOoXDyqpxWJmIiIiIJOw5JCIiIp0iCNCw51B7sbyLmBwSERGRThGg4bByOc8OOaxMRERERBImh0RERKRT8hekaLKp4+jRo+jcuTPs7OwgCAIiIyOlY9nZ2Rg/fjw8PDxgamoKOzs7fPXVV3j48KFSG0+fPoWfnx8UCgUsLCzQv39/pKenK9W5dOkSmjVrBiMjI9jb22PWrFkluj9MDomIiEi3CFrY1PD8+XPUq1cPS5YsKXDsxYsXOH/+PIKDg3H+/Hls3boVcXFx+Oyzz5Tq+fn54erVq4iKisLOnTtx9OhRDBo0SDqelpaGdu3awdHREefOncPs2bMRGhqK5cuXqxcsOOeQiIiIdI2Gj7IR1Ty3Q4cO6NChQ6HHzM3NERUVpVS2ePFifPjhh7h//z4cHBwQGxuLPXv24MyZM2jUqBEAYNGiRejYsSPmzJkDOzs7REREICsrCz///DMMDAxQu3ZtxMTEYN68eUpJZHGw55CIiIioBNLS0pS2zMxMrbSbmpoKQRBgYWEBAIiOjoaFhYWUGAJAmzZtIJPJcOrUKalO8+bNYWBgINXx8fFBXFwckpOT1bo+k0MiIiLSKdqac2hvbw9zc3Npmz59usaxZWRkYPz48ejVqxcUCgUAICEhAdbW1kr19PX1YWVlhYSEBKmOjY2NUp38/fw6xcVhZSIiItIpmr4hJf/c+Ph4KYEDAENDQ43iys7ORo8ePSCKIpYuXapRW5pgckhERERUAgqFQik51ER+Ynjv3j0cPHhQqV1bW1skJSUp1X/16hWePn0KW1tbqU5iYqJSnfz9/DrFxWFlIiIi0i1vebXym+Qnhjdu3MD+/ftRsWJFpePe3t5ISUnBuXPnpLKDBw8iNzcXXl5eUp2jR48iOztbqhMVFQVXV1dYWlqqFQ+TQyIiItIpb/s5h+np6YiJiUFMTAwA4M6dO4iJicH9+/eRnZ2Nzz//HGfPnkVERARycnKQkJCAhIQEZGVlAQDc3NzQvn17DBw4EKdPn8bx48cRFBSEnj17ws7ODgDQu3dvGBgYoH///rh69So2bdqEhQsXYtSoUWrfHw4rExEREZWis2fPolWrVtJ+fsLm7++P0NBQbN++HQDg6empdN6hQ4fQsmVLAEBERASCgoLQunVryGQydO/eHeHh4VJdc3Nz7Nu3D4GBgWjYsCEqVaqEkJAQtR9jAzA5JCIiIh2jrQUpxdWyZUuIoljkcVXH8llZWWHDhg0q69StWxfHjh1TK7bCMDkkIiIinfK2k8P3DeccEhEREZGEPYdERESkU9hzqBqTQyIiItItmj6OpnznhkwOiYiISLew51A1zjkkIiIiIgl7DomIiEinsOdQNSaHREREpFOYHKrGYWUiIiIikrDnkIiIiHQLVyurxOSQiIiIdAqHlVXjsDIRERERSdhz+A44fPgwWrVqheTkZFhYWLzTbYeGhiIyMhIxMTEat0Xvnt9/P4bt248rldnaWmHq1EFKZaIoYsGCX3Hlym0EBnZDgwY1pWMbNkTh5s2/8eDBP6hSpSJCQ/u9ldiJSmLVb8fw85ZjiH/0FABQq7otxvbvgLZNawMA7vz9GMELt+FkzG1kZb9Ca283zBzzf7CuqCjLsElD7DlUrUx7DgMCAiAIAmbMmKFUHhkZWaY3/u7duxAEgQkQ6SQ7u0qYNy9I2r799ssCdaKizkDVt+jHH9dF48a1SjFKIu2ws7bApCBfHFo3DgfXjkWzRjXhN2Y5Ym89wvOXmegWtAQCBPy+dBj+WDkSWdk56DXqJ+Tm5pZ16KQBAYKUIJZoK+eTDst8WNnIyAgzZ85EcnJyWYfyXsvKyirrEKic0NOTwdxcLm1mZiZKx+/fT8S+fWfQt2/HQs/v3bstPvmkISpXtngL0RJppkNzD7RrWhsfOFijhqMNgod+BlMTQ5y9cgenLt7G/UdPsGTSl6hdoypq16iKH0P74ELsfRw9c72sQycNaJQYatjr+D4o8+SwTZs2sLW1xfTp04uss2XLFtSuXRuGhoZwcnLC3LlzlY47OTlh2rRp6NevH8zMzODg4IDly5ervG5ycjL8/PxQuXJlGBsbw8XFBatXrwYAODs7AwDq168PQRDQsmVLAMCZM2fQtm1bVKpUCebm5mjRogXOnz+v1K4gCFi5ciW6du0KExMTuLi4YPv27Up1du/ejZo1a8LY2BitWrXC3bt3lY4/efIEvXr1QtWqVWFiYgIPDw/85z//UarTsmVLBAUFYcSIEahUqRJ8fHyK1bYqa9asgYWFBSIjI+Hi4gIjIyP4+PggPj6+yHO0dU+uXLmCDh06QC6Xw8bGBn369ME///xT7NhJexITkzFq1GKMH78Uy5dvx5MnqdKxzMxsLF++HX5+bWFuLi/DKIm0LycnF1v2ncWLl1lo7OGMzKxXEAQBhgb/m4FlZKAPmUzAyYu3yjBSotJV5smhnp4epk2bhkWLFuHvv/8ucPzcuXPo0aMHevbsicuXLyM0NBTBwcFYs2aNUr25c+eiUaNGuHDhAoYOHYohQ4YgLi6uyOsGBwfj2rVr+OOPPxAbG4ulS5eiUqVKAIDTp08DAPbv349Hjx5h69atAIBnz57B398ff/75J06ePAkXFxd07NgRz549U2p78uTJ6NGjBy5duoSOHTvCz88PT5/mzWeJj49Ht27d0LlzZ8TExGDAgAH49ttvlc7PyMhAw4YNsWvXLly5cgWDBg1Cnz59pLjyrV27FgYGBjh+/DiWLVtWrLbf5MWLF5g6dSrWrVuH48ePIyUlBT179iyyvjbuSUpKCj755BPUr18fZ8+exZ49e5CYmIgePXoUed3MzEykpaUpbaS56tXt0K9fJ4wc2QN9+vjgn39SMWNGBF6+zAQAbNp0ADVqVEX9+jXf0BLR++PqzQeo1nwUbJqOwKjpm7B+9kDUql4FjT2cYGJkgNBFv+NFRhaev8xE8MJtyMnJRcI//JnzXhO0sJVj78SClK5du8LT0xOTJk3CqlWrlI7NmzcPrVu3RnBwMACgZs2auHbtGmbPno2AgACpXseOHTF06FAAwPjx4zF//nwcOnQIrq6uhV7z/v37qF+/Pho1agQgr/cxX+XKlQEAFStWhK2trVT+ySefKLWxfPlyWFhY4MiRI/j000+l8oCAAPTq1QsAMG3aNISHh+P06dNo3749li5dig8++EDq/XR1dcXly5cxc+ZM6fyqVatizJgx0v6wYcOwd+9ebN68GR9++KFU7uLiglmzZkn733333RvbfpPs7GwsXrwYXl5eAPISUDc3N5w+fVrp2tq8J4sXL0b9+vUxbdo0qf7PP/8Me3t7XL9+HTVrFkxEpk+fjsmTJxf7c1HxeHh8IP3d3t4a1avbYdy4pTh79i+YmZkgNvYeJk3qW4YREmmfi6MNjkZMQFr6S/x+4AKGhq7Hzp+Go1b1Klgzoz9Gz9iEnzYdgUwmoHu7hqhXyx4yWTnPDso5LkhRrcx7DvPNnDkTa9euRWxsrFJ5bGwsmjZtqlTWtGlT3LhxAzk5OVJZ3bp1pb8LggBbW1skJSUBgDRcKZfLUbt23gq0IUOGYOPGjfD09MS4ceNw4sSJN8aYmJiIgQMHwsXFBebm5lAoFEhPT8f9+/eV6v07FlNTUygUCimW2NhYKfHK5+3trbSfk5ODKVOmwMPDA1ZWVpDL5di7d2+B6zRs2LDAvXpT22+ir6+Pxo0bS/u1atWChYVFgX+XfNq4JxcvXsShQ4ekfyO5XI5atfIWM9y6VfjQzYQJE5Camiptqoa+qeRMTIxgY2OJpKRkxMbew+PHyRg2bD4GDpyJgQPz/tPx44/bMGtWRBlHSlRyBhX0Ud2+MjzdHDApyBd1XKpi2cbDAIBPPnLDhchQ3Ng3HbeiZuCnMH88SkqBU9VKZRs0USl6J3oOAaB58+bw8fHBhAkTlHoEi6tChQpK+4IgSKvJVq5ciZcvXyrV69ChA+7du4fdu3cjKioKrVu3RmBgIObMmVPkNfz9/fHkyRMsXLgQjo6OMDQ0hLe3d4HFIKpiKY7Zs2dj4cKFWLBgATw8PGBqaooRI0YUuI6pqWmx2ywt2rgn6enp6Ny5c6E9nFWqVCn0uoaGhjA0NNTSp6CiZGRkISkpBd7ecjRuXAvNmtVTOj5p0ir07Nka9erVKKMIibQvVxSRlfVKqayiRd4c26Nn4vA4OR0dmnmURWikJew5VO2dSQ4BYMaMGfD09FQaCnZzc8Px48rPXTt+/Dhq1qwJPT29YrVbtWrVQssrV64Mf39/+Pv7o1mzZhg7dizmzJkDAwMDAFDqmcy/7o8//oiOHfNWacbHx6u9aMLNza3AYoyTJ08WuI6vry++/DLvESK5ubm4fv063N3dNW77TV69eoWzZ89KQ8hxcXFISUmBm5tbofW1cU8aNGiALVu2wMnJCfr679SXpM7ZtOkgPD1roGJFBVJS0vH7739CJhPg5eUOMzOTQhehWFkplFYmJyYmIzMzC6mpz5GV9Qr37ycCyHtEjr5+8b5nid6WyYt/R5smtWFva4lnLzLw256z+PPcDWxZlDdNKWJ7NGo626KSpRynL93BhHm/YWivVnBxsinjyEkTggCVj+Mqzvnl2Tv1m9jDwwN+fn4IDw+XykaPHo3GjRtjypQp+OKLLxAdHY3Fixfjxx9/1OhaISEhaNiwIWrXro3MzEzs3LlTSoCsra1hbGyMPXv2oFq1ajAyMoK5uTlcXFywfv16NGrUCGlpaRg7diyMjY3Vuu7gwYMxd+5cjB07FgMGDMC5c+cKLK5xcXHBb7/9hhMnTsDS0hLz5s1DYmLiG5PD4rT9JhUqVMCwYcMQHh4OfX19BAUF4aOPPip0vmF+rJrek8DAQKxYsQK9evXCuHHjYGVlhZs3b2Ljxo1YuXJlsf8TQJpLTn6Gn37ajufPX8LMzAQ1alTD999/VeBxNqqsXbsbcXH/G+afPDnvKQAzZw5GpUoW2g6ZSCP/JKdjSOg6JP6TBoXcCLVrVMWWRUPRyivv98GNe0kIW7IdyWkv4GBnhdF9fTC09ydvaJXo/fZOJYcAEBYWhk2bNkn7DRo0wObNmxESEoIpU6agSpUqCAsLK9HQ878ZGBhgwoQJuHv3LoyNjdGsWTNs3LgRQN68u/DwcISFhSEkJATNmjXD4cOHsWrVKgwaNAgNGjSAvb09pk2bprRwpDgcHBywZcsWjBw5EosWLcKHH34oPYYn38SJE3H79m34+PjAxMQEgwYNQpcuXZCamqqi5eK1/SYmJiYYP348evfujQcPHqBZs2YFFgn9mzbuiZ2dHY4fP47x48ejXbt2yMzMhKOjI9q3bw+Z7J2ZFqsTBg/2Vav+qlUFV8OPG+enrXCISt2iYNVfr6HDfBE6TL3vC3r35fUcajKsrMVg3kGCKIpiWQdB74Y1a9ZgxIgRSElJKetQ1JaWlgZzc3OsOHINJnKzsg6HqFR0q1utrEMgKjVpaWmwqWiO1NRUKBSl83rC/N8V1b/5DXqGJZ+3n5P5HLfDPy/VWMsSu2WIiIiISMLkUIf8+5E+r2//fsYgERFRecbX56n2zs05pNLz70f6vM7KygpWVlYaz+UkIiJ613G1smpMDnVIUY/0ISIi0iUymaDRW27Ecv6GHA4rExEREZGEPYdERESkUzisrBqTQyIiItIpfH2eahxWJiIiIiIJew6JiIhIp3BYWTUmh0RERKRTOKysGoeViYiIiEjCnkMiIiLSKew5VI3JIREREekUzjlUjcPKRERERCRhzyERERHpFAEaDiujfHcdMjkkIiIincJhZdWYHBIREZFO4YIU1TjnkIiIiKgUHT16FJ07d4adnR0EQUBkZKTScVEUERISgipVqsDY2Bht2rTBjRs3lOo8ffoUfn5+UCgUsLCwQP/+/ZGenq5U59KlS2jWrBmMjIxgb2+PWbNmlSheJodERESkU/KHlTXZ1PH8+XPUq1cPS5YsKfT4rFmzEB4ejmXLluHUqVMwNTWFj48PMjIypDp+fn64evUqoqKisHPnThw9ehSDBg2SjqelpaFdu3ZwdHTEuXPnMHv2bISGhmL58uVq3x8OKxMREZFOedvDyh06dECHDh0KPSaKIhYsWICJEyfC19cXALBu3TrY2NggMjISPXv2RGxsLPbs2YMzZ86gUaNGAIBFixahY8eOmDNnDuzs7BAREYGsrCz8/PPPMDAwQO3atRETE4N58+YpJZHFwZ5DIiIiohJIS0tT2jIzM9Vu486dO0hISECbNm2kMnNzc3h5eSE6OhoAEB0dDQsLCykxBIA2bdpAJpPh1KlTUp3mzZvDwMBAquPj44O4uDgkJyerFROTQyIiItIp2hpWtre3h7m5ubRNnz5d7VgSEhIAADY2NkrlNjY20rGEhARYW1srHdfX14eVlZVSncLa+Pc1iovDykRERKRTtDWsHB8fD4VCIZUbGhpqHNu7gD2HRERERCWgUCiUtpIkh7a2tgCAxMREpfLExETpmK2tLZKSkpSOv3r1Ck+fPlWqU1gb/75GcTE5JCIiIt2i6ZCyFh9z6OzsDFtbWxw4cEAqS0tLw6lTp+Dt7Q0A8Pb2RkpKCs6dOyfVOXjwIHJzc+Hl5SXVOXr0KLKzs6U6UVFRcHV1haWlpVoxMTkkIiIinZI/rKzJpo709HTExMQgJiYGQN4ilJiYGNy/fx+CIGDEiBH44YcfsH37dly+fBlfffUV7Ozs0KVLFwCAm5sb2rdvj4EDB+L06dM4fvw4goKC0LNnT9jZ2QEAevfuDQMDA/Tv3x9Xr17Fpk2bsHDhQowaNUrt+8M5h0RERESl6OzZs2jVqpW0n5+w+fv7Y82aNRg3bhyeP3+OQYMGISUlBR9//DH27NkDIyMj6ZyIiAgEBQWhdevWkMlk6N69O8LDw6Xj5ubm2LdvHwIDA9GwYUNUqlQJISEhaj/GBgAEURRFDT4v0TshLS0N5ubmWHHkGkzkZmUdDlGp6Fa3WlmHQFRq0tLSYFPRHKmpqUqLPLR9DXNzczSevBv6RqYlbudVxnOcmdSxVGMtS+w5JCIiIp3CdyurxuSQiIiIdEpJXoH3+vnlGRekEBEREZGEPYdERESkUzisrBqTQyIiItIpTA5V47AyEREREUnYc0hEREQ6hQtSVGNySERERDqFw8qqcViZiIiIiCTsOSQiIiKdwmFl1ZgcEhERkU7hsLJqHFYmIiIiIgl7DomIiEinCNBwWFlrkbybmBwSERGRTpEJAmQaZIeanPs+YHJIREREOoULUlTjnEMiIiIikrDnkIiIiHQKVyurxuSQiIiIdIpMyNs0Ob8847AyEREREUnYc0hERES6RdBwaLic9xwyOSQiIiKdwtXKqnFYmYiIiIgk7DkkIiIinSL8948m55dnTA6JiIhIp3C1smocViYiIiIiCXsOiYiISKfwIdiqFSs53L59e7Eb/Oyzz0ocDBEREVFp42pl1YqVHHbp0qVYjQmCgJycHE3iISIiIipVMkGATIMMT5Nz3wfFSg5zc3NLOw4iIiIiegdoNOcwIyMDRkZG2oqFiIiIqNRxWFk1tVcr5+TkYMqUKahatSrkcjlu374NAAgODsaqVau0HiARERGRNuUvSNFkK8/UTg6nTp2KNWvWYNasWTAwMJDK69Spg5UrV2o1OCIiIiJ6u9RODtetW4fly5fDz88Penp6Unm9evXw119/aTU4IiIiIm3LH1bWZCvP1J5z+ODBA9SoUaNAeW5uLrKzs7USFBEREVFp4Wpl1dTuOXR3d8exY8cKlP/222+oX7++VoIiIiIiorKhds9hSEgI/P398eDBA+Tm5mLr1q2Ii4vDunXrsHPnztKIkYiIiEhrhP9umpxfnqndc+jr64sdO3Zg//79MDU1RUhICGJjY7Fjxw60bdu2NGIkIiIi0hquVlatRM85bNasGaKiorQdCxERERGVsRI/BPvs2bOIjY0FkDcPsWHDhloLioiIiKi0yIS8TZPzyzO1k8O///4bvXr1wvHjx2FhYQEASElJQZMmTbBx40ZUq1ZN2zESERERaY2mQ8PlfVhZ7TmHAwYMQHZ2NmJjY/H06VM8ffoUsbGxyM3NxYABA0ojRiIiIiKt4jMOi6Z2cnjkyBEsXboUrq6uUpmrqysWLVqEo0ePajU4IiIiovddTk4OgoOD4ezsDGNjY3zwwQeYMmUKRFGU6oiiiJCQEFSpUgXGxsZo06YNbty4odTO06dP4efnB4VCAQsLC/Tv3x/p6elaj1ft5NDe3r7Qh13n5OTAzs5OK0ERERERlZa3vVp55syZWLp0KRYvXozY2FjMnDkTs2bNwqJFi6Q6s2bNQnh4OJYtW4ZTp07B1NQUPj4+yMjIkOr4+fnh6tWriIqKws6dO3H06FEMGjRIa/cln9rJ4ezZszFs2DCcPXtWKjt79iyGDx+OOXPmaDU4IiIiIm3LX5CiyaaOEydOwNfXF506dYKTkxM+//xztGvXDqdPnwaQ12u4YMECTJw4Eb6+vqhbty7WrVuHhw8fIjIyEgAQGxuLPXv2YOXKlfDy8sLHH3+MRYsWYePGjXj48KF2709xKllaWsLKygpWVlbo27cvYmJi4OXlBUNDQxgaGsLLywvnz59Hv379tBocERER0bsqLS1NacvMzCy0XpMmTXDgwAFcv34dAHDx4kX8+eef6NChAwDgzp07SEhIQJs2baRzzM3N4eXlhejoaABAdHQ0LCws0KhRI6lOmzZtIJPJcOrUKa1+rmKtVl6wYIFWL0pERERUVrS1Wtne3l6pfNKkSQgNDS1Q/9tvv0VaWhpq1aoFPT095OTkYOrUqfDz8wMAJCQkAABsbGyUzrOxsZGOJSQkwNraWum4vr4+rKyspDraUqzk0N/fX6sXJSIiIior2np9Xnx8PBQKhVRuaGhYaP3NmzcjIiICGzZsQO3atRETE4MRI0bAzs7uncyxSvwQbADIyMhAVlaWUtm/bxIRERFReaVQKIqV94wdOxbffvstevbsCQDw8PDAvXv3MH36dPj7+8PW1hYAkJiYiCpVqkjnJSYmwtPTEwBga2uLpKQkpXZfvXqFp0+fSudri9oLUp4/f46goCBYW1vD1NQUlpaWShsRERHRu0wmCBpv6njx4gVkMuWUS09PD7m5uQAAZ2dn2Nra4sCBA9LxtLQ0nDp1Ct7e3gAAb29vpKSk4Ny5c1KdgwcPIjc3F15eXiW9FYVSOzkcN24cDh48iKVLl8LQ0BArV67E5MmTYWdnh3Xr1mk1OCIiIiJt0+QB2CV5EHbnzp0xdepU7Nq1C3fv3sW2bdswb948dO3a9b/xCBgxYgR++OEHbN++HZcvX8ZXX30FOzs7dOnSBQDg5uaG9u3bY+DAgTh9+jSOHz+OoKAg9OzZU+uPElR7WHnHjh1Yt24dWrZsib59+6JZs2aoUaMGHB0dERERIU2uJCIiIiJg0aJFCA4OxtChQ5GUlAQ7Ozt8/fXXCAkJkeqMGzcOz58/x6BBg5CSkoKPP/4Ye/bsgZGRkVQnIiICQUFBaN26NWQyGbp3747w8HCtxyuI/348dzHI5XJcu3YNDg4OqFatGrZu3YoPP/wQd+7cgYeHR6k8qZvoTdLS0mBubo4VR67BRG5W1uEQlYpudfnueiq/0tLSYFPRHKmpqaW2fiH/d4X/mpMwMJGXuJ2sF+lYG/BRqcZaltQeVq5evTru3LkDAKhVqxY2b94MIK9H0cLCQqvBEREREWnb2x5Wft+onRz27dsXFy9eBJD33J4lS5bAyMgII0eOxNixY7UeIBEREZE2ve0FKe8bteccjhw5Uvp7mzZt8Ndff+HcuXOoUaMG6tatq9XgiIiIiOjt0ug5hwDg6OgIR0dHbcRCREREVOo0HRou5x2HxUsO1VkJ880335Q4GCIiIqLSpq3X55VXxUoO58+fX6zGBEFgckhERET0HitWcpi/OpnoXdfJ3a5cPlaACAAsGweVdQhEpUbMyXpzJS2RoQQrcl87vzzTeM4hERER0fuEw8qqlffkl4iIiIjUwJ5DIiIi0imCAMi4WrlITA6JiIhIp8g0TA41Ofd9wGFlIiIiIpKUKDk8duwYvvzyS3h7e+PBgwcAgPXr1+PPP//UanBERERE2pa/IEWTrTxTOzncsmULfHx8YGxsjAsXLiAzMxMAkJqaimnTpmk9QCIiIiJtyh9W1mQrz9RODn/44QcsW7YMK1asQIUKFaTypk2b4vz581oNjoiIiEjb8l+fp8lWnqmdHMbFxaF58+YFys3NzZGSkqKNmIiIiIiojKidHNra2uLmzZsFyv/8809Ur15dK0ERERERlRaZIGi8lWdqJ4cDBw7E8OHDcerUKQiCgIcPHyIiIgJjxozBkCFDSiNGIiIiIq2RaWErz9R+zuG3336L3NxctG7dGi9evEDz5s1haGiIMWPGYNiwYaURIxERERG9JWonh4Ig4Pvvv8fYsWNx8+ZNpKenw93dHXK5vDTiIyIiItIqTReVlPNR5ZK/IcXAwADu7u7ajIWIiIio1Mmg2bxBGcp3dqh2ctiqVSuVD388ePCgRgERERERUdlROzn09PRU2s/OzkZMTAyuXLkCf39/bcVFREREVCo4rKya2snh/PnzCy0PDQ1Fenq6xgERERERlSZN33LCN6QU05dffomff/5ZW80RERERURko8YKU10VHR8PIyEhbzRERERGVCkGARgtSOKz8mm7duinti6KIR48e4ezZswgODtZaYERERESlgXMOVVM7OTQ3N1fal8lkcHV1RVhYGNq1a6e1wIiIiIhKA+ccqqZWcpiTk4O+ffvCw8MDlpaWpRUTEREREZURtRak6OnpoV27dkhJSSmlcIiIiIhKl6CFP+WZ2quV69Spg9u3b5dGLERERESlLn9YWZOtPFM7Ofzhhx8wZswY7Ny5E48ePUJaWprSRkRERETvr2LPOQwLC8Po0aPRsWNHAMBnn32m9Bo9URQhCAJycnK0HyURERGRlnBBimrFTg4nT56MwYMH49ChQ6UZDxEREVGpEgRBqYOrJOeXZ8VODkVRBAC0aNGi1IIhIiIiorKl1qNsynumTEREROUfh5VVUys5rFmz5hsTxKdPn2oUEBEREVFp4htSVFMrOZw8eXKBN6QQERERUfmhVnLYs2dPWFtbl1YsRERERKVOJgiQadD9p8m574NiJ4ecb0hERETlAeccqqb2amUiIiKi95qGcw7L+dvziv+GlNzcXA4pExEREZXAgwcP8OWXX6JixYowNjaGh4cHzp49Kx0XRREhISGoUqUKjI2N0aZNG9y4cUOpjadPn8LPzw8KhQIWFhbo378/0tPTtR6r2q/PIyIiInqfySBovKkjOTkZTZs2RYUKFfDHH3/g2rVrmDt3LiwtLaU6s2bNQnh4OJYtW4ZTp07B1NQUPj4+yMjIkOr4+fnh6tWriIqKws6dO3H06FEMGjRIa/cln1oLUoiIiIjed2/7UTYzZ86Evb09Vq9eLZU5OztLfxdFEQsWLMDEiRPh6+sLAFi3bh1sbGwQGRmJnj17IjY2Fnv27MGZM2fQqFEjAMCiRYvQsWNHzJkzB3Z2diX/QK9hzyERERFRCaSlpSltmZmZhdbbvn07GjVqhP/7v/+DtbU16tevjxUrVkjH79y5g4SEBLRp00YqMzc3h5eXF6KjowEA0dHRsLCwkBJDAGjTpg1kMhlOnTql1c/F5JCIiIh0Sv5qZU02ALC3t4e5ubm0TZ8+vdDr3b59G0uXLoWLiwv27t2LIUOG4JtvvsHatWsBAAkJCQAAGxsbpfNsbGykYwkJCQXWfujr68PKykqqoy0cViYiIiKdoq3nHMbHx0OhUEjlhoaGhdbPzc1Fo0aNMG3aNABA/fr1ceXKFSxbtgz+/v4ljqO0sOeQiIiIqAQUCoXSVlRyWKVKFbi7uyuVubm54f79+wAAW1tbAEBiYqJSncTEROmYra0tkpKSlI6/evUKT58+lepoC5NDIiIi0in5C1I02dTRtGlTxMXFKZVdv34djo6OAPIWp9ja2uLAgQPS8bS0NJw6dQre3t4AAG9vb6SkpODcuXNSnYMHDyI3NxdeXl4lvBOF47AyERER6RQZNBxWVvNRNiNHjkSTJk0wbdo09OjRA6dPn8by5cuxfPlyAHlvoRsxYgR++OEHuLi4wNnZGcHBwbCzs0OXLl0A5PU0tm/fHgMHDsSyZcuQnZ2NoKAg9OzZU6srlQEmh0RERESlqnHjxti2bRsmTJiAsLAwODs7Y8GCBfDz85PqjBs3Ds+fP8egQYOQkpKCjz/+GHv27IGRkZFUJyIiAkFBQWjdujVkMhm6d++O8PBwrccriHwvHpUDaWlpMDc3x8PHKUqTg4nKk0pew8o6BKJSI+ZkIfPyCqSmppbaz/H83xWLD16BsdysxO28TH+GoE/qlGqsZYk9h0RERKRTZNBs0UV5X7DB5JCIiIh0iiAIEDSYc6jJue+D8p78EhEREZEa2HNIREREOkX476bJ+eUZk0MiIiLSKdp6Q0p5xWFlIiIiIpKw55CIiIh0Tvnu+9MMk0MiIiLSKSV5Bd7r55dnHFYmIiIiIgl7DomIiEin8DmHqjE5JCIiIp3CN6SoVt4/HxERERGpgT2HREREpFM4rKwak0MiIiLSKXxDimpMDomIiEinsOdQNc45JCIiIiIJew6JiIhIp3C1smpMDomIiEincFhZtfKe/BIRERGRGthzSERERDqFq5VVY3JIREREOkUQ8jZNzi/POKxMRERERBL2HBIREZFOkUGATIPBYU3OfR8wOSQiIiKdwmFl1TisTEREREQS9hwSERGRThH++0eT88szJodERESkUzisrBqTQyIiItIpgoYLUsp7zyHnHBIRERGRhD2HREREpFM4rKwak0MiIiLSKUwOVeOwMhERERFJ2HNIREREOoWPslGNySERERHpFJmQt2lyfnnGYWUiIiIikrDnkIiIiHQKh5VVY3JIREREOoWrlVXjsDIRERERSdhzSERERDpFgGZDw+W845DJIREREekWrlZWjckhERER6RQuSFGNcw7fAXfv3oUgCIiJiXnn216zZg0sLCy00ha9+2au2I1KXsOUto96TFGqc+byHXQZGg6HFqPh1GosPv16AV5mZJVRxET/06T+B/jPvK9xbfdUJJ9ZjI4t6hZZd963PZF8ZjEG92pZ4Fi7prURtXoMHh6bhzsHZuGX2QOVjs8Y/TkOrRuHhOPzcTTiW21/DCqHZsyYAUEQMGLECKksIyMDgYGBqFixIuRyObp3747ExESl8+7fv49OnTrBxMQE1tbWGDt2LF69eqX1+HS25/Dx48cICQnBrl27kJiYCEtLS9SrVw8hISFo2rQpBEHAtm3b0KVLl7IOlahM1apeBVsWB0n7+nr/+z/lmct30GP4jxjh3xYzxvwf9PRkuHrjAWTlfcyF3gsmxoa4cv0BftkejV9mDyqyXqeWddHIwwkPk1IKHOvcyhMLv++FKT/uwNGz16GvJ4PbB1UK1IvYcRINazuitktVbX4EKiVluVr5zJkz+Omnn1C3rvJ/VkaOHIldu3bh119/hbm5OYKCgtCtWzccP34cAJCTk4NOnTrB1tYWJ06cwKNHj/DVV1+hQoUKmDZtWskDKoTOJofdu3dHVlYW1q5di+rVqyMxMREHDhzAkydPyjq0EsnKyoKBgUFZh0HlkL6eDDYVFYUemzh/Kwb1aIHh/u2kMhdHm7cVGpFK+09cw/4T11TWqVLZHDPH/B8+/2YJNs0fonRMT0+G6aO7IyQ8Er9sj5bK4+4kKNX7du5vAICKFh2ZHL4nBGi2qKSk56anp8PPzw8rVqzADz/8IJWnpqZi1apV2LBhAz755BMAwOrVq+Hm5oaTJ0/io48+wr59+3Dt2jXs378fNjY28PT0xJQpUzB+/HiEhoZqNQfQyWHllJQUHDt2DDNnzkSrVq3g6OiIDz/8EBMmTMBnn30GJycnAEDXrl0hCIK0f+vWLfj6+sLGxgZyuRyNGzfG/v37ldp2cnLCtGnT0K9fP5iZmcHBwQHLly9XqnP69GnUr18fRkZGaNSoES5cuKB0PCcnB/3794ezszOMjY3h6uqKhQsXKtUJCAhAly5dMHXqVNjZ2cHV1bVYbaty+PBhCIKAXbt2oW7dujAyMsJHH32EK1euFHmOtu5JfHw8evToAQsLC1hZWcHX1xd3794tduxUem7HP0btTt+jYddQfB2yFn8nPAUAPH76DOeu3kUlKzN0GDAPbu2/Q+fBC3Ey5lYZR0xUPIIgYNnkr7DolwP463ZCgeP1XO1R1cYSuaKII7+MR+wfU/HrwiGF9hySbkpLS1PaMjMzVdYPDAxEp06d0KZNG6Xyc+fOITs7W6m8Vq1acHBwQHR03n9MoqOj4eHhARub//0H3MfHB2lpabh69aoWP5WOJodyuRxyuRyRkZGF/kOeOXMGQF7W/ujRI2k/PT0dHTt2xIEDB3DhwgW0b98enTt3xv3795XOnzt3rpSYDR06FEOGDEFcXJzUxqeffgp3d3ecO3cOoaGhGDNmjNL5ubm5qFatGn799Vdcu3YNISEh+O6777B582alegcOHEBcXByioqKwc+fOYrVdHGPHjsXcuXNx5swZVK5cGZ07d0Z2dnahdbVxT7Kzs+Hj4wMzMzMcO3YMx48fh1wuR/v27ZGVVfjctczMzALflKR9DWs7YlHIl9i8YChmj/8C9x8+wadfL8Cz5xm49+AfAMCsFbvRx7cJNi0cgrqu1dAtaDFu3U8q48iJ3myEf1u8ysnFTxsPF3rcqWolAMC3Aztizqq96DlyGVLSXmLHsuGwUJi8xUhJ22QQIBM02P7bd2hvbw9zc3Npmz59epHX3LhxI86fP19onYSEBBgYGBSY029jY4OEhASpzr8Tw/zj+ce0SSeHlfX19bFmzRoMHDgQy5YtQ4MGDdCiRQv07NkTdevWReXKlQEAFhYWsLW1lc6rV68e6tWrJ+1PmTIF27Ztw/bt2xEU9L85WR07dsTQoUMBAOPHj8f8+fNx6NAhuLq6YsOGDcjNzcWqVatgZGSE2rVr4++//8aQIf8bzqhQoQImT54s7Ts7OyM6OhqbN29Gjx49pHJTU1OsXLlS6kpevnz5G9sujkmTJqFt27YAgLVr16JatWrYtm2b0rW1eU82bdqE3NxcrFy5EsJ/J3KsXr0aFhYWOHz4MNq1a4fXTZ8+XekeUelo06S29PfaLlXRsLYjPH0n4fcDF1DTKe+Hkn/Xpujd+SMAQF1Xexw7ex0bdpxEcOBnZRIzUXHUq2WPr3u2RMsvZxZZJ3/u7NzVe7HjUAwAIDDsF1zdNQVdWtfHmm3H30aoVAq0NawcHx8PheJ/024MDQ0LrR8fH4/hw4cjKioKRkZGGlz57dDJnkMgb87hw4cPsX37drRv3x6HDx9GgwYNsGbNmiLPSU9Px5gxY+Dm5gYLCwvI5XLExsYW6CX79yRTQRBga2uLpKS8npTY2FhpyDaft7d3gWstWbIEDRs2ROXKlSGXy7F8+fIC1/Hw8FCaY1Dctt/k3+dYWVnB1dUVsbGxhdbVxj25ePEibt68CTMzM6lX18rKChkZGbh1q/AhygkTJiA1NVXa4uPj1f6cpD5zMxN84GCNO/GPYVMp7wdiTWflITYXJxv8nZhcFuERFZt3/Q9Q2VKOyzvC8Dh6IR5HL4SDXUX8MLwbLv6e9x/PhH9SAQBxtx9J52Vlv8LdB09QzdaqTOKmd4tCoVDaikoOz507h6SkJDRo0AD6+vrQ19fHkSNHEB4eDn19fdjY2CArKwspKSlK5yUmJkqdVLa2tgVWL+fv/7sjSxt0sucwn5GREdq2bYu2bdsiODgYAwYMwKRJkxAQEFBo/TFjxiAqKgpz5sxBjRo1YGxsjM8//7zA0GeFChWU9gVBQG5ubrHj2rhxI8aMGYO5c+fC29sbZmZmmD17Nk6dOqVUz9TUtNhtlhZt3JP09HQ0bNgQERERBdrP78V9naGhYZHfhFR60l9k4u6Df9CjQ2M4VKkI28rmuHVP+YfV7fuP0drbrYwiJCqeTbvP4MjpOKWy38IDsfmP04jYcRIAcPGveGRkZqOGow1OXrwNIG+BlkMVK8T/d+4tvafe8oqU1q1b4/Lly0plffv2Ra1atTB+/HjY29ujQoUKOHDgALp37w4AiIuLw/3796UOG29vb0ydOhVJSUmwtrYGAERFRUGhUMDd3V2DD1OQTieHr3N3d0dkZCSAvGQmJydH6fjx48cREBCArl27AshLatRdNOHm5ob169cjIyND6uE7efJkges0adJEGoYFUGQPmrptF8fJkyfh4OAAAEhOTsb169fh5lb4L3tt3JMGDRpg06ZNsLa2Vuqep7IXsnAbfJrVgb2tFRL+ScXMFbuhJ5OhW7uGEAQBQX6tMXPFbtR2qYo6Nath065TuHEvET9P71fWoRPB1NgAzvb/+w+mo11F1KlZFSmpL/B3YjKSU58r1X/1KgeJT9Jw817eqMaz5xlYvfVPfDuoIx4kJiM+4SmGfZm3YCBy/3npPOdqlWBqYgibigoYGVZAnZp5K5bjbicg+5Xy7xF6N7zth2CbmZmhTp06SmWmpqaoWLGiVN6/f3+MGjUKVlZWUCgUGDZsGLy9vfHRR3nTdtq1awd3d3f06dMHs2bNQkJCAiZOnIjAwECtd5boZHL45MkT/N///R/69euHunXrwszMDGfPnsWsWbPg6+sLIG+F7YEDB9C0aVMYGhrC0tISLi4u2Lp1Kzp37gxBEBAcHKxWjyAA9O7dG99//z0GDhyICRMm4O7du5gzZ45SHRcXF6xbtw579+6Fs7Mz1q9fjzNnzsDZ2VnjtosjLCwMFStWhI2NDb7//ntUqlSpyOc9auOe+Pn5Yfbs2fD19UVYWBiqVauGe/fuYevWrRg3bhyqVaum9mcg7XiYlIJBwWuQnPoCFS3k8KpXHXtWjUIlSzMAwOBerZCZlY2JC7YiJe0FartUxW/hgXCuVniPL9Hb5OnmiJ0/DZf2p43K65HZsPMkAif/Uqw2QhZuw6ucXCyb/BWMDCvg3NV78B0ajtRnL6U64RP98HFDF2n/WMQEAEDdz0IQ/4g9jFQ88+fPh0wmQ/fu3ZGZmQkfHx/8+OOP0nE9PT3s3LkTQ4YMgbe3N0xNTeHv74+wsDCtx6KTyaFcLoeXlxfmz5+PW7duITs7G/b29hg4cCC+++47AHmra0eNGoUVK1agatWquHv3LubNm4d+/fqhSZMmqFSpEsaPH6/2Klm5XI4dO3Zg8ODBqF+/Ptzd3TFz5kypGxkAvv76a1y4cAFffPEFBEFAr169MHToUPzxxx8at10cM2bMwPDhw3Hjxg14enpix44dRT4/SRv3xMTEBEePHsX48ePRrVs3PHv2DFWrVkXr1q3Zk1jGVk7t+8Y6w/3bKT3nkOhdcfz8DVg2Dnpzxf+q5zupQNmrnFyELNyGkIXbijyv8+CFRR6jd5SGD8HWxtvzDh8+rLRvZGSEJUuWYMmSJUWe4+joiN27d2t+8TcQRFEUS/0q9F44fPgwWrVqheTk5PfuFXlpaWkwNzfHw8cpTCip3KrkNaysQyAqNWJOFjIvr0Bqamqp/RzP/11xMOY+5GYlv0b6szR84ulQqrGWJZ3sOSQiIiIdVlavSHlP6OyjbHTR4MGDpUfFvL4NHjy4rMMjIiKidwB7DnVIWFhYkW9MUSgUsLa2BmcZEBFRefe2Vyu/b5gc6hBra2vp2UhERES6StBwQYpGi1neAxxWJiIiIiIJew6JiIhIp3A9impMDomIiEi3MDtUicPKRERERCRhzyERERHpFK5WVo3JIREREekUrlZWjcPKRERERCRhzyERERHpFK5HUY3JIREREekWZocqMTkkIiIincIFKapxziERERERSdhzSERERDqFq5VVY3JIREREOoVTDlXjsDIRERERSdhzSERERLqFXYcqMTkkIiIincLVyqpxWJmIiIiIJOw5JCIiIp3C1cqqMTkkIiIincIph6pxWJmIiIiIJOw5JCIiIt3CrkOVmBwSERGRTuFqZdWYHBIREZFO4YIU1TjnkIiIiIgk7DkkIiIincIph6oxOSQiIiLdwuxQJQ4rExEREZGEPYdERESkU7haWTUmh0RERKRbNFytXM5zQw4rExEREdH/sOeQiIiIdArXo6jG5JCIiIh0C7NDlZgcEhERkU7hghTVOOeQiIiIiCTsOSQiIiKdwncrq8bkkIiIiHQKpxyqxmFlIiIiolI0ffp0NG7cGGZmZrC2tkaXLl0QFxenVCcjIwOBgYGoWLEi5HI5unfvjsTERKU69+/fR6dOnWBiYgJra2uMHTsWr1690nq8TA6JiIhItwha2NRw5MgRBAYG4uTJk4iKikJ2djbatWuH58+fS3VGjhyJHTt24Ndff8WRI0fw8OFDdOvWTTqek5ODTp06ISsrCydOnMDatWuxZs0ahISElPQuFEkQRVHUeqtEb1laWhrMzc3x8HEKFApFWYdDVCoqeQ0r6xCISo2Yk4XMyyuQmppaaj/H839XXL6TBDOzkl/j2bM0eDhblzjWx48fw9raGkeOHEHz5s2RmpqKypUrY8OGDfj8888BAH/99Rfc3NwQHR2Njz76CH/88Qc+/fRTPHz4EDY2NgCAZcuWYfz48Xj8+DEMDAxK/Hlex55DIiIiohJIS0tT2jIzM4t1XmpqKgDAysoKAHDu3DlkZ2ejTZs2Up1atWrBwcEB0dHRAIDo6Gh4eHhIiSEA+Pj4IC0tDVevXtXWRwLA5JCIiIh0jID/rVgu0fbfduzt7WFubi5t06dPf+O1c3NzMWLECDRt2hR16tQBACQkJMDAwAAWFhZKdW1sbJCQkCDV+XdimH88/5g2cbUyERER6RRtrVaOj49XGlY2NDR847mBgYG4cuUK/vzzTw0iKF3sOSQiIiIqAYVCobS9KTkMCgrCzp07cejQIVSrVk0qt7W1RVZWFlJSUpTqJyYmwtbWVqrz+url/P38OtrC5JCIiIh0ikZDyiV4gLYoiggKCsK2bdtw8OBBODs7Kx1v2LAhKlSogAMHDkhlcXFxuH//Pry9vQEA3t7euHz5MpKSkqQ6UVFRUCgUcHd3L/nNKASHlYmIiEjHvN3HYAcGBmLDhg34/fffYWZmJs0RNDc3h7GxMczNzdG/f3+MGjUKVlZWUCgUGDZsGLy9vfHRRx8BANq1awd3d3f06dMHs2bNQkJCAiZOnIjAwMBiDWerg8khERER6ZS3/fq8pUuXAgBatmypVL569WoEBAQAAObPnw+ZTIbu3bsjMzMTPj4++PHHH6W6enp62LlzJ4YMGQJvb2+YmprC398fYWFhJf8gRWBySERERFSKivNIaSMjIyxZsgRLliwpso6joyN2796tzdAKxeSQiIiIdArfrawak0MiIiLSKW97WPl9w9XKRERERCRhzyERERHpFOG/fzQ5vzxjckhERES6hZMOVeKwMhERERFJ2HNIREREOoUdh6oxOSQiIiKdwtXKqnFYmYiIiIgk7DkkIiIincLVyqoxOSQiIiLdwkmHKjE5JCIiIp3C3FA1zjkkIiIiIgl7DomIiEincLWyakwOiYiISMdotiClvA8sc1iZiIiIiCTsOSQiIiKdwmFl1dhzSEREREQSJodEREREJOGwMhEREekUDiurxuSQiIiIdApfn6cah5WJiIiISMKeQyIiItIpHFZWjckhERER6RS+W1k1JodERESkW5gdqsQ5h0REREQkYc8hERER6RSuVlaNySERERHpFC5IUY3DykREREQkYc8hERER6RSuR1GNySERERHpFmaHKnFYmYiIiIgk7DkkIiIincLVyqoxOSQiIiKdwtXKqjE5pHJBFEUAwLNnaWUcCVHpEXOyyjoEolKT//Wd//O8NKWlafa7QtPz33VMDqlcePbsGQDAtbpDGUdCRESaePbsGczNzUulbQMDA9ja2sLF2V7jtmxtbWFgYKCFqN49gvg2UnSiUpabm4uHDx/CzMwMQnnv739HpKWlwd7eHvHx8VAoFGUdDpFW8ev77RNFEc+ePYOdnR1kstJbL5uRkYGsLM174Q0MDGBkZKSFiN497DmkckEmk6FatWplHYZOUigU/OVJ5Ra/vt+u0uox/DcjI6Nym9RpCx9lQ0REREQSJodEREREJGFySEQlYmhoiEmTJsHQ0LCsQyHSOn59ky7jghQiIiIikrDnkIiIiIgkTA6JiIiISMLkkIiIiIgkTA6JSC2HDx+GIAhISUl559sODQ2Fp6enVtqi98vdu3chCAJiYmLe+bbXrFkDCwsLrbRFpA1MDomKKSAgAIIgYMaMGUrlkZGRZfpWltL8JUikjsePH2PIkCFwcHCAoaEhbG1t4ePjg+PHjwMABEFAZGRk2QZJRG/E5JBIDUZGRpg5cyaSk5PLOpT3mjZeXUXvnu7du+PChQtYu3Ytrl+/ju3bt6Nly5Z48uRJWYdWIvw6JV3F5JBIDW3atIGtrS2mT59eZJ0tW7agdu3aMDQ0hJOTE+bOnat03MnJCdOmTUO/fv1gZmYGBwcHLF++XOV1k5OT4efnh8qVK8PY2BguLi5YvXo1AMDZ2RkAUL9+fQiCgJYtWwIAzpw5g7Zt26JSpUowNzdHixYtcP78eaV2BUHAypUr0bVrV5iYmMDFxQXbt29XqrN7927UrFkTxsbGaNWqFe7evat0/MmTJ+jVqxeqVq0KExMTeHh44D//+Y9SnZYtWyIoKAgjRoxApUqV4OPjU6y2VckfiouMjISLiwuMjIzg4+OD+Pj4Is/R1j25cuUKOnToALlcDhsbG/Tp0wf//PNPsWMvj1JSUnDs2DHMnDkTrVq1gqOjIz788ENMmDABn332GZycnAAAXbt2hSAI0v6tW7fg6+sLGxsbyOVyNG7cGPv371dquzjfM6dPn0b9+vVhZGSERo0a4cKFC0rHc3Jy0L9/fzg7O8PY2Biurq5YuHChUp2AgAB06dIFU6dOhZ2dHVxdXYvVtir5UyV27dqFunXrwsjICB999BGuXLlS5Dnauifx8fHo0aMHLCwsYGVlBV9fX7W+x0iHiURULP7+/qKvr6+4detW0cjISIyPjxdFURS3bdsm5n8rnT17VpTJZGJYWJgYFxcnrl69WjQ2NhZXr14ttePo6ChaWVmJS5YsEW/cuCFOnz5dlMlk4l9//VXktQMDA0VPT0/xzJkz4p07d8SoqChx+/btoiiK4unTp0UA4v79+8VHjx6JT548EUVRFA8cOCCuX79ejI2NFa9duyb2799ftLGxEdPS0qR2AYjVqlUTN2zYIN64cUP85ptvRLlcLrVx//590dDQUBw1apT4119/ib/88otoY2MjAhCTk5NFURTFv//+W5w9e7Z44cIF8datW2J4eLiop6cnnjp1SrpOixYtRLlcLo4dO1b866+/xL/++qtYbauyevVqsUKFCmKjRo3EEydOiGfPnhU//PBDsUmTJlKdSZMmifXq1ZP2tXFPkpOTxcqVK4sTJkwQY2NjxfPnz4tt27YVW7Vq9caYy7Ps7GxRLpeLI0aMEDMyMgocT0pKEgGIq1evFh89eiQmJSWJoiiKMTEx4rJly8TLly+L169fFydOnCgaGRmJ9+7dk8590/fMs2fPxMqVK4u9e/cWr1y5Iu7YsUOsXr26CEC8cOGCKIqimJWVJYaEhIhnzpwRb9++Lf7yyy+iiYmJuGnTJuk6/v7+olwuF/v06SNeuXJFvHLlSrHaVuXQoUMiANHNzU3ct2+feOnSJfHTTz8VnZycxKysLFEU876Wzc3NpXO0cU+ysrJENzc3sV+/fuKlS5fEa9euib179xZdXV3FzMzM4v2jks5ickhUTPnJoSiK4kcffST269dPFEXl5LB3795i27Ztlc4bO3as6O7uLu07OjqKX375pbSfm5srWltbi0uXLi3y2p07dxb79u1b6LE7d+4U6xdVTk6OaGZmJu7YsUMqAyBOnDhR2k9PTxcBiH/88YcoiqI4YcIEpdhFURTHjx//xgSuU6dO4ujRo6X9Fi1aiPXr11eqU9K2861evVoEIJ48eVIqi42NFQFIienryeHrSnJPpkyZIrZr106pnfj4eBGAGBcX98a4y7PffvtNtLS0FI2MjMQmTZqIEyZMEC9evCgdByBu27btje3Url1bXLRokbT/pu+Zn376SaxYsaL48uVLqc7SpUvf+H0RGBgodu/eXdr39/cXbWxslJKnkradLz853Lhxo1T25MkT0djYWEpMX08OC6PuPVm/fr3o6uoq5ubmSnUyMzNFY2Njce/evW+Mm3Qbh5WJSmDmzJlYu3YtYmNjlcpjY2PRtGlTpbKmTZvixo0byMnJkcrq1q0r/V0QBNja2iIpKQkApOFKuVyO2rVrAwCGDBmCjRs3wtPTE+PGjcOJEyfeGGNiYiIGDhwIFxcXmJubQ6FQID09Hffv31eq9+9YTE1NoVAopFhiY2Ph5eWlVN/b21tpPycnB1OmTIGHhwesrKwgl8uxd+/eAtdp2LBhgXv1prbfRF9fH40bN5b2a9WqBQsLiwL/Lvm0cU8uXryIQ4cOSf9GcrkctWrVApA3HKjLunfvjocPH2L79u1o3749Dh8+jAYNGmDNmjVFnpOeno4xY8bAzc0NFhYWkMvliI2NVflv8vr3TGxsrDRkm6+wr6UlS5agYcOGqFy5MuRyOZYvX17gOh4eHjAwMJD2i9v2m/z7HCsrK7i6uhb5daqNe3Lx4kXcvHkTZmZm0teplZUVMjIydP7rlN5Mv6wDIHofNW/eHD4+PpgwYQICAgLUPr9ChQpK+4IgIDc3FwCwcuVKvHz5Uqlehw4dcO/ePezevRtRUVFo3bo1AgMDMWfOnCKv4e/vjydPnmDhwoVwdHSEoaEhvL29C0yyVxVLccyePRsLFy7EggUL4OHhAVNTU4wYMaLAdUxNTYvdZmnRxj1JT09H586dMXPmzALtV6lSpfSCf08YGRmhbdu2aNu2LYKDgzFgwABMmjSpyO+TMWPGICoqCnPmzEGNGjVgbGyMzz//XOtfpxs3bsSYMWMwd+5ceHt7w8zMDLNnz8apU6eU6r0LX6fauCfp6elo2LAhIiIiCrRfuXLl0gueygUmh0QlNGPGDHh6ekqT1gHAzc1NemxHvuPHj6NmzZrQ09MrVrtVq1YttLxy5crw9/eHv78/mjVrhrFjx2LOnDlSL8e/eybzr/vjjz+iY8eOAPImp6u7aMLNza3AYoyTJ08WuI6vry++/PJLAEBubi6uX78Od3d3jdt+k1evXuHs2bP48MMPAQBxcXFISUmBm5tbofW1cU8aNGiALVu2wMnJCfr6/BH6Ju7u7tLjaypUqFDo12lAQAC6du0KIC+pUXfRhJubG9avX4+MjAyph6+wr9MmTZpg6NChUllxetCK03ZxnDx5Eg4ODgDyFphdv35d5deppvekQYMG2LRpE6ytraFQKNSOl3Qbh5WJSsjDwwN+fn4IDw+XykaPHo0DBw5gypQpuH79OtauXYvFixdjzJgxGl0rJCQEv//+O27evImrV69i586d0i8Wa2trGBsbY8+ePUhMTERqaioAwMXFBevXr0dsbCxOnToFPz8/GBsbq3XdwYMH48aNGxg7dizi4uKwYcOGAkOELi4uiIqKwokTJxAbG4uvv/4aiYmJWmn7TSpUqIBhw4bh1KlTOHfuHAICAvDRRx9JyeLrtHFPAgMD8fTpU/Tq1QtnzpzBrVu3sHfvXvTt27dA4qNLnjx5gk8++QS//PILLl26hDt37uDXX3/FrFmz4OvrCyBvhe2BAweQkJAgPQ7KxcUFW7duRUxMDC5evIjevXur1SMIAL1794YgCBg4cCCuXbuG3bt3F+hVd3FxwdmzZ7F3715cv34dwcHBOHPmjFbaLo6wsDAcOHAAV65cQUBAACpVqoQuXboUWlcb98TPzw+VKlWCr68vjh07hjt37uDw4cP45ptv8Pfff6sdP+kWJodEGggLC1P6od2gQQNs3rwZGzduRJ06dRASEoKwsLASDT3/m4GBASZMmIC6deuiefPm0NPTw8aNGwHkzbsLDw/HTz/9BDs7O+kX8apVq5CcnIwGDRqgT58++Oabb2Btba3WdR0cHLBlyxZERkaiXr16WLZsGaZNm6ZUZ+LEiWjQoAF8fHzQsmVL2NraFvlLT92238TExATjx49H79690bRpU8jlcmzatKnI+tq4J3Z2djh+/DhycnLQrl07eHh4YMSIEbCwsIBMprs/UuVyOby8vDB//nw0b94cderUQXBwMAYOHIjFixcDAObOnYuoqCjY29ujfv36AIB58+bB0tISTZo0QefOneHj44MGDRqofe0dO3bg8uXLqF+/Pr7//vsCw/5ff/01unXrhi+++AJeXl548uSJUi+iJm0Xx4wZMzB8+HA0bNgQCQkJ2LFjh9Lcxn/Txj0xMTHB0aNH4eDggG7dusHNzQ39+/dHRkYGexLpjQRRFMWyDoKISF1r1qzBiBEjSuU1fkTacvjwYbRq1QrJycl8RR69N3T3v7lEREREVACTQyJ6J/37kT6vb+oOPxOVlsGDBxf5dTp48OCyDo+oRDisTETvpAcPHkiP9HmdlZUVrKys3nJERAUlJSUhLS2t0GMKhULtOa1E7wImh0REREQk4bAyEREREUmYHBIRERGRhMkhEREREUmYHBIRaUlAQIDSA8BbtmyJESNGvPU4Dh8+DEEQVD4DUhAE6bV2xREaGgpPT0+N4rp79y4EQUBMTIxG7RBR6WJySETlWkBAAARBgCAIMDAwQI0aNRAWFoZXr16V+rW3bt2KKVOmFKtucRI6IqK3gW+NJ6Jyr3379li9ejUyMzOxe/duBAYGokKFCpgwYUKBullZWUW+1kxdfNwOEb2P2HNIROWeoaEhbG1t4ejoiCFDhqBNmzbYvn07gP8NBU+dOhV2dnZwdXUFAMTHx6NHjx6wsLCAlZUVfH19cffuXanNnJwcjBo1ChYWFqhYsSLGjRuH158M9vqwcmZmJsaPHw97e3sYGhqiRo0aWLVqFe7evYtWrVoBACwtLSEIgvQ+7tzcXEyfPh3Ozs4wNjZGvXr18NtvvyldZ/fu3ahZsyaMjY3RqlUrpTiLa/z48ahZsyZMTExQvXp1BAcHIzs7u0C9n376Cfb29jAxMUGPHj2QmpqqdHzlypVwc3ODkZERatWqhR9//FHtWIiobDE5JCKdY2xsjKysLGn/wIEDiIuLQ1RUFHbu3Ins7Gz4+PjAzMwMx44dw/HjxyGXy9G+fXvpvLlz52LNmjX4+eef8eeff+Lp06fYtm2byut+9dVX+M9//oPw8HDExsbip59+glwuh729PbZs2QIAiIuLw6NHj7Bw4UIAwPTp07Fu3TosW7YMV69exciRI/Hll1/iyJEjAPKS2G7duqFz586IiYnBgAED8O2336p9T8zMzLBmzRpcu3YNCxcuxIoVKzB//nylOjdv3sTmzZuxY8cO7NmzBxcuXMDQoUOl4xEREQgJCcHUqVMRGxuLadOmITg4GGvXrlU7HiIqQyIRUTnm7+8v+vr6iqIoirm5uWJUVJRoaGgojhkzRjpuY2MjZmZmSuesX79edHV1FXNzc6WyzMxM0djYWNy7d68oiqJYpUoVcdasWdLx7OxssVq1atK1RFEUW7RoIQ4fPlwURVGMi4sTAYhRUVGFxnno0CERgJicnCyVZWRkiCYmJuKJEyeU6vbv31/s1auXKIqiOGHCBNHd3V3p+Pjx4wu09ToA4rZt24o8Pnv2bLFhw4bS/qRJk0Q9PT3x77//lsr++OMPUSaTiY8ePRJFURQ/+OADccOGDUrtTJkyRfT29hZFURTv3LkjAhAvXLhQ5HWJqOxxziERlXs7d+6EXC5HdnY2cnNz0bt3b4SGhkrHPTw8lOYZXrx4ETdv3oSZmZlSOxkZGbh16xZSU1Px6NEjeHl5Scf09fXRqFGjAkPL+WJiYqCnp4cWLVoUO+6bN2/ixYsXaNu2rVJ5VlYW6tevDwCIjY1VigMAvL29i32NfJs2bUJ4eDhu3bqF9PR0vHr1CgqFQqmOg4MDqlatqnSd3NxcxMXFwczMDLdu3UL//v0xcOBAqc6rV69gbm6udjxEVHaYHBJRudeqVSssXboUBgYGsLOzg76+8o8+U1NTpf309HQ0bNgQERERBdqqXLlyiWIwNjZW+5z09HQAwK5du5SSMiBvHqW2REdHw8/PD5MnT4aPjw/Mzc2xceNGzJ07V+1YV6xYUSBZ1dPT01qsRFT6mBwSUblnamqKGjVqFLt+gwYNsGnTJlhbWxfoPctXpUoVnDp1Cs2bNweQ10N27tw5NGjQoND6Hh4eyM3NxZEjR9CmTZsCx/N7LnNycqQyd3d3GBoa4v79+0X2OLq5uUmLa/KdPHnyzR/yX06cOAFHR0d8//33Utm9e/cK1Lt//z4ePnwIOzs76ToymQyurq6wsbGBnZ0dbt++DT8/P7WuT0TvFi5IISJ6jZ+fHypVqgRfX18cO3YMd+7cweHDh/HNN9/g77//BgAMHz4cM2bMQGRkJP766y8MHTpU5TMKnZyc4O/vj379+iEyMlJqc/PmzQAAR0dHCIKAnTt34vHjx0hPT4eZmRnGjBmDkSNHYu3atbh16xbOnz+PRYsWSYs8Bg8ejBs3bmDs2LGIi4vDhg0bsGbNGrU+r4uLC+7fv4+NGzfi1q1bCA8PL3RxjZGREfz9/XHx4kUcO3YM33zzDXr06AFbW1sAwOTJkzF9+nSEh4fj+vXruHz5MlavXo158+apFQ8RlS0mh0RErzExMcHRo0fh4OCAbt26wc3NDf3790dGRobUkzh69Gj06dMH/v7+8Pb2hpmZGbp27aqy3aVLl+Lzzz/H0KFDUatWLQwcOBDPnz8HAFStWhWTJ0/Gt99+CxsbGwQFBQEApkyZguDgYEyfPh1ubm5o3749du3aBWdnZwB58wC3bNmCyMhI1KtXD8uWLcO0adPU+ryfffYZRo4ciaCgIHh6euLEiRMIDg4uUK9GjRro1q0bOnbsiHbt2qFu3bpKj6oZMGAAVq5cidWrV8PDwwMtWrTAmjVrpFiJ6P0giEXNniYiIiIincOeQyIiIiKSMDkkIiIiIgmTQyIiIiKSMDkkIiIiIgmTQyIiIiKSMDkkIiIiIgmTQyIiIiKSMDkkIiIiIgmTQyIiIiKSMDkkIiIiIgmTQyIiIiKSMDkkIiIiIsn/A9undJrhvAl5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(true, pre)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "class_labels = ['Non-standard_plane','Standard_plane']\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=class_labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f8b5537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:18:11.057695Z",
     "iopub.status.busy": "2025-02-28T22:18:11.057207Z",
     "iopub.status.idle": "2025-02-28T22:18:11.064624Z",
     "shell.execute_reply": "2025-02-28T22:18:11.063771Z"
    },
    "papermill": {
     "duration": 0.081962,
     "end_time": "2025-02-28T22:18:11.065906",
     "exception": false,
     "start_time": "2025-02-28T22:18:10.983944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Confidence Interval: (0.9458, 0.9636)\n"
     ]
    }
   ],
   "source": [
    "# using traditonal method to calculate CI\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Function to calculate 95% confidence interval for a parameter x\n",
    "def calculate_confidence_interval(x, sample_size, confidence_level=0.95):\n",
    "    # Calculate the standard error\n",
    "    standard_error = np.sqrt((x * (1 - x)) / sample_size)\n",
    "\n",
    "    # Find the Z-score for the given confidence level\n",
    "    z_score = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "\n",
    "    # Calculate the margin of error\n",
    "    margin_of_error = z_score * standard_error\n",
    "\n",
    "    # Calculate the confidence interval\n",
    "    lower_bound = x - margin_of_error\n",
    "    upper_bound = x + margin_of_error\n",
    "\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "ci_lower, ci_upper = calculate_confidence_interval(test_accuracy, len(test_loader.dataset), confidence_level=0.95)\n",
    "print(f\"95% Confidence Interval: ({ci_lower:.4f}, {ci_upper:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6b4abb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:18:11.108263Z",
     "iopub.status.busy": "2025-02-28T22:18:11.108010Z",
     "iopub.status.idle": "2025-02-28T22:18:16.636634Z",
     "shell.execute_reply": "2025-02-28T22:18:16.635712Z"
    },
    "papermill": {
     "duration": 5.551243,
     "end_time": "2025-02-28T22:18:16.638004",
     "exception": false,
     "start_time": "2025-02-28T22:18:11.086761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap AUC 95% CI: (0.936, 0.959)\n"
     ]
    }
   ],
   "source": [
    "# Bootstrapping AUCs to calculate CI\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def bootstrap_auc(y_test, y_pred, n_iterations=2000, confidence_level=0.95):\n",
    "    # Store the AUCs\n",
    "    aucs = []\n",
    "    n_size = len(y_test)\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        # print(\"Processing: \",i)\n",
    "        # Resample the data with replacement\n",
    "        y_test_resampled, y_pred_resampled = resample(y_test, y_pred, n_samples=n_size)\n",
    "        # Calculate the AUC\n",
    "        auc = roc_auc_score(y_test_resampled, y_pred_resampled)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    # Calculate the lower and upper percentiles for the confidence interval\n",
    "    lower_bound = np.percentile(aucs, ((1 - confidence_level) / 2) * 100)\n",
    "    upper_bound = np.percentile(aucs, (confidence_level + ((1 - confidence_level) / 2)) * 100)\n",
    "\n",
    "    return lower_bound, upper_bound, aucs\n",
    "\n",
    "\n",
    "lower_ci, upper_ci, auc_scores = bootstrap_auc(true, pre)\n",
    "print(f\"Bootstrap AUC 95% CI: ({lower_ci:.3f}, {upper_ci:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f803b947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:18:16.681748Z",
     "iopub.status.busy": "2025-02-28T22:18:16.681478Z",
     "iopub.status.idle": "2025-02-28T22:18:16.938799Z",
     "shell.execute_reply": "2025-02-28T22:18:16.938057Z"
    },
    "papermill": {
     "duration": 0.280414,
     "end_time": "2025-02-28T22:18:16.940159",
     "exception": false,
     "start_time": "2025-02-28T22:18:16.659745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(auc_scores, bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Bootstrapped AUCs')\n",
    "plt.xlabel('AUC')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(lower_ci, color='red', linestyle='--', label=f'Lower CI: {lower_ci:.3f}')\n",
    "plt.axvline(upper_ci, color='green', linestyle='--', label=f'Upper CI: {upper_ci:.3f}')\n",
    "plt.axvline(np.mean(auc_scores), color='blue', linestyle='-', label=f'Mean AUC: {np.mean(auc_scores):.3f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82d51398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T22:18:16.984112Z",
     "iopub.status.busy": "2025-02-28T22:18:16.983895Z",
     "iopub.status.idle": "2025-02-28T22:18:22.750421Z",
     "shell.execute_reply": "2025-02-28T22:18:22.749447Z"
    },
    "papermill": {
     "duration": 5.789895,
     "end_time": "2025-02-28T22:18:22.751881",
     "exception": false,
     "start_time": "2025-02-28T22:18:16.961986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap AUC 95% CI: (0.937, 0.959)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "def bootstrap_auc(y_test, y_pred, n_iterations=2000, confidence_level=0.95):\n",
    "    \"\"\"\n",
    "    Bootstraps AUCs to calculate confidence intervals with stratification.\n",
    "\n",
    "    Parameters:\n",
    "    y_test: np.array or list\n",
    "        True labels (binary classification).\n",
    "    y_pred: np.array or list\n",
    "        Predicted probabilities or scores.\n",
    "    n_iterations: int\n",
    "        Number of bootstrap iterations.\n",
    "    confidence_level: float\n",
    "        Confidence level for the CI.\n",
    "\n",
    "    Returns:\n",
    "    lower_bound: float\n",
    "        Lower bound of the confidence interval.\n",
    "    upper_bound: float\n",
    "        Upper bound of the confidence interval.\n",
    "    aucs: list\n",
    "        List of AUCs from bootstrapping.\n",
    "    \"\"\"\n",
    "    # Store the AUCs\n",
    "    aucs = []\n",
    "    n_size = len(y_test)\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        # Resample the data with replacement, ensuring at least one positive and one negative sample\n",
    "        while True:\n",
    "            y_test_resampled, y_pred_resampled = resample(y_test, y_pred, n_samples=n_size)\n",
    "            if len(np.unique(y_test_resampled)) == 2:  # Check for both classes\n",
    "                break\n",
    "\n",
    "        # Calculate the AUC\n",
    "        auc = roc_auc_score(y_test_resampled, y_pred_resampled)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    # Calculate the lower and upper percentiles for the confidence interval\n",
    "    lower_bound = np.percentile(aucs, ((1 - confidence_level) / 2) * 100)\n",
    "    upper_bound = np.percentile(aucs, (confidence_level + ((1 - confidence_level) / 2)) * 100)\n",
    "\n",
    "    return lower_bound, upper_bound, aucs\n",
    "\n",
    "# Example usage:\n",
    "# Replace true and pre with your actual data\n",
    "# true = np.array([...])  # Binary ground truth\n",
    "# pre = np.array([...])   # Predicted probabilities or scores\n",
    "\n",
    "lower_ci, upper_ci, auc_scores = bootstrap_auc(true, pre)\n",
    "print(f\"Bootstrap AUC 95% CI: ({lower_ci:.3f}, {upper_ci:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60525ea6",
   "metadata": {
    "papermill": {
     "duration": 0.021904,
     "end_time": "2025-02-28T22:18:22.796386",
     "exception": false,
     "start_time": "2025-02-28T22:18:22.774482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6748901,
     "sourceId": 10863691,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 253945,
     "modelInstanceId": 232216,
     "sourceId": 271276,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 254007,
     "modelInstanceId": 232278,
     "sourceId": 271344,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11675.463371,
   "end_time": "2025-02-28T22:18:25.427107",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-28T19:03:49.963736",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
